{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ruta_al_directorio = '/home/TFM/code'\n",
    "\n",
    "os.chdir(ruta_al_directorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from gnn.model import get_gnnNets\n",
    "from gendata import get_dataset\n",
    "from utils.parser_utils import (\n",
    "    arg_parse,\n",
    "    create_args_group,\n",
    "    fix_random_seed,\n",
    "    get_data_args,\n",
    "    get_graph_size_args,\n",
    ")\n",
    "from pathlib import Path\n",
    "from torch_geometric.utils import degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forma manual - entender el código proporcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import mat73\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torch_geometric.data import InMemoryDataset, Data, download_url, extract_zip\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from utils.gen_utils import from_edge_index_to_adj, padded_datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "names = {\n",
    "        \"uk\": [\"uk\", \"Uk\", \"UK\", None],\n",
    "        \"ieee24\": [\"ieee24\", \"Ieee24\", \"IEEE24\", None],\n",
    "        \"ieee39\": [\"ieee39\", \"Ieee39\", \"IEEE39\", None],\n",
    "        \"ieee118\": [\"ieee118\", \"Ieee118\", \"IEEE118\", None],\n",
    "            }\n",
    "name = \"ieee24\"\n",
    "raw_dir = '/home/dataset/{}/raw'.format(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# load branch list also called edge order or edge index\n",
    "path = os.path.join(raw_dir, 'blist.mat')\n",
    "edge_order = mat73.loadmat(path)\n",
    "edge_order = torch.tensor(edge_order[\"bList\"] - 1)\n",
    "\n",
    "\n",
    "# load output binary classification labels\n",
    "path = os.path.join(raw_dir, 'of_bi.mat')\n",
    "of_bi = mat73.loadmat(path)\n",
    "\n",
    "# load output binary regression labels\n",
    "path = os.path.join(raw_dir, 'of_reg.mat')\n",
    "of_reg = mat73.loadmat(path)\n",
    "\n",
    "# load output mc labels\n",
    "path = os.path.join(raw_dir, 'of_mc.mat')\n",
    "of_mc = mat73.loadmat(path)\n",
    "\n",
    "\n",
    "# load output node feature matrix\n",
    "path = os.path.join(raw_dir, 'Bf.mat')\n",
    "node_f = mat73.loadmat(path)\n",
    "\n",
    "\n",
    "# load output edge feature matrix\n",
    "path = os.path.join(raw_dir, 'Ef.mat')\n",
    "edge_f = mat73.loadmat(path)\n",
    "\n",
    "\n",
    "# load explanations\n",
    "path = os.path.join(raw_dir, \"exp.mat\")\n",
    "exp = mat73.loadmat(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "node_f = node_f['B_f_tot']\n",
    "edge_f = edge_f['E_f_post']\n",
    "of_bi = of_bi['output_features']\n",
    "of_mc = of_mc['category']\n",
    "of_reg = of_reg['dns_MW']\n",
    "exp_mask = exp[\"explainations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "adj_list = []\n",
    "max_num_nodes = 0\n",
    "index = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bucle principal de procesamiento:\n",
    "\n",
    "Para cada grafo del dataset (resultado de un corte), hacemos.\n",
    "- Cogemos las características de los nodos y aristas\n",
    "- Procesamos las aristas:\n",
    "    1. Se crea una máscara que tiene a 1 las aristas que fueron parte del inicio del fallo\n",
    "    2. Se eliminan las contingencias (aristas que tengan todo a 0 al final) de la máscara, y se duplica la máscara \n",
    "    3. Se eliminan las contingencias de la matriz de atributos de aristas\n",
    "    4. Se duplican las características de las aristas, para tener en cuenta los ejes en ambos sentidos\n",
    "    5. Se eliminan las contingencias de la lista de aristas general (para obtener una versión de cada grafo)\n",
    "    6. Se duplica la lista de aristas general\n",
    "- Creamos un objeto Data, que representa un grafo, y lo procesamos correctamente:\n",
    "    - Las etiquetas 0 se transforman a 1, y las etiquetas 1 se cambian a -1\n",
    "    - Se guarda en una lista de objetos Data\n",
    "- Se obtiene la matriz de adyacencia, y se guarda en una lista de matrices de adyacencia\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def th_delete(tensor, indices):\n",
    "            mask = torch.ones(tensor.size(), dtype=torch.bool)\n",
    "            mask[indices] = False\n",
    "            return tensor[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "datatype = 'binary'\n",
    "pre_filter = None\n",
    "pre_transform = None\n",
    "#Iteramos a través de todo el dataset:\n",
    "\n",
    "for i in range(len(node_f)):\n",
    "    # node output features\n",
    "    x = torch.tensor(node_f[i][0], dtype=torch.float32).reshape([-1, 3]).to(device)\n",
    "    # edge output features\n",
    "    f = torch.tensor(edge_f[i][0], dtype=torch.float32)\n",
    "\n",
    "\n",
    "    #Se ponen a 1 las aristas que empezaron con la cascada de fallos\n",
    "    e_mask = torch.zeros(len(edge_f[i][0]), 1)\n",
    "    if exp_mask[i][0] is None:  # .all() == 0:\n",
    "        e_mask = e_mask\n",
    "    else:\n",
    "        e_mask[exp_mask[i][0].astype('int')-1] = 1\n",
    "\n",
    "        \n",
    "    # contigency lists, finds where do we have contigencies from the .mat edge feature matrices\n",
    "    # ( if a line is part of the contigency list all egde features are set 0)\n",
    "    cont = [j for j in range(len(f)) if np.all(np.array(f[j])) == 0]\n",
    "    e_mask_post = th_delete(e_mask, cont)\n",
    "    e_mask_post = torch.cat((e_mask_post, e_mask_post), 0).to(device)\n",
    "\n",
    "    \n",
    "    # remove edge features of the associated line\n",
    "    f_tot = th_delete(f, cont).reshape([-1, 4]).type(torch.float32)\n",
    "\n",
    "\n",
    "    # concat the post-contigency edge feature matrix to take into account the reversed edges\n",
    "    f_totw = torch.cat((f_tot, f_tot), 0).to(device)\n",
    "\n",
    "    \n",
    "    # remove failed lines from branch list\n",
    "    edge_iw = th_delete(edge_order, cont).reshape(-1, 2).type(torch.long)\n",
    "    # flip branch list\n",
    "    edge_iwr = torch.fliplr(edge_iw)\n",
    "    \n",
    "    #  and concat the non flipped and flipped branch list\n",
    "    edge_iw = torch.cat((edge_iw, edge_iwr), 0)\n",
    "    edge_iw = edge_iw.t().contiguous().to(device)\n",
    "\n",
    "    if datatype.lower() == 'binary':\n",
    "        ydata = torch.tensor(of_bi[i][0], dtype=torch.float, device=device).view(1, -1)\n",
    "    if datatype.lower() == 'regression':\n",
    "        ydata = torch.tensor(of_reg[i], dtype=torch.float, device=device).view(1, -1)\n",
    "    if datatype.lower() == 'multiclass':\n",
    "        #do argmax\n",
    "        ydata = torch.tensor(np.argmax(of_mc[i][0]), dtype=torch.float, device=device).view(1, -1)\n",
    "        # ydata = torch.tensor(of_mc[i][0], dtype=torch.int, device=device).view(1, -1)\n",
    "    # Fill Data object, 1 Data object -> 1 graph\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_iw, edge_attr=f_totw, y=ydata, edge_mask=e_mask_post, idx=index)\n",
    "    index+=1\n",
    "    if ydata == 0:\n",
    "        ydata_cf = torch.tensor(1, dtype=torch.int, device=device).view(-1)\n",
    "    else:\n",
    "        ydata_cf = torch.tensor(-1, dtype=torch.int, device=device).view(-1)\n",
    "    data.y_cf = ydata_cf\n",
    "\n",
    "\n",
    "    \n",
    "    adj = from_edge_index_to_adj(data.edge_index, None, data.num_nodes)\n",
    "    adj_list.append(adj)\n",
    "    max_num_nodes = max(max_num_nodes, data.num_nodes)\n",
    "    # append Data object to datalist\n",
    "    data_list.append(data)\n",
    "    if pre_filter is not None and not pre_filter(data):\n",
    "        continue\n",
    "\n",
    "    if pre_transform is not None:\n",
    "        data = pre_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_list = padded_datalist(data_list, adj_list, max_num_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automático \n",
    "\n",
    "Lo hacemos con la librería adecuada - InMemoryDataset es una clase proporcionada por PyTorch Geometric, una biblioteca diseñada para trabajar con datos de grafos en PyTorch. Esta clase es una subclase de torch_geometric.data.Dataset y está diseñada para manejar conjuntos de datos de grafos que se pueden cargar completamente en la memoria RAM.\n",
    "\n",
    "El código correspondiente a la clase InMemoryDataset viene proporcionado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from dataset.powergrid import PowerGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_dataset(dataset_root, **params):\n",
    "\n",
    "    dataset_name = params[\"dataset_name\"]\n",
    "    datatype = params[\"datatype\"]\n",
    "    print(f\"Loading {dataset_name} dataset...\")\n",
    "\n",
    "    if dataset_name.lower() in list(PowerGrid.names.keys()):\n",
    "        return PowerGrid(root=dataset_root, name=dataset_name, datatype=datatype)\n",
    "    \n",
    "    # NO VAMOS A USAR DATASETS SINTÉTICOS\n",
    "    #elif dataset_name.lower() in list(SynGraphDataset.names.keys()):\n",
    "    #   dataset = SynGraphDataset(root=dataset_root, name=dataset_name, **kwargs)\n",
    "    #   return dataset\n",
    "    else:\n",
    "        raise ValueError(f\"{dataset_name} is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "CKPT_ROOT = \"/home/TFM/code/extras/\"\n",
    "\n",
    "DATA_DIR = \"/home/dataset/\"\n",
    "MODEL_DIR = CKPT_ROOT + \"model/\"\n",
    "LOG_DIR = CKPT_ROOT + \"logs/\"\n",
    "RESULT_DIR = CKPT_ROOT + \"results/\"\n",
    "MASK_DIR = CKPT_ROOT + \"mask/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    \"dataset_name\": \"ieee24\",\n",
    "    \"random_seed\": 0,\n",
    "    \"datatype\": \"binary\",\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.15,\n",
    "    \"test_ratio\": 0.1\n",
    "}\n",
    "\n",
    "args = {\n",
    "    'data_save_dir': DATA_DIR,\n",
    "    'dest': '/home/TFM/',\n",
    "    'logs_save_dir': LOG_DIR,\n",
    "    'mask_save_dir': MASK_DIR,\n",
    "    'model_save_dir': MODEL_DIR,\n",
    "    'result_save_dir': RESULT_DIR,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ieee24 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = get_dataset(args['data_save_dir'], **dataset_params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PowerGrid(12900)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
