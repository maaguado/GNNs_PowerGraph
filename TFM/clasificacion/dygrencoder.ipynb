{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentación - DyGrEncoder\n",
    "\n",
    "\n",
    "\n",
    "## 1. Obtención de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "sns.set_palette(\"coolwarm_r\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import GCNConv\n",
    "import itertools\n",
    "import os, sys\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "sys.path.insert(1, \"/\".join(path.split(\"/\")[0:-1]))\n",
    "\n",
    "from utils import powergrid\n",
    "\n",
    "\n",
    "from utils import pygt_loader\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable):\n",
    "        return iterable\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from utils.models import DyGrEncoderModel\n",
    "from utils.trainer import  TrainerDryGrEncoder\n",
    "from utils.utils_graph import *\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.models\n",
    "utils.models = reload(utils.models)\n",
    "from utils.models import MPNNLSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_path = \"/home/TFM/code_dataset2/datos/Natural Oscillation\"\n",
    "folder_path = \"/Users/maguado/Documents/UGR/Master/TFM/datos_2/Natural Oscillation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n",
      "Processing:  row_307\n",
      "Node:  0  not included, including...\n",
      "Node:  1  not included, including...\n",
      "Node:  2  not included, including...\n",
      "Node:  3  not included, including...\n",
      "Node:  4  not included, including...\n",
      "Node:  5  not included, including...\n",
      "Node:  6  not included, including...\n",
      "Node:  7  not included, including...\n",
      "Node:  8  not included, including...\n",
      "Node:  9  not included, including...\n",
      "Node:  10  not included, including...\n",
      "Node:  11  not included, including...\n",
      "Node:  12  not included, including...\n",
      "Node:  13  not included, including...\n",
      "Node:  14  not included, including...\n",
      "Node:  15  not included, including...\n",
      "Node:  16  not included, including...\n",
      "Node:  17  not included, including...\n",
      "Node:  18  not included, including...\n",
      "Node:  19  not included, including...\n",
      "Node:  20  not included, including...\n",
      "Node:  21  not included, including...\n",
      "Node:  22  not included, including...\n",
      "Processing:  row_135\n",
      "Processing:  row_75\n",
      "Processing:  row_338\n",
      "Processing:  row_81\n",
      "Processing:  row_132\n",
      "Processing:  row_300\n",
      "Processing:  row_86\n",
      "Processing:  row_72\n",
      "Processing:  row_104\n",
      "Processing:  row_336\n",
      "Processing:  row_309\n",
      "Processing:  row_44\n",
      "Processing:  row_331\n",
      "Processing:  row_88\n",
      "Processing:  row_103\n",
      "Processing:  row_43\n",
      "Processing:  row_17\n",
      "Processing:  row_168\n",
      "Processing:  row_28\n",
      "Processing:  row_391\n",
      "Processing:  row_157\n",
      "Processing:  row_365\n",
      "Processing:  row_533\n",
      "Processing:  row_10\n",
      "Processing:  row_534\n",
      "Processing:  row_362\n",
      "Processing:  row_150\n",
      "Processing:  row_396\n",
      "Processing:  row_159\n",
      "Processing:  row_26\n",
      "Processing:  row_354\n",
      "Processing:  row_166\n",
      "Processing:  row_502\n",
      "Processing:  row_19\n",
      "Processing:  row_192\n",
      "Processing:  row_21\n",
      "Processing:  row_398\n",
      "Processing:  row_195\n",
      "Processing:  row_505\n",
      "Processing:  row_161\n",
      "Processing:  row_353\n",
      "Processing:  row_102\n",
      "Processing:  row_330\n",
      "Processing:  row_89\n",
      "Processing:  row_42\n",
      "Processing:  row_337\n",
      "Processing:  row_105\n",
      "Processing:  row_45\n",
      "Processing:  row_308\n",
      "Processing:  row_301\n",
      "Processing:  row_133\n",
      "Processing:  row_73\n",
      "Processing:  row_87\n",
      "Processing:  row_550\n",
      "Processing:  row_134\n",
      "Processing:  row_306\n",
      "Processing:  row_339\n",
      "Processing:  row_80\n",
      "Processing:  row_74\n",
      "Processing:  row_20\n",
      "Processing:  row_399\n",
      "Processing:  row_504\n",
      "Processing:  row_352\n",
      "Processing:  row_160\n",
      "Processing:  row_194\n",
      "Processing:  row_27\n",
      "Processing:  row_158\n",
      "Processing:  row_193\n",
      "Processing:  row_18\n",
      "Processing:  row_167\n",
      "Processing:  row_355\n",
      "Processing:  row_503\n",
      "Processing:  row_11\n",
      "Processing:  row_397\n",
      "Processing:  row_535\n",
      "Processing:  row_151\n",
      "Processing:  row_363\n",
      "Processing:  row_169\n",
      "Processing:  row_16\n",
      "Processing:  row_364\n",
      "Processing:  row_156\n",
      "Processing:  row_532\n",
      "Processing:  row_29\n",
      "Processing:  row_390\n",
      "Processing:  row_440\n",
      "Processing:  row_216\n",
      "Processing:  row_229\n",
      "Processing:  row_211\n",
      "Processing:  row_447\n",
      "Processing:  row_478\n",
      "Processing:  row_471\n",
      "Processing:  row_227\n",
      "Processing:  row_485\n",
      "Processing:  row_218\n",
      "Processing:  row_482\n",
      "Processing:  row_220\n",
      "Processing:  row_476\n",
      "Processing:  row_449\n",
      "Processing:  row_280\n",
      "Processing:  row_274\n",
      "Processing:  row_422\n",
      "Processing:  row_425\n",
      "Processing:  row_273\n",
      "Processing:  row_287\n",
      "Processing:  row_245\n",
      "Processing:  row_413\n",
      "Processing:  row_289\n",
      "Processing:  row_414\n",
      "Processing:  row_242\n",
      "Processing:  row_221\n",
      "Processing:  row_477\n",
      "Processing:  row_483\n",
      "Processing:  row_448\n",
      "Processing:  row_484\n",
      "Processing:  row_470\n",
      "Processing:  row_226\n",
      "Processing:  row_219\n",
      "Processing:  row_210\n",
      "Processing:  row_446\n",
      "Processing:  row_479\n",
      "Processing:  row_441\n",
      "Processing:  row_217\n",
      "Processing:  row_228\n",
      "Processing:  row_288\n",
      "Processing:  row_415\n",
      "Processing:  row_243\n",
      "Processing:  row_244\n",
      "Processing:  row_412\n",
      "Processing:  row_286\n",
      "Processing:  row_424\n",
      "Processing:  row_272\n",
      "Processing:  row_275\n",
      "Processing:  row_423\n",
      "Processing:  row_281\n",
      "Processing:  row_401\n",
      "Processing:  row_257\n",
      "Processing:  row_268\n",
      "Processing:  row_3\n",
      "Processing:  row_250\n",
      "Processing:  row_406\n",
      "Processing:  row_439\n",
      "Processing:  row_4\n",
      "Processing:  row_292\n",
      "Processing:  row_430\n",
      "Processing:  row_266\n",
      "Processing:  row_259\n",
      "Processing:  row_261\n",
      "Processing:  row_437\n",
      "Processing:  row_295\n",
      "Processing:  row_408\n",
      "Processing:  row_235\n",
      "Processing:  row_463\n",
      "Processing:  row_497\n",
      "Processing:  row_490\n",
      "Processing:  row_464\n",
      "Processing:  row_232\n",
      "Processing:  row_499\n",
      "Processing:  row_204\n",
      "Processing:  row_452\n",
      "Processing:  row_455\n",
      "Processing:  row_203\n",
      "Processing:  row_294\n",
      "Processing:  row_260\n",
      "Processing:  row_436\n",
      "Processing:  row_409\n",
      "Processing:  row_431\n",
      "Processing:  row_267\n",
      "Processing:  row_293\n",
      "Processing:  row_258\n",
      "Processing:  row_251\n",
      "Processing:  row_407\n",
      "Processing:  row_438\n",
      "Processing:  row_5\n",
      "Processing:  row_400\n",
      "Processing:  row_256\n",
      "Processing:  row_2\n",
      "Processing:  row_269\n",
      "Processing:  row_454\n",
      "Processing:  row_202\n",
      "Processing:  row_498\n",
      "Processing:  row_205\n",
      "Processing:  row_453\n",
      "Processing:  row_465\n",
      "Processing:  row_233\n",
      "Processing:  row_491\n",
      "Processing:  row_496\n",
      "Processing:  row_234\n",
      "Processing:  row_462\n",
      "Processing:  row_510\n",
      "Processing:  row_174\n",
      "Processing:  row_346\n",
      "Processing:  row_180\n",
      "Processing:  row_379\n",
      "Processing:  row_34\n",
      "Processing:  row_187\n",
      "Processing:  row_341\n",
      "Processing:  row_173\n",
      "Processing:  row_517\n",
      "Processing:  row_33\n",
      "Processing:  row_528\n",
      "Processing:  row_383\n",
      "Processing:  row_521\n",
      "Processing:  row_377\n",
      "Processing:  row_145\n",
      "Processing:  row_348\n",
      "Processing:  row_142\n",
      "Processing:  row_370\n",
      "Processing:  row_526\n",
      "Processing:  row_384\n",
      "Processing:  row_519\n",
      "Processing:  row_189\n",
      "Processing:  row_129\n",
      "Processing:  row_56\n",
      "Processing:  row_324\n",
      "Processing:  row_116\n",
      "Processing:  row_69\n",
      "Processing:  row_51\n",
      "Processing:  row_111\n",
      "Processing:  row_323\n",
      "Processing:  row_67\n",
      "Processing:  row_93\n",
      "Processing:  row_118\n",
      "Processing:  row_58\n",
      "Processing:  row_127\n",
      "Processing:  row_315\n",
      "Processing:  row_543\n",
      "Processing:  row_94\n",
      "Processing:  row_60\n",
      "Processing:  row_544\n",
      "Processing:  row_312\n",
      "Processing:  row_120\n",
      "Processing:  row_385\n",
      "Processing:  row_371\n",
      "Processing:  row_143\n",
      "Processing:  row_527\n",
      "Processing:  row_188\n",
      "Processing:  row_518\n",
      "Processing:  row_520\n",
      "Processing:  row_144\n",
      "Processing:  row_376\n",
      "Processing:  row_382\n",
      "Processing:  row_349\n",
      "Processing:  row_172\n",
      "Processing:  row_340\n",
      "Processing:  row_516\n",
      "Processing:  row_186\n",
      "Processing:  row_529\n",
      "Processing:  row_32\n",
      "Processing:  row_181\n",
      "Processing:  row_511\n",
      "Processing:  row_347\n",
      "Processing:  row_175\n",
      "Processing:  row_35\n",
      "Processing:  row_378\n",
      "Processing:  row_61\n",
      "Processing:  row_95\n",
      "Processing:  row_545\n",
      "Processing:  row_121\n",
      "Processing:  row_313\n",
      "Processing:  row_119\n",
      "Processing:  row_92\n",
      "Processing:  row_66\n",
      "Processing:  row_314\n",
      "Processing:  row_126\n",
      "Processing:  row_542\n",
      "Processing:  row_59\n",
      "Processing:  row_50\n",
      "Processing:  row_322\n",
      "Processing:  row_110\n",
      "Processing:  row_57\n",
      "Processing:  row_128\n",
      "Processing:  row_68\n",
      "Processing:  row_117\n",
      "Processing:  row_325\n",
      "Processing:  row_508\n",
      "Processing:  row_13\n",
      "Processing:  row_198\n",
      "Processing:  row_537\n",
      "Processing:  row_153\n",
      "Processing:  row_361\n",
      "Processing:  row_395\n",
      "Processing:  row_14\n",
      "Processing:  row_359\n",
      "Processing:  row_392\n",
      "Processing:  row_366\n",
      "Processing:  row_154\n",
      "Processing:  row_530\n",
      "Processing:  row_22\n",
      "Processing:  row_539\n",
      "Processing:  row_196\n",
      "Processing:  row_506\n",
      "Processing:  row_350\n",
      "Processing:  row_162\n",
      "Processing:  row_368\n",
      "Processing:  row_25\n",
      "Processing:  row_165\n",
      "Processing:  row_357\n",
      "Processing:  row_501\n",
      "Processing:  row_191\n",
      "Processing:  row_303\n",
      "Processing:  row_131\n",
      "Processing:  row_85\n",
      "Processing:  row_71\n",
      "Processing:  row_49\n",
      "Processing:  row_136\n",
      "Processing:  row_304\n",
      "Processing:  row_76\n",
      "Processing:  row_82\n",
      "Processing:  row_109\n",
      "Processing:  row_100\n",
      "Processing:  row_332\n",
      "Processing:  row_40\n",
      "Processing:  row_335\n",
      "Processing:  row_107\n",
      "Processing:  row_78\n",
      "Processing:  row_138\n",
      "Processing:  row_47\n",
      "Processing:  row_24\n",
      "Processing:  row_369\n",
      "Processing:  row_190\n",
      "Processing:  row_356\n",
      "Processing:  row_164\n",
      "Processing:  row_500\n",
      "Processing:  row_538\n",
      "Processing:  row_23\n",
      "Processing:  row_507\n",
      "Processing:  row_163\n",
      "Processing:  row_351\n",
      "Processing:  row_197\n",
      "Processing:  row_358\n",
      "Processing:  row_15\n",
      "Processing:  row_155\n",
      "Processing:  row_367\n",
      "Processing:  row_531\n",
      "Processing:  row_393\n",
      "Processing:  row_199\n",
      "Processing:  row_12\n",
      "Processing:  row_509\n",
      "Processing:  row_394\n",
      "Processing:  row_536\n",
      "Processing:  row_360\n",
      "Processing:  row_152\n",
      "Processing:  row_79\n",
      "Processing:  row_106\n",
      "Processing:  row_334\n",
      "Processing:  row_46\n",
      "Processing:  row_139\n",
      "Processing:  row_333\n",
      "Processing:  row_101\n",
      "Processing:  row_41\n",
      "Processing:  row_305\n",
      "Processing:  row_137\n",
      "Processing:  row_48\n",
      "Processing:  row_108\n",
      "Processing:  row_83\n",
      "Processing:  row_77\n",
      "Processing:  row_130\n",
      "Processing:  row_302\n",
      "Processing:  row_70\n",
      "Processing:  row_84\n",
      "Processing:  row_419\n",
      "Processing:  row_426\n",
      "Processing:  row_270\n",
      "Processing:  row_284\n",
      "Processing:  row_248\n",
      "Processing:  row_283\n",
      "Processing:  row_277\n",
      "Processing:  row_421\n",
      "Processing:  row_428\n",
      "Processing:  row_417\n",
      "Processing:  row_241\n",
      "Processing:  row_279\n",
      "Processing:  row_246\n",
      "Processing:  row_410\n",
      "Processing:  row_212\n",
      "Processing:  row_444\n",
      "Processing:  row_443\n",
      "Processing:  row_215\n",
      "Processing:  row_488\n",
      "Processing:  row_481\n",
      "Processing:  row_223\n",
      "Processing:  row_475\n",
      "Processing:  row_472\n",
      "Processing:  row_224\n",
      "Processing:  row_486\n",
      "Processing:  row_278\n",
      "Processing:  row_247\n",
      "Processing:  row_411\n",
      "Processing:  row_429\n",
      "Processing:  row_416\n",
      "Processing:  row_240\n",
      "Processing:  row_249\n",
      "Processing:  row_276\n",
      "Processing:  row_420\n",
      "Processing:  row_282\n",
      "Processing:  row_418\n",
      "Processing:  row_285\n",
      "Processing:  row_427\n",
      "Processing:  row_271\n",
      "Processing:  row_487\n",
      "Processing:  row_473\n",
      "Processing:  row_225\n",
      "Processing:  row_222\n",
      "Processing:  row_474\n",
      "Processing:  row_480\n",
      "Processing:  row_442\n",
      "Processing:  row_214\n",
      "Processing:  row_489\n",
      "Processing:  row_213\n",
      "Processing:  row_445\n",
      "Processing:  row_458\n",
      "Processing:  row_493\n",
      "Processing:  row_467\n",
      "Processing:  row_231\n",
      "Processing:  row_209\n",
      "Processing:  row_236\n",
      "Processing:  row_460\n",
      "Processing:  row_494\n",
      "Processing:  row_469\n",
      "Processing:  row_456\n",
      "Processing:  row_200\n",
      "Processing:  row_238\n",
      "Processing:  row_207\n",
      "Processing:  row_451\n",
      "Processing:  row_253\n",
      "Processing:  row_405\n",
      "Processing:  row_298\n",
      "Processing:  row_7\n",
      "Processing:  row_402\n",
      "Processing:  row_254\n",
      "Processing:  row_262\n",
      "Processing:  row_9\n",
      "Processing:  row_434\n",
      "Processing:  row_296\n",
      "Processing:  row_291\n",
      "Processing:  row_433\n",
      "Processing:  row_265\n",
      "Processing:  row_239\n",
      "Processing:  row_206\n",
      "Processing:  row_450\n",
      "Processing:  row_468\n",
      "Processing:  row_457\n",
      "Processing:  row_201\n",
      "Processing:  row_208\n",
      "Processing:  row_495\n",
      "Processing:  row_237\n",
      "Processing:  row_461\n",
      "Processing:  row_459\n",
      "Processing:  row_466\n",
      "Processing:  row_230\n",
      "Processing:  row_492\n",
      "Processing:  row_432\n",
      "Processing:  row_264\n",
      "Processing:  row_290\n",
      "Processing:  row_297\n",
      "Processing:  row_8\n",
      "Processing:  row_263\n",
      "Processing:  row_435\n",
      "Processing:  row_403\n",
      "Processing:  row_255\n",
      "Processing:  row_1\n",
      "Processing:  row_252\n",
      "Processing:  row_404\n",
      "Processing:  row_6\n",
      "Processing:  row_299\n",
      "Processing:  row_52\n",
      "Processing:  row_549\n",
      "Processing:  row_99\n",
      "Processing:  row_320\n",
      "Processing:  row_112\n",
      "Processing:  row_318\n",
      "Processing:  row_55\n",
      "Processing:  row_115\n",
      "Processing:  row_327\n",
      "Processing:  row_97\n",
      "Processing:  row_63\n",
      "Processing:  row_547\n",
      "Processing:  row_123\n",
      "Processing:  row_311\n",
      "Processing:  row_64\n",
      "Processing:  row_90\n",
      "Processing:  row_329\n",
      "Processing:  row_316\n",
      "Processing:  row_124\n",
      "Processing:  row_540\n",
      "Processing:  row_184\n",
      "Processing:  row_170\n",
      "Processing:  row_342\n",
      "Processing:  row_514\n",
      "Processing:  row_389\n",
      "Processing:  row_30\n",
      "Processing:  row_513\n",
      "Processing:  row_345\n",
      "Processing:  row_177\n",
      "Processing:  row_183\n",
      "Processing:  row_148\n",
      "Processing:  row_37\n",
      "Processing:  row_373\n",
      "Processing:  row_141\n",
      "Processing:  row_525\n",
      "Processing:  row_387\n",
      "Processing:  row_380\n",
      "Processing:  row_39\n",
      "Processing:  row_522\n",
      "Processing:  row_146\n",
      "Processing:  row_374\n",
      "Processing:  row_179\n",
      "Processing:  row_91\n",
      "Processing:  row_328\n",
      "Skipping  row_328\n",
      "Processing:  row_65\n",
      "Processing:  row_125\n",
      "Processing:  row_317\n",
      "Processing:  row_541\n",
      "Processing:  row_62\n",
      "Processing:  row_96\n",
      "Processing:  row_546\n",
      "Processing:  row_310\n",
      "Processing:  row_122\n",
      "Processing:  row_54\n",
      "Processing:  row_319\n",
      "Processing:  row_326\n",
      "Processing:  row_114\n",
      "Processing:  row_548\n",
      "Processing:  row_53\n",
      "Processing:  row_113\n",
      "Processing:  row_98\n",
      "Processing:  row_321\n",
      "Processing:  row_523\n",
      "Processing:  row_375\n",
      "Processing:  row_147\n",
      "Processing:  row_381\n",
      "Processing:  row_38\n",
      "Processing:  row_178\n",
      "Processing:  row_386\n",
      "Processing:  row_140\n",
      "Processing:  row_372\n",
      "Processing:  row_524\n",
      "Processing:  row_182\n",
      "Processing:  row_512\n",
      "Processing:  row_176\n",
      "Processing:  row_344\n",
      "Processing:  row_36\n",
      "Processing:  row_149\n",
      "Processing:  row_343\n",
      "Processing:  row_171\n",
      "Processing:  row_515\n",
      "Processing:  row_185\n",
      "Processing:  row_388\n",
      "Processing:  row_31\n",
      "Number of situations:  549\n",
      "Number of timestamps:  800\n",
      "Number of situations of the selected type:  549\n"
     ]
    }
   ],
   "source": [
    "loader = powergrid.PowerGridDatasetLoader(folder_path, problem=\"classification_type\")\n",
    "_,_,_ =loader.process()\n",
    "limit = 300\n",
    "dataset_full, situations_each = loader.get_dataset()\n",
    "target_names = loader.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares - entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_y_evaluar_modelos_dygrencoder(param_grid, dataset, dataloader_params, num_early_stop, num_epochs, problem=\"Classification\", name=None, target_names=None, device=torch.device(\"cpu\")):\n",
    "    resultados_list = []\n",
    "\n",
    "    # Variables para guardar el mejor modelo\n",
    "    mejor_loss_test = float('inf')\n",
    "    mejor_trainer = None\n",
    "    mejores_parametros = None\n",
    "    mejores_resultados = None\n",
    "\n",
    "    # Detalles del dataset\n",
    "    n_nodes = dataset.features[0].shape[0]\n",
    "    n_target = dataset.targets[0].shape[0]\n",
    "    n_features = dataset[0].x.shape[1]\n",
    "\n",
    "\n",
    "    for aggr, conv, lstm, out_lstm in tqdm(list(itertools.product(param_grid[\"aggr\"], param_grid[\"conv\"], param_grid[\"lstm\"],  param_grid['out_lstm']))):\n",
    "        \n",
    "        print(f\"Entrenando modelo con aggr={aggr}, conv={conv}, lstm={lstm},out_lstm={out_lstm}\")\n",
    "\n",
    "        model = DyGrEncoderModel(node_features=n_features, node_count=n_nodes,num_conv=conv, num_lstm=lstm, aggr=aggr,lstm_out =out_lstm, n_target=n_target, name=\"DyGrEncoder\", is_classification=True)\n",
    "        trainer = TrainerDryGrEncoder(model, dataset, device, f\"./results/{problem}\", dataloader_params, is_classification = True)\n",
    "\n",
    "        losses, eval_losses, accs, precisions, recalls, f1s = trainer.train(num_epochs=num_epochs, steps=50, num_early_stop=num_early_stop)\n",
    "        test_acc, test_precision, test_recall, test_f1, test_loss, preds, real = trainer.test()\n",
    "\n",
    "        results_intermedio = {\n",
    "            \"Aggr\": aggr,\n",
    "            \"Conv\": conv,\n",
    "            \"LSTM\": lstm,\n",
    "            \"LSTM_out\": out_lstm,\n",
    "            \"Loss_final\": losses[-1],  # Usando el último valor de la lista, si es consistente con tus datos\n",
    "            \"Accuracy_eval\": np.mean(accs),\n",
    "            \"Precision_eval\": np.mean(precisions),\n",
    "            \"Recall_eval\": np.mean(recalls),\n",
    "            \"F1_eval\": np.mean(f1s),\n",
    "            \"Loss_eval\": np.mean(eval_losses[-1]),  # Asumiendo que tienes evaluaciones periódicas como en regresión\n",
    "            \"Loss_tst\": np.mean(test_loss),\n",
    "            \"Accuracy_tst\": test_acc,\n",
    "            \"Precision_tst\": test_precision,\n",
    "            \"Recall_tst\": test_recall,\n",
    "            \"F1_tst\": test_f1\n",
    "        }\n",
    "        \n",
    "        resultados_list.append(results_intermedio)\n",
    "\n",
    "        # Actualizar el mejor modelo si es necesario\n",
    "        if np.mean(test_loss) < mejor_loss_test:\n",
    "            mejor_loss_test = np.mean(test_loss)\n",
    "            mejor_trainer = trainer\n",
    "            mejores_parametros = {'aggr': aggr, 'conv': conv, 'lstm': lstm, 'lstm_out': out_lstm}\n",
    "            mejores_resultados = results_intermedio\n",
    "\n",
    "        print(\"Parámetros: \", aggr, conv, lstm, out_lstm)\n",
    "        print(\"Resultados: \", resultados_list[-1])\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados_list)\n",
    "    return mejor_trainer, mejores_parametros, mejores_resultados, resultados_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucle rápido para ajustar y guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.models\n",
    "utils.models = reload(utils.models)\n",
    "from utils.models import DyGrEncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.trainer\n",
    "utils.trainer = reload(utils.trainer)\n",
    "from utils.trainer import TrainerDryGrEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con aggr=add, conv=1, lstm=1,out_lstm=800\n",
      "WARNING: The model is not batched but the dataloader is batched. Changing to not batched dataset.\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5094 | Eval Loss: 1.3422 | Accuracy: 0.6133 | Precision: 0.4379 | Recall: 0.4731 | F1-Score: 0.4513 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3520 | Eval Loss: 1.2909 | Accuracy: 0.6133 | Precision: 0.3408 | Recall: 0.4993 | F1-Score: 0.3994 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3080 | Eval Loss: 1.2959 | Accuracy: 0.6133 | Precision: 0.4894 | Recall: 0.5198 | F1-Score: 0.4489 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2761 | Eval Loss: 1.2997 | Accuracy: 0.6400 | Precision: 0.5623 | Recall: 0.5484 | F1-Score: 0.4821 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2699 | Eval Loss: 1.2944 | Accuracy: 0.5867 | Precision: 0.4264 | Recall: 0.4855 | F1-Score: 0.4485 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2565 | Eval Loss: 1.2896 | Accuracy: 0.5733 | Precision: 0.3864 | Recall: 0.4417 | F1-Score: 0.4054 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2374 | Eval Loss: 1.2884 | Accuracy: 0.6000 | Precision: 0.4197 | Recall: 0.4702 | F1-Score: 0.4371 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2345 | Eval Loss: 1.2885 | Accuracy: 0.6000 | Precision: 0.4237 | Recall: 0.4702 | F1-Score: 0.4405 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2230 | Eval Loss: 1.2977 | Accuracy: 0.5867 | Precision: 0.4160 | Recall: 0.4633 | F1-Score: 0.4325 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2181 | Eval Loss: 1.2943 | Accuracy: 0.6133 | Precision: 0.4314 | Recall: 0.4845 | F1-Score: 0.4548 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2277 | Eval Loss: 1.2762 | Accuracy: 0.6267 | Precision: 0.4320 | Recall: 0.5045 | F1-Score: 0.4441 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2259 | Eval Loss: 1.2815 | Accuracy: 0.6133 | Precision: 0.4402 | Recall: 0.4976 | F1-Score: 0.4595 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2064 | Eval Loss: 1.2747 | Accuracy: 0.6533 | Precision: 0.4778 | Recall: 0.5331 | F1-Score: 0.4980 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2069 | Eval Loss: 1.2903 | Accuracy: 0.6267 | Precision: 0.4452 | Recall: 0.5176 | F1-Score: 0.4726 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2219 | Eval Loss: 1.2994 | Accuracy: 0.6000 | Precision: 0.4295 | Recall: 0.5169 | F1-Score: 0.4413 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2214 | Eval Loss: 1.2885 | Accuracy: 0.6133 | Precision: 0.4674 | Recall: 0.5255 | F1-Score: 0.4804 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1963 | Eval Loss: 1.2712 | Accuracy: 0.6133 | Precision: 0.4448 | Recall: 0.4845 | F1-Score: 0.4596 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1847 | Eval Loss: 1.2774 | Accuracy: 0.6000 | Precision: 0.4379 | Recall: 0.4776 | F1-Score: 0.4405 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1828 | Eval Loss: 1.2864 | Accuracy: 0.5867 | Precision: 0.4450 | Recall: 0.4912 | F1-Score: 0.4605 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1702 | Eval Loss: 1.2869 | Accuracy: 0.6000 | Precision: 0.5104 | Recall: 0.5212 | F1-Score: 0.5093 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1547 | Eval Loss: 1.2676 | Accuracy: 0.6400 | Precision: 0.6608 | Recall: 0.5238 | F1-Score: 0.5214 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1421 | Eval Loss: 1.2906 | Accuracy: 0.6000 | Precision: 0.5081 | Recall: 0.4883 | F1-Score: 0.4714 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1436 | Eval Loss: 1.2855 | Accuracy: 0.6000 | Precision: 0.5124 | Recall: 0.5212 | F1-Score: 0.5128 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1361 | Eval Loss: 1.2638 | Accuracy: 0.6667 | Precision: 0.5974 | Recall: 0.5812 | F1-Score: 0.5808 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1200 | Eval Loss: 1.2720 | Accuracy: 0.6000 | Precision: 0.5038 | Recall: 0.4810 | F1-Score: 0.4713 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1284 | Eval Loss: 1.2877 | Accuracy: 0.6000 | Precision: 0.5277 | Recall: 0.5269 | F1-Score: 0.5138 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1095 | Eval Loss: 1.2583 | Accuracy: 0.6533 | Precision: 0.5600 | Recall: 0.5669 | F1-Score: 0.5613 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0964 | Eval Loss: 1.2678 | Accuracy: 0.6000 | Precision: 0.5016 | Recall: 0.5015 | F1-Score: 0.4798 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0829 | Eval Loss: 1.2587 | Accuracy: 0.6133 | Precision: 0.5290 | Recall: 0.5231 | F1-Score: 0.5082 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0718 | Eval Loss: 1.2472 | Accuracy: 0.6400 | Precision: 0.5481 | Recall: 0.5574 | F1-Score: 0.5346 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0658 | Eval Loss: 1.2539 | Accuracy: 0.6133 | Precision: 0.4775 | Recall: 0.5124 | F1-Score: 0.4814 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0600 | Eval Loss: 1.2488 | Accuracy: 0.6267 | Precision: 0.5332 | Recall: 0.5243 | F1-Score: 0.5153 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0529 | Eval Loss: 1.2506 | Accuracy: 0.6533 | Precision: 0.5948 | Recall: 0.5924 | F1-Score: 0.5866 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0474 | Eval Loss: 1.2625 | Accuracy: 0.6800 | Precision: 0.6143 | Recall: 0.6103 | F1-Score: 0.6097 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0642 | Eval Loss: 1.2311 | Accuracy: 0.6667 | Precision: 0.4913 | Recall: 0.5531 | F1-Score: 0.5139 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0738 | Eval Loss: 1.2587 | Accuracy: 0.6267 | Precision: 0.4961 | Recall: 0.5398 | F1-Score: 0.5036 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0618 | Eval Loss: 1.2767 | Accuracy: 0.6400 | Precision: 0.5583 | Recall: 0.5722 | F1-Score: 0.5501 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0572 | Eval Loss: 1.2357 | Accuracy: 0.6800 | Precision: 0.6060 | Recall: 0.5798 | F1-Score: 0.5653 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0504 | Eval Loss: 1.2608 | Accuracy: 0.6133 | Precision: 0.4402 | Recall: 0.5050 | F1-Score: 0.4669 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0717 | Eval Loss: 1.2428 | Accuracy: 0.6667 | Precision: 0.5613 | Recall: 0.5524 | F1-Score: 0.5459 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0666 | Eval Loss: 1.2534 | Accuracy: 0.6400 | Precision: 0.5531 | Recall: 0.5493 | F1-Score: 0.5461 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0606 | Eval Loss: 1.2588 | Accuracy: 0.6267 | Precision: 0.5329 | Recall: 0.5038 | F1-Score: 0.5071 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0755 | Eval Loss: 1.2405 | Accuracy: 0.6800 | Precision: 0.7206 | Recall: 0.5781 | F1-Score: 0.5625 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0666 | Eval Loss: 1.2568 | Accuracy: 0.6533 | Precision: 0.5961 | Recall: 0.5717 | F1-Score: 0.5489 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0467 | Eval Loss: 1.2490 | Accuracy: 0.6400 | Precision: 0.5603 | Recall: 0.5312 | F1-Score: 0.5183 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0493 | Eval Loss: 1.2329 | Accuracy: 0.6800 | Precision: 0.5851 | Recall: 0.5667 | F1-Score: 0.5647 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0567 | Eval Loss: 1.2758 | Accuracy: 0.5733 | Precision: 0.4763 | Recall: 0.4557 | F1-Score: 0.4427 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0517 | Eval Loss: 1.2578 | Accuracy: 0.6267 | Precision: 0.5759 | Recall: 0.5317 | F1-Score: 0.5233 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0364 | Eval Loss: 1.2541 | Accuracy: 0.6267 | Precision: 0.4594 | Recall: 0.5193 | F1-Score: 0.4854 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0372 | Eval Loss: 1.2398 | Accuracy: 0.6667 | Precision: 0.5912 | Recall: 0.5722 | F1-Score: 0.5752 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0243 | Eval Loss: 1.2345 | Accuracy: 0.6667 | Precision: 0.5211 | Recall: 0.5622 | F1-Score: 0.5312 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0163 | Eval Loss: 1.2553 | Accuracy: 0.6533 | Precision: 0.5629 | Recall: 0.5586 | F1-Score: 0.5478 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [05:27<2:05:28, 327.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        12\n",
      "           1       0.40      0.67      0.50        15\n",
      "           2       0.27      0.33      0.30         9\n",
      "           3       0.25      0.05      0.09        19\n",
      "           4       0.76      0.90      0.83        29\n",
      "\n",
      "    accuracy                           0.55        84\n",
      "   macro avg       0.46      0.49      0.45        84\n",
      "weighted avg       0.51      0.55      0.50        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.329544, test accuracy: 0.5476, test precision: 0.4575, test recall: 0.4898, test F1-score: 0.4516\n",
      "Parámetros:  add 1 1 800\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 1, 'LSTM': 1, 'LSTM_out': 800, 'Loss_final': 1.0163146257400513, 'Accuracy_eval': 0.6266666666666667, 'Precision_eval': 0.5081028438121338, 'Recall_eval': 0.523841890867753, 'F1_eval': 0.4983369168066949, 'Loss_eval': 1.2552554607391357, 'Loss_tst': 1.3295443058013916, 'Accuracy_tst': 0.5476190476190477, 'Precision_tst': 0.4574866310160427, 'Recall_tst': 0.4898366606170598, 'F1_tst': 0.45156157851810025}\n",
      "Entrenando modelo con aggr=add, conv=1, lstm=1,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5079 | Eval Loss: 1.3359 | Accuracy: 0.6267 | Precision: 0.5352 | Recall: 0.4857 | F1-Score: 0.4342 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3486 | Eval Loss: 1.2880 | Accuracy: 0.6133 | Precision: 0.3427 | Recall: 0.4993 | F1-Score: 0.3990 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3039 | Eval Loss: 1.2929 | Accuracy: 0.6400 | Precision: 0.5139 | Recall: 0.5427 | F1-Score: 0.4882 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2799 | Eval Loss: 1.3008 | Accuracy: 0.6000 | Precision: 0.4823 | Recall: 0.5129 | F1-Score: 0.4419 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2688 | Eval Loss: 1.2897 | Accuracy: 0.6133 | Precision: 0.4580 | Recall: 0.5067 | F1-Score: 0.4619 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2639 | Eval Loss: 1.2735 | Accuracy: 0.6267 | Precision: 0.4433 | Recall: 0.4988 | F1-Score: 0.4653 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2422 | Eval Loss: 1.2982 | Accuracy: 0.5600 | Precision: 0.3931 | Recall: 0.4422 | F1-Score: 0.4058 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2305 | Eval Loss: 1.2751 | Accuracy: 0.6133 | Precision: 0.4244 | Recall: 0.4919 | F1-Score: 0.4464 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2296 | Eval Loss: 1.2907 | Accuracy: 0.6000 | Precision: 0.4277 | Recall: 0.4776 | F1-Score: 0.4462 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2169 | Eval Loss: 1.3032 | Accuracy: 0.6000 | Precision: 0.4241 | Recall: 0.4702 | F1-Score: 0.4354 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2063 | Eval Loss: 1.2818 | Accuracy: 0.6267 | Precision: 0.4487 | Recall: 0.4988 | F1-Score: 0.4698 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2025 | Eval Loss: 1.2966 | Accuracy: 0.6000 | Precision: 0.4292 | Recall: 0.4907 | F1-Score: 0.4522 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2098 | Eval Loss: 1.2762 | Accuracy: 0.6267 | Precision: 0.4518 | Recall: 0.5119 | F1-Score: 0.4583 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2101 | Eval Loss: 1.2695 | Accuracy: 0.6133 | Precision: 0.4370 | Recall: 0.4845 | F1-Score: 0.4573 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1904 | Eval Loss: 1.2832 | Accuracy: 0.6133 | Precision: 0.6347 | Recall: 0.4952 | F1-Score: 0.4864 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1890 | Eval Loss: 1.2885 | Accuracy: 0.6000 | Precision: 0.4287 | Recall: 0.4833 | F1-Score: 0.4474 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1833 | Eval Loss: 1.2855 | Accuracy: 0.6133 | Precision: 0.5334 | Recall: 0.5338 | F1-Score: 0.5214 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1765 | Eval Loss: 1.3010 | Accuracy: 0.6000 | Precision: 0.4213 | Recall: 0.4907 | F1-Score: 0.4481 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1694 | Eval Loss: 1.3003 | Accuracy: 0.6133 | Precision: 0.6262 | Recall: 0.5388 | F1-Score: 0.5386 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1691 | Eval Loss: 1.2890 | Accuracy: 0.6133 | Precision: 0.6581 | Recall: 0.5305 | F1-Score: 0.5153 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1526 | Eval Loss: 1.2765 | Accuracy: 0.6267 | Precision: 0.6370 | Recall: 0.5202 | F1-Score: 0.5162 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1408 | Eval Loss: 1.2571 | Accuracy: 0.6400 | Precision: 0.5693 | Recall: 0.5238 | F1-Score: 0.5116 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1476 | Eval Loss: 1.2531 | Accuracy: 0.6533 | Precision: 0.5866 | Recall: 0.5643 | F1-Score: 0.5405 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1357 | Eval Loss: 1.2703 | Accuracy: 0.6267 | Precision: 0.5502 | Recall: 0.5357 | F1-Score: 0.5067 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1244 | Eval Loss: 1.2833 | Accuracy: 0.5733 | Precision: 0.4640 | Recall: 0.4746 | F1-Score: 0.4610 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1110 | Eval Loss: 1.2878 | Accuracy: 0.6133 | Precision: 0.5040 | Recall: 0.4895 | F1-Score: 0.4817 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1076 | Eval Loss: 1.2643 | Accuracy: 0.6267 | Precision: 0.4842 | Recall: 0.4988 | F1-Score: 0.4693 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1128 | Eval Loss: 1.2636 | Accuracy: 0.6667 | Precision: 0.5621 | Recall: 0.5712 | F1-Score: 0.5499 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1009 | Eval Loss: 1.2955 | Accuracy: 0.5867 | Precision: 0.5257 | Recall: 0.5150 | F1-Score: 0.4788 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1148 | Eval Loss: 1.3056 | Accuracy: 0.5600 | Precision: 0.4893 | Recall: 0.5063 | F1-Score: 0.4862 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1160 | Eval Loss: 1.2687 | Accuracy: 0.6667 | Precision: 0.5947 | Recall: 0.5943 | F1-Score: 0.5891 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1036 | Eval Loss: 1.2539 | Accuracy: 0.6533 | Precision: 0.6306 | Recall: 0.5538 | F1-Score: 0.5685 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0947 | Eval Loss: 1.2598 | Accuracy: 0.6267 | Precision: 0.5535 | Recall: 0.5300 | F1-Score: 0.5137 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0796 | Eval Loss: 1.2599 | Accuracy: 0.6267 | Precision: 0.5144 | Recall: 0.5300 | F1-Score: 0.5115 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0660 | Eval Loss: 1.2435 | Accuracy: 0.6267 | Precision: 0.5348 | Recall: 0.5219 | F1-Score: 0.5241 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0656 | Eval Loss: 1.2541 | Accuracy: 0.6267 | Precision: 0.5077 | Recall: 0.5112 | F1-Score: 0.5071 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0577 | Eval Loss: 1.2555 | Accuracy: 0.6667 | Precision: 0.5904 | Recall: 0.5862 | F1-Score: 0.5861 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0519 | Eval Loss: 1.2700 | Accuracy: 0.6400 | Precision: 0.5925 | Recall: 0.5526 | F1-Score: 0.5462 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0735 | Eval Loss: 1.2642 | Accuracy: 0.6267 | Precision: 0.4737 | Recall: 0.5176 | F1-Score: 0.4655 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0816 | Eval Loss: 1.2664 | Accuracy: 0.6400 | Precision: 0.5872 | Recall: 0.5631 | F1-Score: 0.5305 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0676 | Eval Loss: 1.2832 | Accuracy: 0.6267 | Precision: 0.5683 | Recall: 0.5629 | F1-Score: 0.5499 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0664 | Eval Loss: 1.2863 | Accuracy: 0.6400 | Precision: 0.5545 | Recall: 0.5650 | F1-Score: 0.5552 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0817 | Eval Loss: 1.2511 | Accuracy: 0.6400 | Precision: 0.6525 | Recall: 0.5369 | F1-Score: 0.5159 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0748 | Eval Loss: 1.2673 | Accuracy: 0.6133 | Precision: 0.4425 | Recall: 0.5050 | F1-Score: 0.4654 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0647 | Eval Loss: 1.2552 | Accuracy: 0.6400 | Precision: 0.5396 | Recall: 0.5362 | F1-Score: 0.5355 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0567 | Eval Loss: 1.2665 | Accuracy: 0.6133 | Precision: 0.5404 | Recall: 0.5150 | F1-Score: 0.5077 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0603 | Eval Loss: 1.2561 | Accuracy: 0.6267 | Precision: 0.4798 | Recall: 0.4988 | F1-Score: 0.4666 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0640 | Eval Loss: 1.2640 | Accuracy: 0.6267 | Precision: 0.6692 | Recall: 0.5505 | F1-Score: 0.5272 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0523 | Eval Loss: 1.2863 | Accuracy: 0.6133 | Precision: 0.5434 | Recall: 0.5593 | F1-Score: 0.5429 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0534 | Eval Loss: 1.2960 | Accuracy: 0.6000 | Precision: 0.6158 | Recall: 0.5146 | F1-Score: 0.4858 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0665 | Eval Loss: 1.2643 | Accuracy: 0.6133 | Precision: 0.5752 | Recall: 0.5446 | F1-Score: 0.5336 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0691 | Eval Loss: 1.2557 | Accuracy: 0.6533 | Precision: 0.5990 | Recall: 0.5850 | F1-Score: 0.5814 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [11:26<2:06:50, 345.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48        12\n",
      "           1       0.36      0.53      0.43        15\n",
      "           2       0.30      0.33      0.32         9\n",
      "           3       0.36      0.21      0.27        19\n",
      "           4       0.72      0.79      0.75        29\n",
      "\n",
      "    accuracy                           0.51        84\n",
      "   macro avg       0.46      0.46      0.45        84\n",
      "weighted avg       0.51      0.51      0.50        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.350512, test accuracy: 0.5119, test precision: 0.4603, test recall: 0.4574, test F1-score: 0.4490\n",
      "Parámetros:  add 1 1 850\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 1, 'LSTM': 1, 'LSTM_out': 850, 'Loss_final': 1.069093942642212, 'Accuracy_eval': 0.6210256410256411, 'Precision_eval': 0.5239558000714588, 'Recall_eval': 0.5215574081091323, 'F1_eval': 0.49673172663043325, 'Loss_eval': 1.255673885345459, 'Loss_tst': 1.350512146949768, 'Accuracy_tst': 0.5119047619047619, 'Precision_tst': 0.46031565656565654, 'Recall_tst': 0.45739261947973375, 'F1_tst': 0.4490354819259047}\n",
      "Entrenando modelo con aggr=add, conv=1, lstm=1,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5095 | Eval Loss: 1.3378 | Accuracy: 0.5600 | Precision: 0.3013 | Recall: 0.4233 | F1-Score: 0.3489 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3535 | Eval Loss: 1.2865 | Accuracy: 0.6133 | Precision: 0.3420 | Recall: 0.4993 | F1-Score: 0.3988 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3102 | Eval Loss: 1.2964 | Accuracy: 0.5600 | Precision: 0.3946 | Recall: 0.4496 | F1-Score: 0.4092 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2800 | Eval Loss: 1.2953 | Accuracy: 0.6133 | Precision: 0.4894 | Recall: 0.5198 | F1-Score: 0.4489 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2602 | Eval Loss: 1.2833 | Accuracy: 0.6400 | Precision: 0.5187 | Recall: 0.5541 | F1-Score: 0.4825 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2654 | Eval Loss: 1.3101 | Accuracy: 0.5733 | Precision: 0.3968 | Recall: 0.4786 | F1-Score: 0.4018 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2601 | Eval Loss: 1.2842 | Accuracy: 0.6133 | Precision: 0.4394 | Recall: 0.4919 | F1-Score: 0.4574 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2382 | Eval Loss: 1.2899 | Accuracy: 0.6000 | Precision: 0.4241 | Recall: 0.4702 | F1-Score: 0.4354 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2256 | Eval Loss: 1.2905 | Accuracy: 0.6000 | Precision: 0.4325 | Recall: 0.4776 | F1-Score: 0.4447 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2154 | Eval Loss: 1.3059 | Accuracy: 0.5733 | Precision: 0.4138 | Recall: 0.4696 | F1-Score: 0.4275 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2255 | Eval Loss: 1.2976 | Accuracy: 0.5733 | Precision: 0.3257 | Recall: 0.4565 | F1-Score: 0.3755 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2447 | Eval Loss: 1.3044 | Accuracy: 0.5733 | Precision: 0.4092 | Recall: 0.4565 | F1-Score: 0.4248 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2099 | Eval Loss: 1.2970 | Accuracy: 0.6000 | Precision: 0.4274 | Recall: 0.4702 | F1-Score: 0.4394 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2048 | Eval Loss: 1.2745 | Accuracy: 0.6400 | Precision: 0.4601 | Recall: 0.5131 | F1-Score: 0.4834 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1964 | Eval Loss: 1.2942 | Accuracy: 0.6133 | Precision: 0.4399 | Recall: 0.5181 | F1-Score: 0.4668 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2071 | Eval Loss: 1.3007 | Accuracy: 0.5867 | Precision: 0.4149 | Recall: 0.4707 | F1-Score: 0.4258 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2141 | Eval Loss: 1.2734 | Accuracy: 0.6267 | Precision: 0.4487 | Recall: 0.4988 | F1-Score: 0.4698 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1929 | Eval Loss: 1.2881 | Accuracy: 0.5867 | Precision: 0.4198 | Recall: 0.4633 | F1-Score: 0.4216 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1854 | Eval Loss: 1.2924 | Accuracy: 0.6000 | Precision: 0.4404 | Recall: 0.5096 | F1-Score: 0.4540 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2021 | Eval Loss: 1.2828 | Accuracy: 0.6267 | Precision: 0.4596 | Recall: 0.5062 | F1-Score: 0.4643 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2043 | Eval Loss: 1.2850 | Accuracy: 0.6000 | Precision: 0.4297 | Recall: 0.4702 | F1-Score: 0.4310 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1857 | Eval Loss: 1.2805 | Accuracy: 0.6400 | Precision: 0.4976 | Recall: 0.5598 | F1-Score: 0.5075 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1891 | Eval Loss: 1.2711 | Accuracy: 0.6000 | Precision: 0.4055 | Recall: 0.4702 | F1-Score: 0.4292 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1863 | Eval Loss: 1.2810 | Accuracy: 0.6133 | Precision: 0.4553 | Recall: 0.4845 | F1-Score: 0.4426 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1765 | Eval Loss: 1.2669 | Accuracy: 0.6400 | Precision: 0.4620 | Recall: 0.5450 | F1-Score: 0.4874 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1677 | Eval Loss: 1.2389 | Accuracy: 0.6800 | Precision: 0.6283 | Recall: 0.5955 | F1-Score: 0.6013 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1589 | Eval Loss: 1.2649 | Accuracy: 0.6400 | Precision: 0.5022 | Recall: 0.5393 | F1-Score: 0.4937 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1545 | Eval Loss: 1.2849 | Accuracy: 0.5867 | Precision: 0.4316 | Recall: 0.4838 | F1-Score: 0.4463 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1420 | Eval Loss: 1.2693 | Accuracy: 0.6133 | Precision: 0.4724 | Recall: 0.4919 | F1-Score: 0.4612 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1247 | Eval Loss: 1.2826 | Accuracy: 0.5867 | Precision: 0.4607 | Recall: 0.4781 | F1-Score: 0.4613 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1190 | Eval Loss: 1.2657 | Accuracy: 0.6267 | Precision: 0.5490 | Recall: 0.5531 | F1-Score: 0.5467 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1104 | Eval Loss: 1.2577 | Accuracy: 0.6533 | Precision: 0.5112 | Recall: 0.5479 | F1-Score: 0.5142 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0912 | Eval Loss: 1.2446 | Accuracy: 0.6533 | Precision: 0.5994 | Recall: 0.5562 | F1-Score: 0.5521 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0931 | Eval Loss: 1.2391 | Accuracy: 0.6667 | Precision: 0.6053 | Recall: 0.5655 | F1-Score: 0.5555 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0882 | Eval Loss: 1.2395 | Accuracy: 0.6533 | Precision: 0.5763 | Recall: 0.5512 | F1-Score: 0.5362 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1070 | Eval Loss: 1.2752 | Accuracy: 0.6267 | Precision: 0.5817 | Recall: 0.5579 | F1-Score: 0.5314 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1063 | Eval Loss: 1.2605 | Accuracy: 0.6667 | Precision: 0.6213 | Recall: 0.6067 | F1-Score: 0.6045 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1008 | Eval Loss: 1.2499 | Accuracy: 0.6667 | Precision: 0.5094 | Recall: 0.5474 | F1-Score: 0.5126 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0973 | Eval Loss: 1.2365 | Accuracy: 0.6933 | Precision: 0.6141 | Recall: 0.6072 | F1-Score: 0.5886 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0754 | Eval Loss: 1.2753 | Accuracy: 0.6133 | Precision: 0.5180 | Recall: 0.5174 | F1-Score: 0.5066 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0730 | Eval Loss: 1.2402 | Accuracy: 0.6533 | Precision: 0.5725 | Recall: 0.5669 | F1-Score: 0.5679 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0758 | Eval Loss: 1.2723 | Accuracy: 0.6133 | Precision: 0.5352 | Recall: 0.5224 | F1-Score: 0.5223 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0596 | Eval Loss: 1.2789 | Accuracy: 0.6133 | Precision: 0.5350 | Recall: 0.5174 | F1-Score: 0.5024 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0535 | Eval Loss: 1.2743 | Accuracy: 0.6133 | Precision: 0.5423 | Recall: 0.5248 | F1-Score: 0.5143 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0524 | Eval Loss: 1.2832 | Accuracy: 0.6133 | Precision: 0.5648 | Recall: 0.5362 | F1-Score: 0.5090 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0561 | Eval Loss: 1.3039 | Accuracy: 0.5867 | Precision: 0.5238 | Recall: 0.5143 | F1-Score: 0.5036 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0581 | Eval Loss: 1.2508 | Accuracy: 0.6533 | Precision: 0.5742 | Recall: 0.5381 | F1-Score: 0.5307 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0516 | Eval Loss: 1.2891 | Accuracy: 0.6267 | Precision: 0.4861 | Recall: 0.5267 | F1-Score: 0.4923 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0443 | Eval Loss: 1.2684 | Accuracy: 0.6400 | Precision: 0.5741 | Recall: 0.5567 | F1-Score: 0.5533 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0384 | Eval Loss: 1.2568 | Accuracy: 0.6400 | Precision: 0.5575 | Recall: 0.5526 | F1-Score: 0.5507 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0482 | Eval Loss: 1.2653 | Accuracy: 0.6400 | Precision: 0.5871 | Recall: 0.5517 | F1-Score: 0.5357 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0326 | Eval Loss: 1.2602 | Accuracy: 0.6400 | Precision: 0.5871 | Recall: 0.5517 | F1-Score: 0.5357 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [17:28<2:03:39, 353.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        12\n",
      "           1       0.35      0.73      0.48        15\n",
      "           2       0.33      0.33      0.33         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.77      0.83      0.80        29\n",
      "\n",
      "    accuracy                           0.54        84\n",
      "   macro avg       0.42      0.50      0.44        84\n",
      "weighted avg       0.46      0.54      0.48        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.352798, test accuracy: 0.5357, test precision: 0.4197, test recall: 0.4955, test F1-score: 0.4441\n",
      "Parámetros:  add 1 1 900\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 1, 'LSTM': 1, 'LSTM_out': 900, 'Loss_final': 1.0325795412063599, 'Accuracy_eval': 0.6197435897435898, 'Precision_eval': 0.48979388786268446, 'Recall_eval': 0.5170353353543008, 'F1_eval': 0.48477818747057355, 'Loss_eval': 1.2601970434188843, 'Loss_tst': 1.3527977466583252, 'Accuracy_tst': 0.5357142857142857, 'Precision_tst': 0.41974584555229716, 'Recall_tst': 0.4955172413793103, 'F1_tst': 0.44405797101449274}\n",
      "Entrenando modelo con aggr=add, conv=1, lstm=2,out_lstm=800\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5488 | Eval Loss: 1.3988 | Accuracy: 0.5600 | Precision: 0.2274 | Recall: 0.3931 | F1-Score: 0.2780 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3979 | Eval Loss: 1.3071 | Accuracy: 0.6000 | Precision: 0.3405 | Recall: 0.4850 | F1-Score: 0.3928 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3118 | Eval Loss: 1.2833 | Accuracy: 0.6133 | Precision: 0.3480 | Recall: 0.5124 | F1-Score: 0.4060 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2835 | Eval Loss: 1.2719 | Accuracy: 0.6267 | Precision: 0.3462 | Recall: 0.5062 | F1-Score: 0.4067 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2710 | Eval Loss: 1.2898 | Accuracy: 0.5733 | Precision: 0.3627 | Recall: 0.4491 | F1-Score: 0.3928 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2792 | Eval Loss: 1.3126 | Accuracy: 0.5600 | Precision: 0.3928 | Recall: 0.4496 | F1-Score: 0.4155 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2821 | Eval Loss: 1.2914 | Accuracy: 0.6133 | Precision: 0.4513 | Recall: 0.5050 | F1-Score: 0.4259 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.3047 | Eval Loss: 1.2849 | Accuracy: 0.6133 | Precision: 0.4274 | Recall: 0.4993 | F1-Score: 0.4386 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2582 | Eval Loss: 1.3162 | Accuracy: 0.5600 | Precision: 0.4247 | Recall: 0.4832 | F1-Score: 0.4351 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2560 | Eval Loss: 1.3099 | Accuracy: 0.5867 | Precision: 0.4379 | Recall: 0.5043 | F1-Score: 0.4572 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2958 | Eval Loss: 1.3461 | Accuracy: 0.5600 | Precision: 0.3789 | Recall: 0.4791 | F1-Score: 0.3994 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.3117 | Eval Loss: 1.3255 | Accuracy: 0.5600 | Precision: 0.4273 | Recall: 0.4627 | F1-Score: 0.4237 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2572 | Eval Loss: 1.2820 | Accuracy: 0.6267 | Precision: 0.4456 | Recall: 0.5193 | F1-Score: 0.4741 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2565 | Eval Loss: 1.2813 | Accuracy: 0.6133 | Precision: 0.4356 | Recall: 0.4845 | F1-Score: 0.4529 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2416 | Eval Loss: 1.3501 | Accuracy: 0.5467 | Precision: 0.3865 | Recall: 0.4033 | F1-Score: 0.3862 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2983 | Eval Loss: 1.3397 | Accuracy: 0.5600 | Precision: 0.4509 | Recall: 0.5036 | F1-Score: 0.4476 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2642 | Eval Loss: 1.2790 | Accuracy: 0.6133 | Precision: 0.4246 | Recall: 0.4845 | F1-Score: 0.4491 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2719 | Eval Loss: 1.3168 | Accuracy: 0.5867 | Precision: 0.4224 | Recall: 0.4633 | F1-Score: 0.4312 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2531 | Eval Loss: 1.3130 | Accuracy: 0.5867 | Precision: 0.4370 | Recall: 0.4896 | F1-Score: 0.4362 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2413 | Eval Loss: 1.2815 | Accuracy: 0.6133 | Precision: 0.3393 | Recall: 0.4845 | F1-Score: 0.3970 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2427 | Eval Loss: 1.3120 | Accuracy: 0.6000 | Precision: 0.4290 | Recall: 0.4776 | F1-Score: 0.4476 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2110 | Eval Loss: 1.3160 | Accuracy: 0.6000 | Precision: 0.4230 | Recall: 0.4588 | F1-Score: 0.4374 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2173 | Eval Loss: 1.2874 | Accuracy: 0.6133 | Precision: 0.4489 | Recall: 0.4919 | F1-Score: 0.4633 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.2042 | Eval Loss: 1.3314 | Accuracy: 0.5867 | Precision: 0.6575 | Recall: 0.5282 | F1-Score: 0.4963 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.2095 | Eval Loss: 1.3569 | Accuracy: 0.5333 | Precision: 0.4073 | Recall: 0.4489 | F1-Score: 0.4096 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2369 | Eval Loss: 1.2814 | Accuracy: 0.6267 | Precision: 0.4526 | Recall: 0.4988 | F1-Score: 0.4705 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.2217 | Eval Loss: 1.2938 | Accuracy: 0.6000 | Precision: 0.4472 | Recall: 0.5038 | F1-Score: 0.4559 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.2033 | Eval Loss: 1.3432 | Accuracy: 0.5600 | Precision: 0.5060 | Recall: 0.4989 | F1-Score: 0.4841 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.2089 | Eval Loss: 1.2753 | Accuracy: 0.6000 | Precision: 0.4210 | Recall: 0.4776 | F1-Score: 0.4418 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1981 | Eval Loss: 1.2824 | Accuracy: 0.6133 | Precision: 0.5705 | Recall: 0.5133 | F1-Score: 0.5134 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.2030 | Eval Loss: 1.2910 | Accuracy: 0.6133 | Precision: 0.6447 | Recall: 0.5026 | F1-Score: 0.4970 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.2012 | Eval Loss: 1.2882 | Accuracy: 0.6267 | Precision: 0.5721 | Recall: 0.5562 | F1-Score: 0.5167 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1900 | Eval Loss: 1.2780 | Accuracy: 0.6400 | Precision: 0.5885 | Recall: 0.5979 | F1-Score: 0.5908 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1745 | Eval Loss: 1.2614 | Accuracy: 0.6400 | Precision: 0.5793 | Recall: 0.5502 | F1-Score: 0.5594 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1747 | Eval Loss: 1.2912 | Accuracy: 0.6133 | Precision: 0.5615 | Recall: 0.5002 | F1-Score: 0.5032 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1829 | Eval Loss: 1.2924 | Accuracy: 0.6267 | Precision: 0.6046 | Recall: 0.5719 | F1-Score: 0.5698 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1623 | Eval Loss: 1.2771 | Accuracy: 0.6000 | Precision: 0.4982 | Recall: 0.5246 | F1-Score: 0.5001 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1581 | Eval Loss: 1.3061 | Accuracy: 0.5867 | Precision: 0.5637 | Recall: 0.4938 | F1-Score: 0.5060 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1426 | Eval Loss: 1.3055 | Accuracy: 0.5733 | Precision: 0.4970 | Recall: 0.5008 | F1-Score: 0.4734 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1333 | Eval Loss: 1.2614 | Accuracy: 0.6667 | Precision: 0.6678 | Recall: 0.5681 | F1-Score: 0.5881 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1129 | Eval Loss: 1.2945 | Accuracy: 0.6000 | Precision: 0.5290 | Recall: 0.5246 | F1-Score: 0.5188 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1030 | Eval Loss: 1.2879 | Accuracy: 0.6133 | Precision: 0.5531 | Recall: 0.5315 | F1-Score: 0.5370 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0967 | Eval Loss: 1.2997 | Accuracy: 0.5867 | Precision: 0.5317 | Recall: 0.4962 | F1-Score: 0.4855 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0930 | Eval Loss: 1.2898 | Accuracy: 0.6000 | Precision: 0.5278 | Recall: 0.5262 | F1-Score: 0.5263 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0977 | Eval Loss: 1.3194 | Accuracy: 0.5733 | Precision: 0.5119 | Recall: 0.4746 | F1-Score: 0.4634 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0954 | Eval Loss: 1.2962 | Accuracy: 0.6133 | Precision: 0.5400 | Recall: 0.5026 | F1-Score: 0.4945 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.1001 | Eval Loss: 1.2844 | Accuracy: 0.6000 | Precision: 0.5299 | Recall: 0.5065 | F1-Score: 0.5024 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0971 | Eval Loss: 1.2894 | Accuracy: 0.5867 | Precision: 0.5139 | Recall: 0.5093 | F1-Score: 0.4906 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0751 | Eval Loss: 1.2869 | Accuracy: 0.6133 | Precision: 0.5821 | Recall: 0.5355 | F1-Score: 0.5357 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0861 | Eval Loss: 1.2698 | Accuracy: 0.6667 | Precision: 0.6798 | Recall: 0.5862 | F1-Score: 0.6123 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0930 | Eval Loss: 1.3231 | Accuracy: 0.5600 | Precision: 0.4687 | Recall: 0.4324 | F1-Score: 0.4192 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.1343 | Eval Loss: 1.2954 | Accuracy: 0.5867 | Precision: 0.5138 | Recall: 0.5298 | F1-Score: 0.5027 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [26:09<2:19:49, 419.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        12\n",
      "           1       0.32      0.73      0.45        15\n",
      "           2       0.40      0.22      0.29         9\n",
      "           3       0.29      0.11      0.15        19\n",
      "           4       0.79      0.66      0.72        29\n",
      "\n",
      "    accuracy                           0.52        84\n",
      "   macro avg       0.50      0.51      0.47        84\n",
      "weighted avg       0.54      0.52      0.50        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.367285, test accuracy: 0.5238, test precision: 0.5030, test recall: 0.5099, test F1-score: 0.4750\n",
      "Parámetros:  add 1 2 800\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 1, 'LSTM': 2, 'LSTM_out': 800, 'Loss_final': 1.1342536211013794, 'Accuracy_eval': 0.5979487179487178, 'Precision_eval': 0.47940821883233536, 'Recall_eval': 0.4996452254641909, 'F1_eval': 0.46843373909701636, 'Loss_eval': 1.2954282760620117, 'Loss_tst': 1.3672845363616943, 'Accuracy_tst': 0.5238095238095238, 'Precision_tst': 0.5030392156862745, 'Recall_tst': 0.5098648921153458, 'F1_tst': 0.47495038654068295}\n",
      "Entrenando modelo con aggr=add, conv=1, lstm=2,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5542 | Eval Loss: 1.3959 | Accuracy: 0.5733 | Precision: 0.2250 | Recall: 0.4000 | F1-Score: 0.2824 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4052 | Eval Loss: 1.3053 | Accuracy: 0.6133 | Precision: 0.3247 | Recall: 0.4657 | F1-Score: 0.3821 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3256 | Eval Loss: 1.2719 | Accuracy: 0.6400 | Precision: 0.3563 | Recall: 0.5131 | F1-Score: 0.4189 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3045 | Eval Loss: 1.2738 | Accuracy: 0.6400 | Precision: 0.5512 | Recall: 0.5205 | F1-Score: 0.4383 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.3007 | Eval Loss: 1.3334 | Accuracy: 0.5467 | Precision: 0.3865 | Recall: 0.4763 | F1-Score: 0.3978 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.3148 | Eval Loss: 1.3346 | Accuracy: 0.5600 | Precision: 0.3475 | Recall: 0.4398 | F1-Score: 0.3740 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.3230 | Eval Loss: 1.2956 | Accuracy: 0.5867 | Precision: 0.3840 | Recall: 0.4429 | F1-Score: 0.4024 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2721 | Eval Loss: 1.2911 | Accuracy: 0.5467 | Precision: 0.3894 | Recall: 0.4222 | F1-Score: 0.3946 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2679 | Eval Loss: 1.2995 | Accuracy: 0.5867 | Precision: 0.3512 | Recall: 0.4822 | F1-Score: 0.3946 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2805 | Eval Loss: 1.3012 | Accuracy: 0.5867 | Precision: 0.4000 | Recall: 0.4502 | F1-Score: 0.4182 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2851 | Eval Loss: 1.3623 | Accuracy: 0.4933 | Precision: 0.3525 | Recall: 0.4208 | F1-Score: 0.3690 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.3435 | Eval Loss: 1.3116 | Accuracy: 0.5600 | Precision: 0.3743 | Recall: 0.4086 | F1-Score: 0.3818 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2764 | Eval Loss: 1.3055 | Accuracy: 0.5600 | Precision: 0.4057 | Recall: 0.4553 | F1-Score: 0.4150 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2607 | Eval Loss: 1.2834 | Accuracy: 0.6000 | Precision: 0.3872 | Recall: 0.4719 | F1-Score: 0.4175 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2699 | Eval Loss: 1.3070 | Accuracy: 0.5600 | Precision: 0.3998 | Recall: 0.4496 | F1-Score: 0.4160 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2714 | Eval Loss: 1.3303 | Accuracy: 0.5467 | Precision: 0.3869 | Recall: 0.4484 | F1-Score: 0.3955 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2907 | Eval Loss: 1.2764 | Accuracy: 0.6267 | Precision: 0.5806 | Recall: 0.5481 | F1-Score: 0.5355 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2523 | Eval Loss: 1.2812 | Accuracy: 0.5867 | Precision: 0.4231 | Recall: 0.4707 | F1-Score: 0.4279 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2484 | Eval Loss: 1.3017 | Accuracy: 0.5867 | Precision: 0.5940 | Recall: 0.4660 | F1-Score: 0.4651 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2539 | Eval Loss: 1.2900 | Accuracy: 0.6267 | Precision: 0.6674 | Recall: 0.5243 | F1-Score: 0.5133 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2335 | Eval Loss: 1.2834 | Accuracy: 0.6000 | Precision: 0.5960 | Recall: 0.4917 | F1-Score: 0.4897 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2074 | Eval Loss: 1.2619 | Accuracy: 0.6267 | Precision: 0.6438 | Recall: 0.5169 | F1-Score: 0.5052 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1973 | Eval Loss: 1.2341 | Accuracy: 0.6667 | Precision: 0.6312 | Recall: 0.5976 | F1-Score: 0.6036 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1949 | Eval Loss: 1.2873 | Accuracy: 0.6267 | Precision: 0.6797 | Recall: 0.5562 | F1-Score: 0.5237 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.2289 | Eval Loss: 1.3167 | Accuracy: 0.5867 | Precision: 0.6008 | Recall: 0.4660 | F1-Score: 0.4680 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2486 | Eval Loss: 1.2598 | Accuracy: 0.6267 | Precision: 0.5854 | Recall: 0.5596 | F1-Score: 0.5377 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.2104 | Eval Loss: 1.2574 | Accuracy: 0.6400 | Precision: 0.5676 | Recall: 0.5624 | F1-Score: 0.5399 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.2369 | Eval Loss: 1.2839 | Accuracy: 0.6000 | Precision: 0.6288 | Recall: 0.4769 | F1-Score: 0.4784 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.2204 | Eval Loss: 1.3075 | Accuracy: 0.5733 | Precision: 0.5810 | Recall: 0.4410 | F1-Score: 0.4354 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.2155 | Eval Loss: 1.3037 | Accuracy: 0.5733 | Precision: 0.5257 | Recall: 0.4483 | F1-Score: 0.4548 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.2153 | Eval Loss: 1.3387 | Accuracy: 0.5333 | Precision: 0.5043 | Recall: 0.4932 | F1-Score: 0.4560 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.2389 | Eval Loss: 1.3310 | Accuracy: 0.5467 | Precision: 0.5119 | Recall: 0.5044 | F1-Score: 0.4817 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.2468 | Eval Loss: 1.2685 | Accuracy: 0.6400 | Precision: 0.5702 | Recall: 0.5872 | F1-Score: 0.5676 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1998 | Eval Loss: 1.2627 | Accuracy: 0.6000 | Precision: 0.6170 | Recall: 0.4957 | F1-Score: 0.4825 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.2026 | Eval Loss: 1.2912 | Accuracy: 0.5733 | Precision: 0.4940 | Recall: 0.4648 | F1-Score: 0.4609 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1751 | Eval Loss: 1.2989 | Accuracy: 0.5867 | Precision: 0.5448 | Recall: 0.4783 | F1-Score: 0.4836 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1852 | Eval Loss: 1.2487 | Accuracy: 0.6533 | Precision: 0.6603 | Recall: 0.5538 | F1-Score: 0.5754 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1695 | Eval Loss: 1.2820 | Accuracy: 0.6000 | Precision: 0.5181 | Recall: 0.4910 | F1-Score: 0.4990 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1691 | Eval Loss: 1.2696 | Accuracy: 0.6533 | Precision: 0.6367 | Recall: 0.5686 | F1-Score: 0.5841 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1788 | Eval Loss: 1.2929 | Accuracy: 0.6533 | Precision: 0.7022 | Recall: 0.6548 | F1-Score: 0.5775 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1926 | Eval Loss: 1.2553 | Accuracy: 0.6400 | Precision: 0.5887 | Recall: 0.5633 | F1-Score: 0.5661 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1444 | Eval Loss: 1.2485 | Accuracy: 0.6533 | Precision: 0.6506 | Recall: 0.5783 | F1-Score: 0.5806 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.1529 | Eval Loss: 1.2858 | Accuracy: 0.6000 | Precision: 0.5255 | Recall: 0.4876 | F1-Score: 0.4959 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1439 | Eval Loss: 1.2852 | Accuracy: 0.6133 | Precision: 0.5631 | Recall: 0.5603 | F1-Score: 0.5558 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.1190 | Eval Loss: 1.2942 | Accuracy: 0.6133 | Precision: 0.5970 | Recall: 0.5543 | F1-Score: 0.5402 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.1187 | Eval Loss: 1.2667 | Accuracy: 0.6400 | Precision: 0.5867 | Recall: 0.5731 | F1-Score: 0.5561 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.1552 | Eval Loss: 1.2747 | Accuracy: 0.6533 | Precision: 0.6027 | Recall: 0.6007 | F1-Score: 0.5772 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.1212 | Eval Loss: 1.2556 | Accuracy: 0.6400 | Precision: 0.6554 | Recall: 0.5476 | F1-Score: 0.5519 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.1024 | Eval Loss: 1.2568 | Accuracy: 0.6133 | Precision: 0.5535 | Recall: 0.5569 | F1-Score: 0.5528 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0937 | Eval Loss: 1.2638 | Accuracy: 0.6400 | Precision: 0.5581 | Recall: 0.5569 | F1-Score: 0.5550 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.1065 | Eval Loss: 1.2579 | Accuracy: 0.6400 | Precision: 0.6703 | Recall: 0.5550 | F1-Score: 0.5532 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0785 | Eval Loss: 1.2915 | Accuracy: 0.5867 | Precision: 0.4959 | Recall: 0.4938 | F1-Score: 0.4924 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [36:04<2:32:50, 482.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        12\n",
      "           1       0.31      0.53      0.39        15\n",
      "           2       0.29      0.44      0.35         9\n",
      "           3       0.25      0.05      0.09        19\n",
      "           4       0.79      0.76      0.77        29\n",
      "\n",
      "    accuracy                           0.51        84\n",
      "   macro avg       0.46      0.49      0.45        84\n",
      "weighted avg       0.51      0.51      0.49        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.345876, test accuracy: 0.5119, test precision: 0.4592, test recall: 0.4911, test F1-score: 0.4527\n",
      "Parámetros:  add 1 2 850\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 1, 'LSTM': 2, 'LSTM_out': 850, 'Loss_final': 1.0784937143325806, 'Accuracy_eval': 0.6023076923076923, 'Precision_eval': 0.521821913908979, 'Recall_eval': 0.5060193255020842, 'F1_eval': 0.4811950387360564, 'Loss_eval': 1.291514277458191, 'Loss_tst': 1.3458757400512695, 'Accuracy_tst': 0.5119047619047619, 'Precision_tst': 0.45915750915750914, 'Recall_tst': 0.491139342609397, 'F1_tst': 0.45272460047254925}\n",
      "Entrenando modelo con aggr=add, conv=1, lstm=2,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5481 | Eval Loss: 1.3721 | Accuracy: 0.5600 | Precision: 0.2179 | Recall: 0.3857 | F1-Score: 0.2740 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4014 | Eval Loss: 1.2986 | Accuracy: 0.6267 | Precision: 0.3445 | Recall: 0.4988 | F1-Score: 0.4064 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3241 | Eval Loss: 1.2814 | Accuracy: 0.6133 | Precision: 0.3418 | Recall: 0.4919 | F1-Score: 0.3976 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3071 | Eval Loss: 1.2863 | Accuracy: 0.5733 | Precision: 0.3690 | Recall: 0.4286 | F1-Score: 0.3905 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2867 | Eval Loss: 1.2966 | Accuracy: 0.5600 | Precision: 0.3859 | Recall: 0.4610 | F1-Score: 0.4037 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2706 | Eval Loss: 1.2770 | Accuracy: 0.6000 | Precision: 0.4064 | Recall: 0.4702 | F1-Score: 0.4304 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2602 | Eval Loss: 1.3113 | Accuracy: 0.5733 | Precision: 0.3963 | Recall: 0.4302 | F1-Score: 0.4075 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2933 | Eval Loss: 1.3077 | Accuracy: 0.5733 | Precision: 0.3280 | Recall: 0.4638 | F1-Score: 0.3787 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2860 | Eval Loss: 1.3009 | Accuracy: 0.5333 | Precision: 0.3634 | Recall: 0.4022 | F1-Score: 0.3806 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2501 | Eval Loss: 1.3107 | Accuracy: 0.6000 | Precision: 0.4270 | Recall: 0.4965 | F1-Score: 0.4427 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2611 | Eval Loss: 1.3146 | Accuracy: 0.5867 | Precision: 0.4256 | Recall: 0.4781 | F1-Score: 0.4436 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2844 | Eval Loss: 1.2992 | Accuracy: 0.6000 | Precision: 0.3874 | Recall: 0.4867 | F1-Score: 0.4169 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.3312 | Eval Loss: 1.3306 | Accuracy: 0.5867 | Precision: 0.5532 | Recall: 0.5191 | F1-Score: 0.4214 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.3344 | Eval Loss: 1.3388 | Accuracy: 0.5333 | Precision: 0.3921 | Recall: 0.4341 | F1-Score: 0.3877 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2769 | Eval Loss: 1.3452 | Accuracy: 0.5600 | Precision: 0.4543 | Recall: 0.5110 | F1-Score: 0.4245 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2618 | Eval Loss: 1.2782 | Accuracy: 0.6400 | Precision: 0.4613 | Recall: 0.5205 | F1-Score: 0.4826 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2477 | Eval Loss: 1.3071 | Accuracy: 0.6000 | Precision: 0.4202 | Recall: 0.4702 | F1-Score: 0.4375 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2334 | Eval Loss: 1.3062 | Accuracy: 0.6000 | Precision: 0.4438 | Recall: 0.5169 | F1-Score: 0.4595 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2395 | Eval Loss: 1.3088 | Accuracy: 0.5867 | Precision: 0.4390 | Recall: 0.4986 | F1-Score: 0.4405 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2542 | Eval Loss: 1.3374 | Accuracy: 0.5467 | Precision: 0.3175 | Recall: 0.4500 | F1-Score: 0.3634 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2615 | Eval Loss: 1.3332 | Accuracy: 0.5467 | Precision: 0.3157 | Recall: 0.4574 | F1-Score: 0.3627 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2649 | Eval Loss: 1.2966 | Accuracy: 0.5600 | Precision: 0.4475 | Recall: 0.4488 | F1-Score: 0.4465 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2399 | Eval Loss: 1.2952 | Accuracy: 0.5867 | Precision: 0.5973 | Recall: 0.4667 | F1-Score: 0.4532 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.2420 | Eval Loss: 1.3418 | Accuracy: 0.5333 | Precision: 0.3639 | Recall: 0.4079 | F1-Score: 0.3805 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.2306 | Eval Loss: 1.2905 | Accuracy: 0.6000 | Precision: 0.4222 | Recall: 0.4645 | F1-Score: 0.4413 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2332 | Eval Loss: 1.2789 | Accuracy: 0.6133 | Precision: 0.5126 | Recall: 0.5315 | F1-Score: 0.5193 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.2104 | Eval Loss: 1.2653 | Accuracy: 0.6400 | Precision: 0.6759 | Recall: 0.5631 | F1-Score: 0.5248 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.2075 | Eval Loss: 1.2829 | Accuracy: 0.6000 | Precision: 0.4000 | Recall: 0.4760 | F1-Score: 0.4294 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.2081 | Eval Loss: 1.3341 | Accuracy: 0.5333 | Precision: 0.3829 | Recall: 0.3874 | F1-Score: 0.3722 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.2201 | Eval Loss: 1.2681 | Accuracy: 0.6133 | Precision: 0.6198 | Recall: 0.4952 | F1-Score: 0.4779 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1989 | Eval Loss: 1.2754 | Accuracy: 0.6267 | Precision: 0.6354 | Recall: 0.5333 | F1-Score: 0.5366 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1973 | Eval Loss: 1.2878 | Accuracy: 0.6000 | Precision: 0.5298 | Recall: 0.5574 | F1-Score: 0.5302 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.2014 | Eval Loss: 1.2971 | Accuracy: 0.6000 | Precision: 0.4401 | Recall: 0.5055 | F1-Score: 0.4505 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.3014 | Eval Loss: 1.3498 | Accuracy: 0.5467 | Precision: 0.5084 | Recall: 0.5084 | F1-Score: 0.4813 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.2456 | Eval Loss: 1.2826 | Accuracy: 0.6133 | Precision: 0.4409 | Recall: 0.5067 | F1-Score: 0.4629 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.2262 | Eval Loss: 1.3043 | Accuracy: 0.5733 | Precision: 0.5138 | Recall: 0.4960 | F1-Score: 0.4938 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1811 | Eval Loss: 1.2975 | Accuracy: 0.6133 | Precision: 0.6405 | Recall: 0.5281 | F1-Score: 0.5339 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1655 | Eval Loss: 1.2879 | Accuracy: 0.5867 | Precision: 0.4931 | Recall: 0.5184 | F1-Score: 0.4951 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1670 | Eval Loss: 1.3042 | Accuracy: 0.5733 | Precision: 0.5234 | Recall: 0.5132 | F1-Score: 0.4915 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1997 | Eval Loss: 1.2912 | Accuracy: 0.5867 | Precision: 0.4488 | Recall: 0.4502 | F1-Score: 0.4400 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1784 | Eval Loss: 1.2753 | Accuracy: 0.6400 | Precision: 0.6484 | Recall: 0.5633 | F1-Score: 0.5760 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1597 | Eval Loss: 1.2412 | Accuracy: 0.6533 | Precision: 0.6136 | Recall: 0.5743 | F1-Score: 0.5793 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.1402 | Eval Loss: 1.2753 | Accuracy: 0.6000 | Precision: 0.5378 | Recall: 0.5377 | F1-Score: 0.5304 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1309 | Eval Loss: 1.2593 | Accuracy: 0.6533 | Precision: 0.6839 | Recall: 0.5562 | F1-Score: 0.5709 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.1324 | Eval Loss: 1.2655 | Accuracy: 0.6133 | Precision: 0.5152 | Recall: 0.5100 | F1-Score: 0.4984 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.1253 | Eval Loss: 1.2959 | Accuracy: 0.6133 | Precision: 0.4489 | Recall: 0.5238 | F1-Score: 0.4693 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.1267 | Eval Loss: 1.2831 | Accuracy: 0.6000 | Precision: 0.5327 | Recall: 0.4983 | F1-Score: 0.5064 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.1142 | Eval Loss: 1.2948 | Accuracy: 0.6000 | Precision: 0.5585 | Recall: 0.5253 | F1-Score: 0.5081 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.1109 | Eval Loss: 1.2706 | Accuracy: 0.6133 | Precision: 0.5549 | Recall: 0.5700 | F1-Score: 0.5589 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0963 | Eval Loss: 1.2627 | Accuracy: 0.6533 | Precision: 0.6714 | Recall: 0.5750 | F1-Score: 0.5616 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0778 | Eval Loss: 1.2714 | Accuracy: 0.6133 | Precision: 0.5558 | Recall: 0.5355 | F1-Score: 0.5368 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0834 | Eval Loss: 1.2651 | Accuracy: 0.6667 | Precision: 0.6153 | Recall: 0.6198 | F1-Score: 0.6034 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6/24 [46:29<2:39:19, 531.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69        12\n",
      "           1       0.37      0.73      0.49        15\n",
      "           2       0.25      0.11      0.15         9\n",
      "           3       0.50      0.16      0.24        19\n",
      "           4       0.80      0.83      0.81        29\n",
      "\n",
      "    accuracy                           0.57        84\n",
      "   macro avg       0.51      0.52      0.48        84\n",
      "weighted avg       0.57      0.57      0.54        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.330824, test accuracy: 0.5714, test precision: 0.5119, test recall: 0.5160, test F1-score: 0.4777\n",
      "Parámetros:  add 1 2 900\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 1, 'LSTM': 2, 'LSTM_out': 900, 'Loss_final': 1.0833632946014404, 'Accuracy_eval': 0.5946153846153847, 'Precision_eval': 0.47544278241286736, 'Recall_eval': 0.49653135657446, 'F1_eval': 0.46178665237627603, 'Loss_eval': 1.2650500535964966, 'Loss_tst': 1.3308241367340088, 'Accuracy_tst': 0.5714285714285714, 'Precision_tst': 0.5119047619047619, 'Recall_tst': 0.5159850776366203, 'F1_tst': 0.4777204114153267}\n",
      "Entrenando modelo con aggr=add, conv=2, lstm=1,out_lstm=800\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5164 | Eval Loss: 1.3317 | Accuracy: 0.6133 | Precision: 0.3353 | Recall: 0.4657 | F1-Score: 0.3844 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3364 | Eval Loss: 1.2766 | Accuracy: 0.6267 | Precision: 0.3500 | Recall: 0.5119 | F1-Score: 0.4112 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.2788 | Eval Loss: 1.2779 | Accuracy: 0.6133 | Precision: 0.4428 | Recall: 0.5050 | F1-Score: 0.4595 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2567 | Eval Loss: 1.2997 | Accuracy: 0.5733 | Precision: 0.3980 | Recall: 0.4622 | F1-Score: 0.4096 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2486 | Eval Loss: 1.3019 | Accuracy: 0.5867 | Precision: 0.4400 | Recall: 0.4986 | F1-Score: 0.4295 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2626 | Eval Loss: 1.3030 | Accuracy: 0.5733 | Precision: 0.4157 | Recall: 0.4712 | F1-Score: 0.4321 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2410 | Eval Loss: 1.2892 | Accuracy: 0.6000 | Precision: 0.4210 | Recall: 0.4702 | F1-Score: 0.4357 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2263 | Eval Loss: 1.2864 | Accuracy: 0.6133 | Precision: 0.4393 | Recall: 0.4845 | F1-Score: 0.4522 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2090 | Eval Loss: 1.2852 | Accuracy: 0.5867 | Precision: 0.4273 | Recall: 0.4707 | F1-Score: 0.4383 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2035 | Eval Loss: 1.3014 | Accuracy: 0.5867 | Precision: 0.4257 | Recall: 0.4707 | F1-Score: 0.4379 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2032 | Eval Loss: 1.2765 | Accuracy: 0.6000 | Precision: 0.4031 | Recall: 0.4702 | F1-Score: 0.4207 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2005 | Eval Loss: 1.2678 | Accuracy: 0.6000 | Precision: 0.4237 | Recall: 0.4702 | F1-Score: 0.4405 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.1800 | Eval Loss: 1.2876 | Accuracy: 0.6133 | Precision: 0.5235 | Recall: 0.5241 | F1-Score: 0.5143 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.1809 | Eval Loss: 1.2789 | Accuracy: 0.6133 | Precision: 0.4432 | Recall: 0.4919 | F1-Score: 0.4597 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1755 | Eval Loss: 1.2985 | Accuracy: 0.5733 | Precision: 0.4261 | Recall: 0.4638 | F1-Score: 0.4360 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1675 | Eval Loss: 1.2829 | Accuracy: 0.6133 | Precision: 0.5245 | Recall: 0.5100 | F1-Score: 0.5015 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1616 | Eval Loss: 1.3216 | Accuracy: 0.5600 | Precision: 0.4876 | Recall: 0.4858 | F1-Score: 0.4764 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1583 | Eval Loss: 1.3067 | Accuracy: 0.5867 | Precision: 0.4301 | Recall: 0.4707 | F1-Score: 0.4382 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1516 | Eval Loss: 1.2884 | Accuracy: 0.6133 | Precision: 0.4461 | Recall: 0.5050 | F1-Score: 0.4680 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1463 | Eval Loss: 1.2605 | Accuracy: 0.6400 | Precision: 0.6480 | Recall: 0.5238 | F1-Score: 0.5134 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1317 | Eval Loss: 1.2906 | Accuracy: 0.6133 | Precision: 0.5198 | Recall: 0.5060 | F1-Score: 0.4989 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1241 | Eval Loss: 1.2722 | Accuracy: 0.6267 | Precision: 0.6408 | Recall: 0.5021 | F1-Score: 0.4978 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1287 | Eval Loss: 1.2623 | Accuracy: 0.6133 | Precision: 0.4345 | Recall: 0.4845 | F1-Score: 0.4538 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1183 | Eval Loss: 1.2810 | Accuracy: 0.5867 | Precision: 0.4445 | Recall: 0.4838 | F1-Score: 0.4427 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1063 | Eval Loss: 1.2849 | Accuracy: 0.6267 | Precision: 0.5123 | Recall: 0.5374 | F1-Score: 0.5138 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1054 | Eval Loss: 1.2752 | Accuracy: 0.6400 | Precision: 0.5587 | Recall: 0.5419 | F1-Score: 0.5393 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1132 | Eval Loss: 1.2912 | Accuracy: 0.6133 | Precision: 0.5354 | Recall: 0.4945 | F1-Score: 0.4867 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1158 | Eval Loss: 1.2899 | Accuracy: 0.6267 | Precision: 0.5119 | Recall: 0.5152 | F1-Score: 0.4984 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1158 | Eval Loss: 1.2648 | Accuracy: 0.6400 | Precision: 0.4456 | Recall: 0.5262 | F1-Score: 0.4719 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1104 | Eval Loss: 1.2734 | Accuracy: 0.6533 | Precision: 0.6853 | Recall: 0.5438 | F1-Score: 0.5219 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0844 | Eval Loss: 1.2712 | Accuracy: 0.6133 | Precision: 0.4408 | Recall: 0.4976 | F1-Score: 0.4628 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0817 | Eval Loss: 1.2699 | Accuracy: 0.6133 | Precision: 0.4634 | Recall: 0.5050 | F1-Score: 0.4736 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0742 | Eval Loss: 1.2766 | Accuracy: 0.6000 | Precision: 0.5000 | Recall: 0.5015 | F1-Score: 0.4838 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0625 | Eval Loss: 1.2791 | Accuracy: 0.6000 | Precision: 0.5233 | Recall: 0.5105 | F1-Score: 0.4981 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0674 | Eval Loss: 1.2740 | Accuracy: 0.6133 | Precision: 0.5418 | Recall: 0.5002 | F1-Score: 0.4861 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0631 | Eval Loss: 1.2504 | Accuracy: 0.6667 | Precision: 0.7102 | Recall: 0.5450 | F1-Score: 0.5419 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0885 | Eval Loss: 1.2766 | Accuracy: 0.6267 | Precision: 0.5546 | Recall: 0.5152 | F1-Score: 0.4931 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0812 | Eval Loss: 1.2783 | Accuracy: 0.6267 | Precision: 0.4925 | Recall: 0.5324 | F1-Score: 0.4929 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0877 | Eval Loss: 1.2850 | Accuracy: 0.6267 | Precision: 0.5721 | Recall: 0.5598 | F1-Score: 0.5567 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0832 | Eval Loss: 1.2489 | Accuracy: 0.6267 | Precision: 0.4659 | Recall: 0.5062 | F1-Score: 0.4745 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0660 | Eval Loss: 1.2472 | Accuracy: 0.6667 | Precision: 0.5964 | Recall: 0.5631 | F1-Score: 0.5608 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0528 | Eval Loss: 1.2515 | Accuracy: 0.6400 | Precision: 0.5645 | Recall: 0.5345 | F1-Score: 0.5225 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0512 | Eval Loss: 1.2334 | Accuracy: 0.6800 | Precision: 0.5758 | Recall: 0.5650 | F1-Score: 0.5511 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0420 | Eval Loss: 1.2387 | Accuracy: 0.6533 | Precision: 0.5318 | Recall: 0.5438 | F1-Score: 0.5141 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0494 | Eval Loss: 1.3007 | Accuracy: 0.5867 | Precision: 0.4874 | Recall: 0.5093 | F1-Score: 0.4767 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0531 | Eval Loss: 1.2606 | Accuracy: 0.6800 | Precision: 0.5993 | Recall: 0.5955 | F1-Score: 0.5961 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0559 | Eval Loss: 1.2507 | Accuracy: 0.6533 | Precision: 0.6794 | Recall: 0.5307 | F1-Score: 0.5251 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0452 | Eval Loss: 1.2487 | Accuracy: 0.6667 | Precision: 0.5694 | Recall: 0.5705 | F1-Score: 0.5671 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0295 | Eval Loss: 1.2614 | Accuracy: 0.6133 | Precision: 0.5389 | Recall: 0.5372 | F1-Score: 0.5347 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0390 | Eval Loss: 1.2657 | Accuracy: 0.6133 | Precision: 0.5542 | Recall: 0.5288 | F1-Score: 0.5053 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0252 | Eval Loss: 1.2837 | Accuracy: 0.6000 | Precision: 0.4990 | Recall: 0.5088 | F1-Score: 0.4922 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0154 | Eval Loss: 1.2819 | Accuracy: 0.6267 | Precision: 0.5605 | Recall: 0.5655 | F1-Score: 0.5588 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [56:09<2:35:01, 547.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        12\n",
      "           1       0.44      0.53      0.48        15\n",
      "           2       0.40      0.44      0.42         9\n",
      "           3       0.50      0.37      0.42        19\n",
      "           4       0.72      0.79      0.75        29\n",
      "\n",
      "    accuracy                           0.58        84\n",
      "   macro avg       0.55      0.54      0.54        84\n",
      "weighted avg       0.58      0.58      0.58        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.332177, test accuracy: 0.5833, test precision: 0.5526, test recall: 0.5445, test F1-score: 0.5441\n",
      "Parámetros:  add 2 1 800\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 2, 'LSTM': 1, 'LSTM_out': 800, 'Loss_final': 1.0154131650924683, 'Accuracy_eval': 0.6176923076923078, 'Precision_eval': 0.5031011301441235, 'Recall_eval': 0.5113205759757483, 'F1_eval': 0.4856228643016677, 'Loss_eval': 1.2818864583969116, 'Loss_tst': 1.3321772813796997, 'Accuracy_tst': 0.5833333333333334, 'Precision_tst': 0.5526388888888889, 'Recall_tst': 0.5445271224037105, 'F1_tst': 0.544121107537846}\n",
      "Entrenando modelo con aggr=add, conv=2, lstm=1,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5094 | Eval Loss: 1.3221 | Accuracy: 0.6133 | Precision: 0.3334 | Recall: 0.4862 | F1-Score: 0.3921 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3323 | Eval Loss: 1.2707 | Accuracy: 0.6400 | Precision: 0.3524 | Recall: 0.5131 | F1-Score: 0.4138 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.2837 | Eval Loss: 1.2749 | Accuracy: 0.6000 | Precision: 0.4247 | Recall: 0.4833 | F1-Score: 0.4434 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2640 | Eval Loss: 1.2984 | Accuracy: 0.5867 | Precision: 0.4286 | Recall: 0.4912 | F1-Score: 0.4300 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2535 | Eval Loss: 1.2920 | Accuracy: 0.6000 | Precision: 0.4455 | Recall: 0.5055 | F1-Score: 0.4483 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2410 | Eval Loss: 1.2974 | Accuracy: 0.5600 | Precision: 0.3895 | Recall: 0.4700 | F1-Score: 0.4123 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2387 | Eval Loss: 1.2883 | Accuracy: 0.6000 | Precision: 0.4307 | Recall: 0.4850 | F1-Score: 0.4506 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2188 | Eval Loss: 1.2933 | Accuracy: 0.6000 | Precision: 0.4283 | Recall: 0.4645 | F1-Score: 0.4394 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2192 | Eval Loss: 1.2972 | Accuracy: 0.6000 | Precision: 0.4323 | Recall: 0.4776 | F1-Score: 0.4447 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2029 | Eval Loss: 1.3108 | Accuracy: 0.6133 | Precision: 0.4639 | Recall: 0.5124 | F1-Score: 0.4748 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2118 | Eval Loss: 1.2759 | Accuracy: 0.6267 | Precision: 0.4295 | Recall: 0.4988 | F1-Score: 0.4416 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2175 | Eval Loss: 1.2940 | Accuracy: 0.5733 | Precision: 0.4125 | Recall: 0.4565 | F1-Score: 0.4216 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.1857 | Eval Loss: 1.2711 | Accuracy: 0.6133 | Precision: 0.4518 | Recall: 0.4976 | F1-Score: 0.4610 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.1765 | Eval Loss: 1.2762 | Accuracy: 0.6000 | Precision: 0.4427 | Recall: 0.5038 | F1-Score: 0.4608 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1737 | Eval Loss: 1.3025 | Accuracy: 0.6000 | Precision: 0.4458 | Recall: 0.4850 | F1-Score: 0.4556 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1800 | Eval Loss: 1.2895 | Accuracy: 0.6133 | Precision: 0.4431 | Recall: 0.5050 | F1-Score: 0.4645 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1566 | Eval Loss: 1.2955 | Accuracy: 0.5600 | Precision: 0.3813 | Recall: 0.4422 | F1-Score: 0.4036 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1471 | Eval Loss: 1.3097 | Accuracy: 0.6000 | Precision: 0.4247 | Recall: 0.4702 | F1-Score: 0.4279 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1468 | Eval Loss: 1.2675 | Accuracy: 0.6267 | Precision: 0.4650 | Recall: 0.4988 | F1-Score: 0.4691 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1466 | Eval Loss: 1.2690 | Accuracy: 0.6267 | Precision: 0.4530 | Recall: 0.4988 | F1-Score: 0.4666 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1308 | Eval Loss: 1.2818 | Accuracy: 0.6267 | Precision: 0.5274 | Recall: 0.5374 | F1-Score: 0.5182 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1174 | Eval Loss: 1.2774 | Accuracy: 0.6267 | Precision: 0.5330 | Recall: 0.5424 | F1-Score: 0.5358 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1167 | Eval Loss: 1.2978 | Accuracy: 0.5467 | Precision: 0.3792 | Recall: 0.4279 | F1-Score: 0.3923 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1026 | Eval Loss: 1.2761 | Accuracy: 0.6133 | Precision: 0.4424 | Recall: 0.4902 | F1-Score: 0.4462 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1015 | Eval Loss: 1.2738 | Accuracy: 0.6267 | Precision: 0.5670 | Recall: 0.5300 | F1-Score: 0.5128 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.0973 | Eval Loss: 1.2640 | Accuracy: 0.6667 | Precision: 0.5855 | Recall: 0.5779 | F1-Score: 0.5772 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.0965 | Eval Loss: 1.2482 | Accuracy: 0.6400 | Precision: 0.5667 | Recall: 0.5395 | F1-Score: 0.5443 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0919 | Eval Loss: 1.2586 | Accuracy: 0.6400 | Precision: 0.5543 | Recall: 0.5295 | F1-Score: 0.5151 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0781 | Eval Loss: 1.2850 | Accuracy: 0.6000 | Precision: 0.4437 | Recall: 0.4981 | F1-Score: 0.4602 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0825 | Eval Loss: 1.2818 | Accuracy: 0.6000 | Precision: 0.4563 | Recall: 0.5112 | F1-Score: 0.4681 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0875 | Eval Loss: 1.2914 | Accuracy: 0.6000 | Precision: 0.4341 | Recall: 0.4776 | F1-Score: 0.4460 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0819 | Eval Loss: 1.2615 | Accuracy: 0.6267 | Precision: 0.5632 | Recall: 0.5169 | F1-Score: 0.5051 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0804 | Eval Loss: 1.2616 | Accuracy: 0.6133 | Precision: 0.4632 | Recall: 0.5050 | F1-Score: 0.4743 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0765 | Eval Loss: 1.2389 | Accuracy: 0.6667 | Precision: 0.5610 | Recall: 0.5762 | F1-Score: 0.5632 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0864 | Eval Loss: 1.2260 | Accuracy: 0.6933 | Precision: 0.6125 | Recall: 0.5810 | F1-Score: 0.5808 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0827 | Eval Loss: 1.2755 | Accuracy: 0.6267 | Precision: 0.4741 | Recall: 0.5119 | F1-Score: 0.4670 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0702 | Eval Loss: 1.2256 | Accuracy: 0.6800 | Precision: 0.5135 | Recall: 0.5617 | F1-Score: 0.5336 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0606 | Eval Loss: 1.2529 | Accuracy: 0.6400 | Precision: 0.5597 | Recall: 0.5419 | F1-Score: 0.5380 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0604 | Eval Loss: 1.2590 | Accuracy: 0.6667 | Precision: 0.5798 | Recall: 0.5705 | F1-Score: 0.5685 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0579 | Eval Loss: 1.2345 | Accuracy: 0.6533 | Precision: 0.6095 | Recall: 0.5488 | F1-Score: 0.5490 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0548 | Eval Loss: 1.2231 | Accuracy: 0.6800 | Precision: 0.5951 | Recall: 0.5536 | F1-Score: 0.5498 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0533 | Eval Loss: 1.2616 | Accuracy: 0.6533 | Precision: 0.5849 | Recall: 0.5767 | F1-Score: 0.5655 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0609 | Eval Loss: 1.2304 | Accuracy: 0.6800 | Precision: 0.5808 | Recall: 0.5667 | F1-Score: 0.5597 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0599 | Eval Loss: 1.2422 | Accuracy: 0.6267 | Precision: 0.4708 | Recall: 0.4931 | F1-Score: 0.4735 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0526 | Eval Loss: 1.2713 | Accuracy: 0.6000 | Precision: 0.4433 | Recall: 0.4907 | F1-Score: 0.4474 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0412 | Eval Loss: 1.2538 | Accuracy: 0.6533 | Precision: 0.5548 | Recall: 0.5512 | F1-Score: 0.5369 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0471 | Eval Loss: 1.2488 | Accuracy: 0.6533 | Precision: 0.5766 | Recall: 0.5612 | F1-Score: 0.5662 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0378 | Eval Loss: 1.2861 | Accuracy: 0.6400 | Precision: 0.5550 | Recall: 0.5443 | F1-Score: 0.5279 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0361 | Eval Loss: 1.2673 | Accuracy: 0.6400 | Precision: 0.6251 | Recall: 0.5698 | F1-Score: 0.5647 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0285 | Eval Loss: 1.2324 | Accuracy: 0.6933 | Precision: 0.6217 | Recall: 0.5917 | F1-Score: 0.5939 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0199 | Eval Loss: 1.2518 | Accuracy: 0.6667 | Precision: 0.5866 | Recall: 0.5705 | F1-Score: 0.5685 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0176 | Eval Loss: 1.2602 | Accuracy: 0.6533 | Precision: 0.5609 | Recall: 0.5512 | F1-Score: 0.5327 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [1:06:21<2:31:26, 567.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        12\n",
      "           1       0.38      0.73      0.50        15\n",
      "           2       0.38      0.33      0.35         9\n",
      "           3       0.14      0.05      0.08        19\n",
      "           4       0.77      0.79      0.78        29\n",
      "\n",
      "    accuracy                           0.54        84\n",
      "   macro avg       0.47      0.50      0.47        84\n",
      "weighted avg       0.50      0.54      0.50        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.334767, test accuracy: 0.5357, test precision: 0.4728, test recall: 0.4991, test F1-score: 0.4692\n",
      "Parámetros:  add 2 1 850\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 2, 'LSTM': 1, 'LSTM_out': 850, 'Loss_final': 1.0176070928573608, 'Accuracy_eval': 0.6258974358974358, 'Precision_eval': 0.49347393151216984, 'Recall_eval': 0.5181242895035998, 'F1_eval': 0.49046664431373344, 'Loss_eval': 1.2601683139801025, 'Loss_tst': 1.33476722240448, 'Accuracy_tst': 0.5357142857142857, 'Precision_tst': 0.4727668308702791, 'Recall_tst': 0.49914700544464613, 'F1_tst': 0.46917778134129084}\n",
      "Entrenando modelo con aggr=add, conv=2, lstm=1,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5130 | Eval Loss: 1.3260 | Accuracy: 0.6133 | Precision: 0.4440 | Recall: 0.4731 | F1-Score: 0.4325 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3350 | Eval Loss: 1.2720 | Accuracy: 0.6267 | Precision: 0.3463 | Recall: 0.5062 | F1-Score: 0.4065 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.2904 | Eval Loss: 1.2793 | Accuracy: 0.6000 | Precision: 0.4178 | Recall: 0.4776 | F1-Score: 0.4345 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2643 | Eval Loss: 1.3022 | Accuracy: 0.5867 | Precision: 0.4253 | Recall: 0.4838 | F1-Score: 0.4357 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2528 | Eval Loss: 1.2999 | Accuracy: 0.6133 | Precision: 0.4535 | Recall: 0.5198 | F1-Score: 0.4592 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2456 | Eval Loss: 1.3028 | Accuracy: 0.5867 | Precision: 0.4216 | Recall: 0.4912 | F1-Score: 0.4384 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2321 | Eval Loss: 1.2819 | Accuracy: 0.6000 | Precision: 0.4209 | Recall: 0.4776 | F1-Score: 0.4401 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2250 | Eval Loss: 1.2799 | Accuracy: 0.6000 | Precision: 0.4230 | Recall: 0.4702 | F1-Score: 0.4375 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2278 | Eval Loss: 1.2921 | Accuracy: 0.5733 | Precision: 0.3977 | Recall: 0.4360 | F1-Score: 0.4044 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2156 | Eval Loss: 1.2906 | Accuracy: 0.6000 | Precision: 0.4277 | Recall: 0.4776 | F1-Score: 0.4462 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2095 | Eval Loss: 1.3041 | Accuracy: 0.5867 | Precision: 0.4129 | Recall: 0.4838 | F1-Score: 0.4343 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2253 | Eval Loss: 1.3104 | Accuracy: 0.5600 | Precision: 0.3856 | Recall: 0.4569 | F1-Score: 0.4048 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2143 | Eval Loss: 1.2870 | Accuracy: 0.6267 | Precision: 0.4548 | Recall: 0.4988 | F1-Score: 0.4696 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.1953 | Eval Loss: 1.3011 | Accuracy: 0.5867 | Precision: 0.4266 | Recall: 0.4707 | F1-Score: 0.4367 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1877 | Eval Loss: 1.2837 | Accuracy: 0.5733 | Precision: 0.5813 | Recall: 0.4746 | F1-Score: 0.4529 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1897 | Eval Loss: 1.2785 | Accuracy: 0.6267 | Precision: 0.5653 | Recall: 0.5310 | F1-Score: 0.5375 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1802 | Eval Loss: 1.2910 | Accuracy: 0.6000 | Precision: 0.4225 | Recall: 0.4702 | F1-Score: 0.4340 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1738 | Eval Loss: 1.2969 | Accuracy: 0.5867 | Precision: 0.4833 | Recall: 0.4888 | F1-Score: 0.4648 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1748 | Eval Loss: 1.2831 | Accuracy: 0.6000 | Precision: 0.4991 | Recall: 0.4957 | F1-Score: 0.4838 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1537 | Eval Loss: 1.2734 | Accuracy: 0.6267 | Precision: 0.5895 | Recall: 0.5202 | F1-Score: 0.5192 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1486 | Eval Loss: 1.2865 | Accuracy: 0.6000 | Precision: 0.4233 | Recall: 0.4776 | F1-Score: 0.4443 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1267 | Eval Loss: 1.2805 | Accuracy: 0.5733 | Precision: 0.4179 | Recall: 0.4638 | F1-Score: 0.4330 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1117 | Eval Loss: 1.2794 | Accuracy: 0.6133 | Precision: 0.5424 | Recall: 0.5207 | F1-Score: 0.5177 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1002 | Eval Loss: 1.2870 | Accuracy: 0.6000 | Precision: 0.5110 | Recall: 0.5138 | F1-Score: 0.5089 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.0971 | Eval Loss: 1.2554 | Accuracy: 0.6533 | Precision: 0.5853 | Recall: 0.5669 | F1-Score: 0.5704 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.0953 | Eval Loss: 1.2560 | Accuracy: 0.6267 | Precision: 0.5581 | Recall: 0.5095 | F1-Score: 0.5039 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.0988 | Eval Loss: 1.2335 | Accuracy: 0.6667 | Precision: 0.5930 | Recall: 0.5581 | F1-Score: 0.5481 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0840 | Eval Loss: 1.2641 | Accuracy: 0.6400 | Precision: 0.5558 | Recall: 0.5624 | F1-Score: 0.5511 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0930 | Eval Loss: 1.2800 | Accuracy: 0.6267 | Precision: 0.5539 | Recall: 0.5653 | F1-Score: 0.5329 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0990 | Eval Loss: 1.2809 | Accuracy: 0.6267 | Precision: 0.6092 | Recall: 0.5612 | F1-Score: 0.5454 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0893 | Eval Loss: 1.2627 | Accuracy: 0.6133 | Precision: 0.6259 | Recall: 0.4879 | F1-Score: 0.4767 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0778 | Eval Loss: 1.2396 | Accuracy: 0.6800 | Precision: 0.5864 | Recall: 0.5717 | F1-Score: 0.5743 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0732 | Eval Loss: 1.2523 | Accuracy: 0.6400 | Precision: 0.5703 | Recall: 0.5650 | F1-Score: 0.5646 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0769 | Eval Loss: 1.2756 | Accuracy: 0.6133 | Precision: 0.4424 | Recall: 0.4902 | F1-Score: 0.4546 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0769 | Eval Loss: 1.2802 | Accuracy: 0.6000 | Precision: 0.4390 | Recall: 0.4907 | F1-Score: 0.4506 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0610 | Eval Loss: 1.2836 | Accuracy: 0.6133 | Precision: 0.4436 | Recall: 0.5050 | F1-Score: 0.4629 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0772 | Eval Loss: 1.2561 | Accuracy: 0.6267 | Precision: 0.4691 | Recall: 0.4914 | F1-Score: 0.4658 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0693 | Eval Loss: 1.2729 | Accuracy: 0.6133 | Precision: 0.4695 | Recall: 0.5124 | F1-Score: 0.4815 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0510 | Eval Loss: 1.2725 | Accuracy: 0.6267 | Precision: 0.5344 | Recall: 0.5350 | F1-Score: 0.5281 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0557 | Eval Loss: 1.2663 | Accuracy: 0.6000 | Precision: 0.4422 | Recall: 0.4571 | F1-Score: 0.4388 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0510 | Eval Loss: 1.2781 | Accuracy: 0.6133 | Precision: 0.4632 | Recall: 0.5050 | F1-Score: 0.4733 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0374 | Eval Loss: 1.2457 | Accuracy: 0.6400 | Precision: 0.5265 | Recall: 0.5369 | F1-Score: 0.5219 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0354 | Eval Loss: 1.2706 | Accuracy: 0.6267 | Precision: 0.4693 | Recall: 0.5045 | F1-Score: 0.4706 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0243 | Eval Loss: 1.2866 | Accuracy: 0.6267 | Precision: 0.4789 | Recall: 0.4988 | F1-Score: 0.4776 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0170 | Eval Loss: 1.2669 | Accuracy: 0.6400 | Precision: 0.4797 | Recall: 0.5188 | F1-Score: 0.4927 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0093 | Eval Loss: 1.2590 | Accuracy: 0.6533 | Precision: 0.5006 | Recall: 0.5331 | F1-Score: 0.4970 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0049 | Eval Loss: 1.2707 | Accuracy: 0.6400 | Precision: 0.4861 | Recall: 0.5262 | F1-Score: 0.5011 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 0.9987 | Eval Loss: 1.2909 | Accuracy: 0.5867 | Precision: 0.4445 | Recall: 0.4576 | F1-Score: 0.4441 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 0.9967 | Eval Loss: 1.2829 | Accuracy: 0.6267 | Precision: 0.4839 | Recall: 0.5119 | F1-Score: 0.4737 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 0.9933 | Eval Loss: 1.2887 | Accuracy: 0.5867 | Precision: 0.4317 | Recall: 0.4765 | F1-Score: 0.4461 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 0.9942 | Eval Loss: 1.2723 | Accuracy: 0.6000 | Precision: 0.4314 | Recall: 0.4702 | F1-Score: 0.4452 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 0.9908 | Eval Loss: 1.2649 | Accuracy: 0.6267 | Precision: 0.4679 | Recall: 0.5045 | F1-Score: 0.4700 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 9/24 [1:16:10<2:23:37, 574.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        12\n",
      "           1       0.33      0.53      0.41        15\n",
      "           2       0.33      0.44      0.38         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.76      0.86      0.81        29\n",
      "\n",
      "    accuracy                           0.52        84\n",
      "   macro avg       0.42      0.48      0.45        84\n",
      "weighted avg       0.46      0.52      0.48        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.355708, test accuracy: 0.5238, test precision: 0.4248, test recall: 0.4846, test F1-score: 0.4468\n",
      "Parámetros:  add 2 1 900\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 2, 'LSTM': 1, 'LSTM_out': 900, 'Loss_final': 0.9907599687576294, 'Accuracy_eval': 0.6133333333333333, 'Precision_eval': 0.48144482985728754, 'Recall_eval': 0.5029727169382343, 'F1_eval': 0.47575566181117346, 'Loss_eval': 1.2649471759796143, 'Loss_tst': 1.3557080030441284, 'Accuracy_tst': 0.5238095238095238, 'Precision_tst': 0.4248484848484848, 'Recall_tst': 0.48463601532567047, 'F1_tst': 0.4468048080951307}\n",
      "Entrenando modelo con aggr=add, conv=2, lstm=2,out_lstm=800\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5523 | Eval Loss: 1.3981 | Accuracy: 0.5600 | Precision: 0.2246 | Recall: 0.3857 | F1-Score: 0.2838 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4138 | Eval Loss: 1.3120 | Accuracy: 0.5733 | Precision: 0.3582 | Recall: 0.4074 | F1-Score: 0.3248 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3262 | Eval Loss: 1.2937 | Accuracy: 0.6000 | Precision: 0.4430 | Recall: 0.4998 | F1-Score: 0.4160 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3536 | Eval Loss: 1.3396 | Accuracy: 0.5733 | Precision: 0.3251 | Recall: 0.4786 | F1-Score: 0.3807 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.3553 | Eval Loss: 1.2979 | Accuracy: 0.6267 | Precision: 0.4492 | Recall: 0.4743 | F1-Score: 0.4057 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.3365 | Eval Loss: 1.3334 | Accuracy: 0.5200 | Precision: 0.3754 | Recall: 0.4215 | F1-Score: 0.3853 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2781 | Eval Loss: 1.3255 | Accuracy: 0.5467 | Precision: 0.3954 | Recall: 0.4541 | F1-Score: 0.4055 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2709 | Eval Loss: 1.3322 | Accuracy: 0.5467 | Precision: 0.3151 | Recall: 0.4386 | F1-Score: 0.3594 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.3001 | Eval Loss: 1.3137 | Accuracy: 0.5733 | Precision: 0.4196 | Recall: 0.4753 | F1-Score: 0.4272 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2799 | Eval Loss: 1.3085 | Accuracy: 0.5733 | Precision: 0.4009 | Recall: 0.4491 | F1-Score: 0.4154 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2497 | Eval Loss: 1.3378 | Accuracy: 0.5467 | Precision: 0.3652 | Recall: 0.4074 | F1-Score: 0.3777 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2471 | Eval Loss: 1.2835 | Accuracy: 0.6000 | Precision: 0.4195 | Recall: 0.4776 | F1-Score: 0.4437 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2451 | Eval Loss: 1.2831 | Accuracy: 0.6267 | Precision: 0.3741 | Recall: 0.5455 | F1-Score: 0.4270 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2631 | Eval Loss: 1.3367 | Accuracy: 0.5333 | Precision: 0.3778 | Recall: 0.4210 | F1-Score: 0.3865 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2282 | Eval Loss: 1.3289 | Accuracy: 0.5867 | Precision: 0.4218 | Recall: 0.4707 | F1-Score: 0.4384 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2124 | Eval Loss: 1.2977 | Accuracy: 0.6267 | Precision: 0.4693 | Recall: 0.5062 | F1-Score: 0.4770 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2055 | Eval Loss: 1.3197 | Accuracy: 0.5600 | Precision: 0.3874 | Recall: 0.4348 | F1-Score: 0.4004 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1967 | Eval Loss: 1.3009 | Accuracy: 0.6000 | Precision: 0.4552 | Recall: 0.5038 | F1-Score: 0.4575 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1975 | Eval Loss: 1.2940 | Accuracy: 0.5867 | Precision: 0.4297 | Recall: 0.4896 | F1-Score: 0.4470 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2119 | Eval Loss: 1.2797 | Accuracy: 0.6133 | Precision: 0.4474 | Recall: 0.4993 | F1-Score: 0.4660 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1960 | Eval Loss: 1.3025 | Accuracy: 0.5867 | Precision: 0.4382 | Recall: 0.4969 | F1-Score: 0.4501 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1927 | Eval Loss: 1.2565 | Accuracy: 0.6267 | Precision: 0.4652 | Recall: 0.5324 | F1-Score: 0.4916 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2066 | Eval Loss: 1.2458 | Accuracy: 0.6533 | Precision: 0.5727 | Recall: 0.5693 | F1-Score: 0.5567 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1976 | Eval Loss: 1.3099 | Accuracy: 0.5867 | Precision: 0.4408 | Recall: 0.5027 | F1-Score: 0.4472 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1897 | Eval Loss: 1.2910 | Accuracy: 0.6000 | Precision: 0.6049 | Recall: 0.4810 | F1-Score: 0.4642 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1922 | Eval Loss: 1.2802 | Accuracy: 0.6133 | Precision: 0.5126 | Recall: 0.5026 | F1-Score: 0.4965 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1701 | Eval Loss: 1.2846 | Accuracy: 0.6267 | Precision: 0.6161 | Recall: 0.5417 | F1-Score: 0.5513 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1849 | Eval Loss: 1.3081 | Accuracy: 0.5733 | Precision: 0.4246 | Recall: 0.4302 | F1-Score: 0.4099 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1975 | Eval Loss: 1.2550 | Accuracy: 0.6400 | Precision: 0.6033 | Recall: 0.5288 | F1-Score: 0.5410 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1999 | Eval Loss: 1.2716 | Accuracy: 0.6267 | Precision: 0.5630 | Recall: 0.5531 | F1-Score: 0.5535 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1528 | Eval Loss: 1.2739 | Accuracy: 0.5867 | Precision: 0.4609 | Recall: 0.4683 | F1-Score: 0.4583 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1562 | Eval Loss: 1.2591 | Accuracy: 0.6267 | Precision: 0.6441 | Recall: 0.5095 | F1-Score: 0.5045 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1588 | Eval Loss: 1.2724 | Accuracy: 0.6267 | Precision: 0.5854 | Recall: 0.5226 | F1-Score: 0.4860 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1420 | Eval Loss: 1.2527 | Accuracy: 0.6267 | Precision: 0.5420 | Recall: 0.5374 | F1-Score: 0.5231 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1375 | Eval Loss: 1.2923 | Accuracy: 0.6133 | Precision: 0.5722 | Recall: 0.5789 | F1-Score: 0.5430 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1271 | Eval Loss: 1.2861 | Accuracy: 0.6400 | Precision: 0.6718 | Recall: 0.5862 | F1-Score: 0.5904 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1443 | Eval Loss: 1.2454 | Accuracy: 0.6800 | Precision: 0.6903 | Recall: 0.5881 | F1-Score: 0.6044 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0991 | Eval Loss: 1.2879 | Accuracy: 0.6000 | Precision: 0.4515 | Recall: 0.5243 | F1-Score: 0.4686 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1035 | Eval Loss: 1.2396 | Accuracy: 0.6933 | Precision: 0.6619 | Recall: 0.6205 | F1-Score: 0.6337 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1065 | Eval Loss: 1.2682 | Accuracy: 0.6267 | Precision: 0.5803 | Recall: 0.5669 | F1-Score: 0.5363 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1020 | Eval Loss: 1.2738 | Accuracy: 0.6267 | Precision: 0.5589 | Recall: 0.5736 | F1-Score: 0.5593 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0941 | Eval Loss: 1.2697 | Accuracy: 0.6400 | Precision: 0.6624 | Recall: 0.5238 | F1-Score: 0.5189 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0991 | Eval Loss: 1.2842 | Accuracy: 0.6000 | Precision: 0.4397 | Recall: 0.4645 | F1-Score: 0.4404 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1186 | Eval Loss: 1.3104 | Accuracy: 0.5733 | Precision: 0.5074 | Recall: 0.5239 | F1-Score: 0.5093 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.1059 | Eval Loss: 1.2978 | Accuracy: 0.5867 | Precision: 0.4207 | Recall: 0.4633 | F1-Score: 0.4229 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0671 | Eval Loss: 1.2746 | Accuracy: 0.6000 | Precision: 0.4399 | Recall: 0.4719 | F1-Score: 0.4498 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0955 | Eval Loss: 1.3041 | Accuracy: 0.5733 | Precision: 0.5186 | Recall: 0.5074 | F1-Score: 0.5008 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0755 | Eval Loss: 1.2669 | Accuracy: 0.6400 | Precision: 0.6083 | Recall: 0.5886 | F1-Score: 0.5652 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0708 | Eval Loss: 1.2768 | Accuracy: 0.6400 | Precision: 0.6649 | Recall: 0.5567 | F1-Score: 0.5599 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0608 | Eval Loss: 1.2811 | Accuracy: 0.6133 | Precision: 0.5790 | Recall: 0.5298 | F1-Score: 0.5331 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0784 | Eval Loss: 1.2717 | Accuracy: 0.6133 | Precision: 0.5388 | Recall: 0.5126 | F1-Score: 0.5199 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0872 | Eval Loss: 1.3037 | Accuracy: 0.6000 | Precision: 0.5926 | Recall: 0.5572 | F1-Score: 0.5237 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 10/24 [1:27:31<2:21:43, 607.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        12\n",
      "           1       0.33      0.67      0.44        15\n",
      "           2       0.29      0.22      0.25         9\n",
      "           3       0.25      0.11      0.15        19\n",
      "           4       0.75      0.72      0.74        29\n",
      "\n",
      "    accuracy                           0.50        84\n",
      "   macro avg       0.45      0.46      0.44        84\n",
      "weighted avg       0.50      0.50      0.48        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.409290, test accuracy: 0.5000, test precision: 0.4511, test recall: 0.4603, test F1-score: 0.4376\n",
      "Parámetros:  add 2 2 800\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 2, 'LSTM': 2, 'LSTM_out': 800, 'Loss_final': 1.087217926979065, 'Accuracy_eval': 0.6025641025641026, 'Precision_eval': 0.4901365115893033, 'Recall_eval': 0.5029911898446382, 'F1_eval': 0.471892301025893, 'Loss_eval': 1.3037190437316895, 'Loss_tst': 1.4092897176742554, 'Accuracy_tst': 0.5, 'Precision_tst': 0.4510822510822511, 'Recall_tst': 0.46032466223028834, 'F1_tst': 0.43762607000593273}\n",
      "Entrenando modelo con aggr=add, conv=2, lstm=2,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5492 | Eval Loss: 1.3694 | Accuracy: 0.5600 | Precision: 0.2171 | Recall: 0.3857 | F1-Score: 0.2775 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4012 | Eval Loss: 1.3051 | Accuracy: 0.6000 | Precision: 0.3342 | Recall: 0.4793 | F1-Score: 0.3859 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3210 | Eval Loss: 1.2861 | Accuracy: 0.6400 | Precision: 0.5030 | Recall: 0.5279 | F1-Score: 0.4714 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3162 | Eval Loss: 1.2751 | Accuracy: 0.6000 | Precision: 0.4082 | Recall: 0.4571 | F1-Score: 0.4262 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2886 | Eval Loss: 1.2760 | Accuracy: 0.6267 | Precision: 0.4486 | Recall: 0.5324 | F1-Score: 0.4589 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2805 | Eval Loss: 1.3362 | Accuracy: 0.5200 | Precision: 0.3773 | Recall: 0.4215 | F1-Score: 0.3876 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2587 | Eval Loss: 1.2908 | Accuracy: 0.5867 | Precision: 0.3933 | Recall: 0.4633 | F1-Score: 0.4141 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2659 | Eval Loss: 1.3305 | Accuracy: 0.5467 | Precision: 0.3835 | Recall: 0.4181 | F1-Score: 0.3981 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2502 | Eval Loss: 1.3211 | Accuracy: 0.5867 | Precision: 0.4276 | Recall: 0.4838 | F1-Score: 0.4408 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2449 | Eval Loss: 1.3190 | Accuracy: 0.5600 | Precision: 0.3732 | Recall: 0.4569 | F1-Score: 0.3899 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2625 | Eval Loss: 1.3248 | Accuracy: 0.5733 | Precision: 0.4495 | Recall: 0.5105 | F1-Score: 0.4527 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2580 | Eval Loss: 1.3584 | Accuracy: 0.5333 | Precision: 0.3863 | Recall: 0.4489 | F1-Score: 0.4040 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2773 | Eval Loss: 1.2749 | Accuracy: 0.6133 | Precision: 0.4376 | Recall: 0.4976 | F1-Score: 0.4577 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2345 | Eval Loss: 1.3316 | Accuracy: 0.5600 | Precision: 0.3911 | Recall: 0.4496 | F1-Score: 0.4098 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2274 | Eval Loss: 1.3212 | Accuracy: 0.5867 | Precision: 0.4198 | Recall: 0.5043 | F1-Score: 0.4337 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2387 | Eval Loss: 1.3674 | Accuracy: 0.5333 | Precision: 0.3932 | Recall: 0.4546 | F1-Score: 0.4014 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2769 | Eval Loss: 1.3887 | Accuracy: 0.4933 | Precision: 0.3893 | Recall: 0.4339 | F1-Score: 0.3850 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2775 | Eval Loss: 1.3241 | Accuracy: 0.5733 | Precision: 0.4007 | Recall: 0.4229 | F1-Score: 0.4027 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2995 | Eval Loss: 1.3807 | Accuracy: 0.5067 | Precision: 0.3649 | Recall: 0.4072 | F1-Score: 0.3758 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2634 | Eval Loss: 1.3153 | Accuracy: 0.5867 | Precision: 0.4765 | Recall: 0.5117 | F1-Score: 0.4338 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2749 | Eval Loss: 1.2745 | Accuracy: 0.6000 | Precision: 0.4344 | Recall: 0.4850 | F1-Score: 0.4505 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2365 | Eval Loss: 1.3138 | Accuracy: 0.5733 | Precision: 0.4043 | Recall: 0.4491 | F1-Score: 0.4176 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2108 | Eval Loss: 1.3444 | Accuracy: 0.5467 | Precision: 0.3994 | Recall: 0.4598 | F1-Score: 0.3975 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.2239 | Eval Loss: 1.3034 | Accuracy: 0.5867 | Precision: 0.4103 | Recall: 0.4560 | F1-Score: 0.4263 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1975 | Eval Loss: 1.3175 | Accuracy: 0.5467 | Precision: 0.4534 | Recall: 0.4419 | F1-Score: 0.4441 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2029 | Eval Loss: 1.3204 | Accuracy: 0.5733 | Precision: 0.4384 | Recall: 0.4958 | F1-Score: 0.4380 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1967 | Eval Loss: 1.3065 | Accuracy: 0.5867 | Precision: 0.3957 | Recall: 0.4560 | F1-Score: 0.3980 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.2074 | Eval Loss: 1.2462 | Accuracy: 0.6533 | Precision: 0.5765 | Recall: 0.5948 | F1-Score: 0.5531 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1982 | Eval Loss: 1.3079 | Accuracy: 0.6000 | Precision: 0.5533 | Recall: 0.5179 | F1-Score: 0.5005 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1882 | Eval Loss: 1.3026 | Accuracy: 0.5733 | Precision: 0.5134 | Recall: 0.5058 | F1-Score: 0.4925 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1860 | Eval Loss: 1.3094 | Accuracy: 0.5733 | Precision: 0.4923 | Recall: 0.4877 | F1-Score: 0.4688 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1672 | Eval Loss: 1.3235 | Accuracy: 0.5733 | Precision: 0.5929 | Recall: 0.4476 | F1-Score: 0.4614 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.2001 | Eval Loss: 1.2896 | Accuracy: 0.6000 | Precision: 0.4426 | Recall: 0.4645 | F1-Score: 0.4416 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.2112 | Eval Loss: 1.2898 | Accuracy: 0.6267 | Precision: 0.6072 | Recall: 0.5145 | F1-Score: 0.5335 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.2121 | Eval Loss: 1.3545 | Accuracy: 0.5200 | Precision: 0.4745 | Recall: 0.4863 | F1-Score: 0.4480 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1719 | Eval Loss: 1.2759 | Accuracy: 0.6267 | Precision: 0.5561 | Recall: 0.5662 | F1-Score: 0.5581 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1490 | Eval Loss: 1.3117 | Accuracy: 0.5867 | Precision: 0.4354 | Recall: 0.4707 | F1-Score: 0.4385 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1439 | Eval Loss: 1.3267 | Accuracy: 0.5467 | Precision: 0.3888 | Recall: 0.4222 | F1-Score: 0.3927 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1613 | Eval Loss: 1.2903 | Accuracy: 0.6133 | Precision: 0.6438 | Recall: 0.5600 | F1-Score: 0.5413 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1432 | Eval Loss: 1.3076 | Accuracy: 0.5467 | Precision: 0.4895 | Recall: 0.5044 | F1-Score: 0.4891 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1372 | Eval Loss: 1.2531 | Accuracy: 0.6533 | Precision: 0.5812 | Recall: 0.5455 | F1-Score: 0.5253 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1215 | Eval Loss: 1.2751 | Accuracy: 0.6267 | Precision: 0.5464 | Recall: 0.5293 | F1-Score: 0.5335 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.1176 | Eval Loss: 1.3062 | Accuracy: 0.5867 | Precision: 0.4925 | Recall: 0.4872 | F1-Score: 0.4675 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1050 | Eval Loss: 1.2852 | Accuracy: 0.6267 | Precision: 0.5787 | Recall: 0.5769 | F1-Score: 0.5707 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0908 | Eval Loss: 1.2654 | Accuracy: 0.6133 | Precision: 0.5409 | Recall: 0.4952 | F1-Score: 0.4783 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0914 | Eval Loss: 1.2549 | Accuracy: 0.6533 | Precision: 0.6617 | Recall: 0.5750 | F1-Score: 0.5652 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0998 | Eval Loss: 1.2991 | Accuracy: 0.5733 | Precision: 0.5025 | Recall: 0.4927 | F1-Score: 0.4923 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.1399 | Eval Loss: 1.4504 | Accuracy: 0.4267 | Precision: 0.4044 | Recall: 0.4158 | F1-Score: 0.3703 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.1723 | Eval Loss: 1.3520 | Accuracy: 0.5333 | Precision: 0.4863 | Recall: 0.4925 | F1-Score: 0.4736 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.1407 | Eval Loss: 1.2391 | Accuracy: 0.6667 | Precision: 0.6040 | Recall: 0.5845 | F1-Score: 0.5901 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0941 | Eval Loss: 1.3323 | Accuracy: 0.5733 | Precision: 0.6238 | Recall: 0.5065 | F1-Score: 0.4717 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0949 | Eval Loss: 1.2990 | Accuracy: 0.5600 | Precision: 0.6029 | Recall: 0.4932 | F1-Score: 0.4952 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [1:40:24<2:22:35, 658.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67        12\n",
      "           1       0.41      0.80      0.55        15\n",
      "           2       0.33      0.22      0.27         9\n",
      "           3       0.20      0.05      0.08        19\n",
      "           4       0.79      0.79      0.79        29\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.47      0.52      0.47        84\n",
      "weighted avg       0.51      0.56      0.51        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.343284, test accuracy: 0.5595, test precision: 0.4680, test recall: 0.5236, test F1-score: 0.4710\n",
      "Parámetros:  add 2 2 850\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 2, 'LSTM': 2, 'LSTM_out': 850, 'Loss_final': 1.0948878526687622, 'Accuracy_eval': 0.5794871794871794, 'Precision_eval': 0.4673549895914392, 'Recall_eval': 0.4855357142857141, 'F1_eval': 0.4525366948770818, 'Loss_eval': 1.299035906791687, 'Loss_tst': 1.3432843685150146, 'Accuracy_tst': 0.5595238095238095, 'Precision_tst': 0.46804597701149425, 'Recall_tst': 0.5235914498890905, 'F1_tst': 0.4710449320794147}\n",
      "Entrenando modelo con aggr=add, conv=2, lstm=2,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5485 | Eval Loss: 1.3590 | Accuracy: 0.5600 | Precision: 0.2156 | Recall: 0.3857 | F1-Score: 0.2749 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3986 | Eval Loss: 1.3268 | Accuracy: 0.5867 | Precision: 0.3347 | Recall: 0.4724 | F1-Score: 0.3809 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3285 | Eval Loss: 1.2710 | Accuracy: 0.6400 | Precision: 0.5522 | Recall: 0.5205 | F1-Score: 0.4381 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3072 | Eval Loss: 1.3569 | Accuracy: 0.5467 | Precision: 0.4601 | Recall: 0.5041 | F1-Score: 0.4062 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.3131 | Eval Loss: 1.3456 | Accuracy: 0.5600 | Precision: 0.3533 | Recall: 0.4398 | F1-Score: 0.3710 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.3195 | Eval Loss: 1.3615 | Accuracy: 0.5333 | Precision: 0.4140 | Recall: 0.4677 | F1-Score: 0.3997 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.3018 | Eval Loss: 1.2927 | Accuracy: 0.6133 | Precision: 0.4411 | Recall: 0.4936 | F1-Score: 0.4617 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2764 | Eval Loss: 1.3160 | Accuracy: 0.5600 | Precision: 0.4038 | Recall: 0.4422 | F1-Score: 0.4078 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2579 | Eval Loss: 1.3379 | Accuracy: 0.5200 | Precision: 0.3470 | Recall: 0.3805 | F1-Score: 0.3549 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2674 | Eval Loss: 1.2657 | Accuracy: 0.6267 | Precision: 0.4692 | Recall: 0.5136 | F1-Score: 0.4605 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2435 | Eval Loss: 1.3222 | Accuracy: 0.5600 | Precision: 0.4057 | Recall: 0.4684 | F1-Score: 0.4200 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2421 | Eval Loss: 1.3230 | Accuracy: 0.5467 | Precision: 0.3724 | Recall: 0.4279 | F1-Score: 0.3852 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2398 | Eval Loss: 1.2613 | Accuracy: 0.6133 | Precision: 0.4357 | Recall: 0.4919 | F1-Score: 0.4598 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2288 | Eval Loss: 1.3121 | Accuracy: 0.5733 | Precision: 0.3984 | Recall: 0.4302 | F1-Score: 0.4076 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2201 | Eval Loss: 1.3168 | Accuracy: 0.5733 | Precision: 0.3991 | Recall: 0.4417 | F1-Score: 0.4129 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2419 | Eval Loss: 1.3049 | Accuracy: 0.6000 | Precision: 0.6034 | Recall: 0.4998 | F1-Score: 0.4636 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2028 | Eval Loss: 1.2700 | Accuracy: 0.6267 | Precision: 0.5576 | Recall: 0.5769 | F1-Score: 0.5622 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2134 | Eval Loss: 1.2363 | Accuracy: 0.6533 | Precision: 0.6450 | Recall: 0.5414 | F1-Score: 0.5361 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2195 | Eval Loss: 1.2935 | Accuracy: 0.6000 | Precision: 0.5279 | Recall: 0.5279 | F1-Score: 0.5193 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2582 | Eval Loss: 1.3066 | Accuracy: 0.6000 | Precision: 0.6505 | Recall: 0.5277 | F1-Score: 0.4933 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2125 | Eval Loss: 1.3132 | Accuracy: 0.5600 | Precision: 0.4008 | Recall: 0.4438 | F1-Score: 0.4179 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2276 | Eval Loss: 1.2756 | Accuracy: 0.6000 | Precision: 0.5509 | Recall: 0.5122 | F1-Score: 0.5032 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2122 | Eval Loss: 1.3132 | Accuracy: 0.6133 | Precision: 0.6050 | Recall: 0.5905 | F1-Score: 0.5488 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.2178 | Eval Loss: 1.2754 | Accuracy: 0.6267 | Precision: 0.6531 | Recall: 0.5276 | F1-Score: 0.5418 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.2005 | Eval Loss: 1.2698 | Accuracy: 0.6133 | Precision: 0.5633 | Recall: 0.5322 | F1-Score: 0.5120 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1941 | Eval Loss: 1.2799 | Accuracy: 0.6000 | Precision: 0.6228 | Recall: 0.5065 | F1-Score: 0.5144 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1747 | Eval Loss: 1.2898 | Accuracy: 0.6133 | Precision: 0.5635 | Recall: 0.5315 | F1-Score: 0.5383 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1798 | Eval Loss: 1.3520 | Accuracy: 0.5733 | Precision: 0.5170 | Recall: 0.5386 | F1-Score: 0.5178 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.2382 | Eval Loss: 1.3288 | Accuracy: 0.5600 | Precision: 0.5990 | Recall: 0.4784 | F1-Score: 0.4801 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.2296 | Eval Loss: 1.2811 | Accuracy: 0.6000 | Precision: 0.5418 | Recall: 0.5115 | F1-Score: 0.5163 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.2114 | Eval Loss: 1.2619 | Accuracy: 0.6667 | Precision: 0.5843 | Recall: 0.5967 | F1-Score: 0.5797 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1889 | Eval Loss: 1.3176 | Accuracy: 0.5867 | Precision: 0.5359 | Recall: 0.5727 | F1-Score: 0.5400 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1753 | Eval Loss: 1.2777 | Accuracy: 0.6133 | Precision: 0.5723 | Recall: 0.5207 | F1-Score: 0.5236 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1407 | Eval Loss: 1.2672 | Accuracy: 0.6133 | Precision: 0.6506 | Recall: 0.5419 | F1-Score: 0.5090 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1335 | Eval Loss: 1.2882 | Accuracy: 0.6400 | Precision: 0.6428 | Recall: 0.5912 | F1-Score: 0.6043 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1624 | Eval Loss: 1.2533 | Accuracy: 0.6667 | Precision: 0.6664 | Recall: 0.5681 | F1-Score: 0.5917 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1819 | Eval Loss: 1.2944 | Accuracy: 0.5867 | Precision: 0.4464 | Recall: 0.4969 | F1-Score: 0.4551 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1882 | Eval Loss: 1.2620 | Accuracy: 0.6267 | Precision: 0.5775 | Recall: 0.5696 | F1-Score: 0.5665 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1396 | Eval Loss: 1.2264 | Accuracy: 0.6933 | Precision: 0.6792 | Recall: 0.6443 | F1-Score: 0.6516 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0988 | Eval Loss: 1.2622 | Accuracy: 0.6667 | Precision: 0.6436 | Recall: 0.6386 | F1-Score: 0.6225 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1197 | Eval Loss: 1.2538 | Accuracy: 0.6533 | Precision: 0.5954 | Recall: 0.5743 | F1-Score: 0.5790 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1256 | Eval Loss: 1.3045 | Accuracy: 0.6000 | Precision: 0.6168 | Recall: 0.4802 | F1-Score: 0.4950 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.1442 | Eval Loss: 1.2977 | Accuracy: 0.5733 | Precision: 0.4577 | Recall: 0.4507 | F1-Score: 0.4074 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1746 | Eval Loss: 1.2684 | Accuracy: 0.6667 | Precision: 0.6946 | Recall: 0.6379 | F1-Score: 0.5676 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.1728 | Eval Loss: 1.2202 | Accuracy: 0.7067 | Precision: 0.6872 | Recall: 0.6274 | F1-Score: 0.6390 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.1248 | Eval Loss: 1.2769 | Accuracy: 0.6267 | Precision: 0.6294 | Recall: 0.5383 | F1-Score: 0.5483 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.1065 | Eval Loss: 1.2661 | Accuracy: 0.6133 | Precision: 0.6289 | Recall: 0.5265 | F1-Score: 0.5226 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0821 | Eval Loss: 1.2848 | Accuracy: 0.6133 | Precision: 0.6325 | Recall: 0.5453 | F1-Score: 0.5250 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0805 | Eval Loss: 1.2719 | Accuracy: 0.6400 | Precision: 0.6098 | Recall: 0.5452 | F1-Score: 0.5493 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0845 | Eval Loss: 1.2529 | Accuracy: 0.6267 | Precision: 0.5969 | Recall: 0.5424 | F1-Score: 0.5437 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0787 | Eval Loss: 1.2502 | Accuracy: 0.6533 | Precision: 0.6122 | Recall: 0.5817 | F1-Score: 0.5846 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0873 | Eval Loss: 1.2716 | Accuracy: 0.6000 | Precision: 0.5374 | Recall: 0.4957 | F1-Score: 0.4846 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 12/24 [1:54:21<2:22:28, 712.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        12\n",
      "           1       0.41      0.73      0.52        15\n",
      "           2       0.22      0.22      0.22         9\n",
      "           3       1.00      0.05      0.10        19\n",
      "           4       0.73      0.93      0.82        29\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.59      0.49      0.44        84\n",
      "weighted avg       0.66      0.56      0.50        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.346402, test accuracy: 0.5595, test precision: 0.5919, test recall: 0.4878, test F1-score: 0.4419\n",
      "Parámetros:  add 2 2 900\n",
      "Resultados:  {'Aggr': 'add', 'Conv': 2, 'LSTM': 2, 'LSTM_out': 900, 'Loss_final': 1.087317705154419, 'Accuracy_eval': 0.6074358974358974, 'Precision_eval': 0.5365677414335959, 'Recall_eval': 0.5194851269420235, 'F1_eval': 0.4960879593483896, 'Loss_eval': 1.2715829610824585, 'Loss_tst': 1.3464021682739258, 'Accuracy_tst': 0.5595238095238095, 'Precision_tst': 0.5918718718718718, 'Recall_tst': 0.487844323452309, 'F1_tst': 0.44193362193362196}\n",
      "Entrenando modelo con aggr=mean, conv=1, lstm=1,out_lstm=800\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5093 | Eval Loss: 1.3388 | Accuracy: 0.6267 | Precision: 0.3748 | Recall: 0.4800 | F1-Score: 0.3990 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3573 | Eval Loss: 1.2853 | Accuracy: 0.6133 | Precision: 0.3421 | Recall: 0.4993 | F1-Score: 0.3990 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3154 | Eval Loss: 1.3019 | Accuracy: 0.6133 | Precision: 0.5540 | Recall: 0.5198 | F1-Score: 0.4313 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2875 | Eval Loss: 1.2996 | Accuracy: 0.6133 | Precision: 0.4894 | Recall: 0.5198 | F1-Score: 0.4489 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2688 | Eval Loss: 1.2717 | Accuracy: 0.6267 | Precision: 0.4405 | Recall: 0.5062 | F1-Score: 0.4659 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2497 | Eval Loss: 1.2770 | Accuracy: 0.6133 | Precision: 0.4307 | Recall: 0.4845 | F1-Score: 0.4507 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2324 | Eval Loss: 1.2722 | Accuracy: 0.6267 | Precision: 0.4471 | Recall: 0.4988 | F1-Score: 0.4682 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2250 | Eval Loss: 1.2795 | Accuracy: 0.6000 | Precision: 0.4290 | Recall: 0.4776 | F1-Score: 0.4476 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2159 | Eval Loss: 1.2898 | Accuracy: 0.6000 | Precision: 0.4296 | Recall: 0.4907 | F1-Score: 0.4537 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2230 | Eval Loss: 1.2797 | Accuracy: 0.6000 | Precision: 0.4370 | Recall: 0.4924 | F1-Score: 0.4302 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2283 | Eval Loss: 1.2827 | Accuracy: 0.6133 | Precision: 0.4328 | Recall: 0.4845 | F1-Score: 0.4514 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2084 | Eval Loss: 1.2845 | Accuracy: 0.6267 | Precision: 0.4584 | Recall: 0.5062 | F1-Score: 0.4755 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.1978 | Eval Loss: 1.2683 | Accuracy: 0.6000 | Precision: 0.4383 | Recall: 0.4776 | F1-Score: 0.4523 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.1976 | Eval Loss: 1.2807 | Accuracy: 0.5867 | Precision: 0.4081 | Recall: 0.4707 | F1-Score: 0.4264 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1922 | Eval Loss: 1.2897 | Accuracy: 0.6000 | Precision: 0.5442 | Recall: 0.5088 | F1-Score: 0.4905 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1755 | Eval Loss: 1.2769 | Accuracy: 0.6400 | Precision: 0.6707 | Recall: 0.5443 | F1-Score: 0.5300 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1590 | Eval Loss: 1.2758 | Accuracy: 0.6267 | Precision: 0.6393 | Recall: 0.5095 | F1-Score: 0.5012 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1566 | Eval Loss: 1.2953 | Accuracy: 0.5867 | Precision: 0.4080 | Recall: 0.4560 | F1-Score: 0.4188 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1613 | Eval Loss: 1.2634 | Accuracy: 0.6667 | Precision: 0.6930 | Recall: 0.5688 | F1-Score: 0.5632 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1488 | Eval Loss: 1.2645 | Accuracy: 0.6400 | Precision: 0.5646 | Recall: 0.5600 | F1-Score: 0.5440 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1460 | Eval Loss: 1.2668 | Accuracy: 0.6267 | Precision: 0.6576 | Recall: 0.5300 | F1-Score: 0.5158 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1159 | Eval Loss: 1.2637 | Accuracy: 0.6400 | Precision: 0.6822 | Recall: 0.5312 | F1-Score: 0.5198 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1129 | Eval Loss: 1.2594 | Accuracy: 0.6533 | Precision: 0.6761 | Recall: 0.5586 | F1-Score: 0.5429 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1030 | Eval Loss: 1.2580 | Accuracy: 0.6400 | Precision: 0.5711 | Recall: 0.5443 | F1-Score: 0.5274 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.0882 | Eval Loss: 1.2503 | Accuracy: 0.6533 | Precision: 0.5676 | Recall: 0.5586 | F1-Score: 0.5433 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.0870 | Eval Loss: 1.2520 | Accuracy: 0.6267 | Precision: 0.4671 | Recall: 0.5119 | F1-Score: 0.4741 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.0761 | Eval Loss: 1.2404 | Accuracy: 0.6400 | Precision: 0.5642 | Recall: 0.5369 | F1-Score: 0.5225 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0854 | Eval Loss: 1.2382 | Accuracy: 0.6533 | Precision: 0.5604 | Recall: 0.5562 | F1-Score: 0.5535 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0799 | Eval Loss: 1.2486 | Accuracy: 0.6533 | Precision: 0.5897 | Recall: 0.5512 | F1-Score: 0.5363 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0737 | Eval Loss: 1.2436 | Accuracy: 0.6400 | Precision: 0.5921 | Recall: 0.5526 | F1-Score: 0.5540 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0713 | Eval Loss: 1.2503 | Accuracy: 0.6400 | Precision: 0.4851 | Recall: 0.5262 | F1-Score: 0.4933 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0601 | Eval Loss: 1.2506 | Accuracy: 0.6533 | Precision: 0.5985 | Recall: 0.5619 | F1-Score: 0.5559 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0532 | Eval Loss: 1.2478 | Accuracy: 0.6400 | Precision: 0.5471 | Recall: 0.5493 | F1-Score: 0.5439 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0571 | Eval Loss: 1.2309 | Accuracy: 0.6667 | Precision: 0.6910 | Recall: 0.5762 | F1-Score: 0.5781 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0588 | Eval Loss: 1.2552 | Accuracy: 0.6400 | Precision: 0.5756 | Recall: 0.5369 | F1-Score: 0.5186 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0573 | Eval Loss: 1.2609 | Accuracy: 0.6533 | Precision: 0.4889 | Recall: 0.5536 | F1-Score: 0.5110 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0841 | Eval Loss: 1.2413 | Accuracy: 0.6400 | Precision: 0.5594 | Recall: 0.5419 | F1-Score: 0.5370 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0947 | Eval Loss: 1.2458 | Accuracy: 0.6533 | Precision: 0.5939 | Recall: 0.5669 | F1-Score: 0.5602 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0706 | Eval Loss: 1.2493 | Accuracy: 0.6267 | Precision: 0.5232 | Recall: 0.5169 | F1-Score: 0.5068 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0650 | Eval Loss: 1.2318 | Accuracy: 0.6667 | Precision: 0.5838 | Recall: 0.5581 | F1-Score: 0.5445 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0623 | Eval Loss: 1.2410 | Accuracy: 0.6533 | Precision: 0.5950 | Recall: 0.5586 | F1-Score: 0.5439 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0454 | Eval Loss: 1.2398 | Accuracy: 0.6667 | Precision: 0.5836 | Recall: 0.5812 | F1-Score: 0.5816 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0450 | Eval Loss: 1.2404 | Accuracy: 0.6533 | Precision: 0.5763 | Recall: 0.5512 | F1-Score: 0.5362 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0371 | Eval Loss: 1.2280 | Accuracy: 0.6667 | Precision: 0.6223 | Recall: 0.5762 | F1-Score: 0.5747 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0315 | Eval Loss: 1.2409 | Accuracy: 0.6800 | Precision: 0.6017 | Recall: 0.5774 | F1-Score: 0.5790 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0300 | Eval Loss: 1.2349 | Accuracy: 0.6800 | Precision: 0.6382 | Recall: 0.5831 | F1-Score: 0.5827 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0260 | Eval Loss: 1.2332 | Accuracy: 0.6933 | Precision: 0.6311 | Recall: 0.5867 | F1-Score: 0.5752 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0202 | Eval Loss: 1.2713 | Accuracy: 0.6400 | Precision: 0.5443 | Recall: 0.5517 | F1-Score: 0.5356 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0251 | Eval Loss: 1.2371 | Accuracy: 0.6667 | Precision: 0.6081 | Recall: 0.5886 | F1-Score: 0.5868 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0192 | Eval Loss: 1.2323 | Accuracy: 0.6800 | Precision: 0.6091 | Recall: 0.5724 | F1-Score: 0.5602 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0134 | Eval Loss: 1.2439 | Accuracy: 0.6533 | Precision: 0.5875 | Recall: 0.5586 | F1-Score: 0.5436 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0134 | Eval Loss: 1.2137 | Accuracy: 0.7067 | Precision: 0.6615 | Recall: 0.6117 | F1-Score: 0.6127 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 13/24 [2:00:32<1:51:38, 608.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70        12\n",
      "           1       0.43      0.60      0.50        15\n",
      "           2       0.44      0.44      0.44         9\n",
      "           3       0.56      0.26      0.36        19\n",
      "           4       0.74      0.86      0.79        29\n",
      "\n",
      "    accuracy                           0.61        84\n",
      "   macro avg       0.58      0.57      0.56        84\n",
      "weighted avg       0.61      0.61      0.59        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.296082, test accuracy: 0.6071, test precision: 0.5782, test recall: 0.5673, test F1-score: 0.5582\n",
      "Parámetros:  mean 1 1 800\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 1, 'LSTM': 1, 'LSTM_out': 800, 'Loss_final': 1.0133885145187378, 'Accuracy_eval': 0.6397435897435897, 'Precision_eval': 0.5474031690437263, 'Recall_eval': 0.5360164835164836, 'F1_eval': 0.5134393969054734, 'Loss_eval': 1.2137041091918945, 'Loss_tst': 1.2960824966430664, 'Accuracy_tst': 0.6071428571428571, 'Precision_tst': 0.578227654698243, 'Recall_tst': 0.5672675942730389, 'F1_tst': 0.5581780538302278}\n",
      "Entrenando modelo con aggr=mean, conv=1, lstm=1,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5097 | Eval Loss: 1.3382 | Accuracy: 0.5867 | Precision: 0.5087 | Recall: 0.4445 | F1-Score: 0.3826 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3529 | Eval Loss: 1.2903 | Accuracy: 0.6133 | Precision: 0.3420 | Recall: 0.4993 | F1-Score: 0.3988 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3037 | Eval Loss: 1.2979 | Accuracy: 0.5867 | Precision: 0.4357 | Recall: 0.4912 | F1-Score: 0.4394 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2767 | Eval Loss: 1.2984 | Accuracy: 0.5867 | Precision: 0.4319 | Recall: 0.4912 | F1-Score: 0.4381 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2620 | Eval Loss: 1.2877 | Accuracy: 0.6133 | Precision: 0.4348 | Recall: 0.4919 | F1-Score: 0.4586 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2409 | Eval Loss: 1.2767 | Accuracy: 0.6133 | Precision: 0.4345 | Recall: 0.4845 | F1-Score: 0.4538 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2307 | Eval Loss: 1.2802 | Accuracy: 0.6400 | Precision: 0.4670 | Recall: 0.5131 | F1-Score: 0.4821 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2186 | Eval Loss: 1.2884 | Accuracy: 0.6267 | Precision: 0.4548 | Recall: 0.4988 | F1-Score: 0.4696 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2210 | Eval Loss: 1.2901 | Accuracy: 0.5600 | Precision: 0.3794 | Recall: 0.4422 | F1-Score: 0.4048 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2295 | Eval Loss: 1.2812 | Accuracy: 0.5867 | Precision: 0.4052 | Recall: 0.4633 | F1-Score: 0.4295 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2154 | Eval Loss: 1.2790 | Accuracy: 0.6267 | Precision: 0.4548 | Recall: 0.4988 | F1-Score: 0.4696 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.1975 | Eval Loss: 1.2931 | Accuracy: 0.5733 | Precision: 0.4350 | Recall: 0.4565 | F1-Score: 0.4344 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.1931 | Eval Loss: 1.2707 | Accuracy: 0.6133 | Precision: 0.4375 | Recall: 0.4993 | F1-Score: 0.4574 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.1975 | Eval Loss: 1.2823 | Accuracy: 0.6000 | Precision: 0.5153 | Recall: 0.4957 | F1-Score: 0.4739 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1821 | Eval Loss: 1.2800 | Accuracy: 0.6400 | Precision: 0.6580 | Recall: 0.5238 | F1-Score: 0.5148 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1595 | Eval Loss: 1.2620 | Accuracy: 0.6400 | Precision: 0.6625 | Recall: 0.5238 | F1-Score: 0.5188 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1464 | Eval Loss: 1.2606 | Accuracy: 0.6667 | Precision: 0.6007 | Recall: 0.5738 | F1-Score: 0.5759 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1367 | Eval Loss: 1.2718 | Accuracy: 0.6000 | Precision: 0.5540 | Recall: 0.5138 | F1-Score: 0.5097 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1310 | Eval Loss: 1.2408 | Accuracy: 0.6667 | Precision: 0.6901 | Recall: 0.5705 | F1-Score: 0.5784 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1184 | Eval Loss: 1.2714 | Accuracy: 0.6267 | Precision: 0.6513 | Recall: 0.5095 | F1-Score: 0.4969 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1242 | Eval Loss: 1.2568 | Accuracy: 0.6267 | Precision: 0.6517 | Recall: 0.5169 | F1-Score: 0.5090 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1167 | Eval Loss: 1.2677 | Accuracy: 0.6133 | Precision: 0.5282 | Recall: 0.5157 | F1-Score: 0.4883 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1222 | Eval Loss: 1.2813 | Accuracy: 0.6133 | Precision: 0.5155 | Recall: 0.5231 | F1-Score: 0.4985 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1170 | Eval Loss: 1.2645 | Accuracy: 0.6667 | Precision: 0.6090 | Recall: 0.5886 | F1-Score: 0.5870 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1056 | Eval Loss: 1.2337 | Accuracy: 0.6800 | Precision: 0.6676 | Recall: 0.5881 | F1-Score: 0.5989 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1031 | Eval Loss: 1.2425 | Accuracy: 0.6667 | Precision: 0.6117 | Recall: 0.5598 | F1-Score: 0.5519 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.0812 | Eval Loss: 1.2561 | Accuracy: 0.6533 | Precision: 0.5843 | Recall: 0.5586 | F1-Score: 0.5409 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0880 | Eval Loss: 1.2270 | Accuracy: 0.7067 | Precision: 0.6536 | Recall: 0.6217 | F1-Score: 0.6308 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0823 | Eval Loss: 1.2425 | Accuracy: 0.6667 | Precision: 0.6054 | Recall: 0.5524 | F1-Score: 0.5422 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0667 | Eval Loss: 1.2449 | Accuracy: 0.6800 | Precision: 0.6200 | Recall: 0.5872 | F1-Score: 0.5727 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0607 | Eval Loss: 1.2329 | Accuracy: 0.6400 | Precision: 0.5513 | Recall: 0.5362 | F1-Score: 0.5363 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0687 | Eval Loss: 1.2522 | Accuracy: 0.6533 | Precision: 0.5709 | Recall: 0.5512 | F1-Score: 0.5320 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0542 | Eval Loss: 1.2565 | Accuracy: 0.6400 | Precision: 0.5696 | Recall: 0.5443 | F1-Score: 0.5282 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0466 | Eval Loss: 1.2180 | Accuracy: 0.6933 | Precision: 0.6627 | Recall: 0.5917 | F1-Score: 0.5990 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0441 | Eval Loss: 1.2346 | Accuracy: 0.6667 | Precision: 0.6117 | Recall: 0.5655 | F1-Score: 0.5493 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0340 | Eval Loss: 1.2235 | Accuracy: 0.6800 | Precision: 0.6020 | Recall: 0.5667 | F1-Score: 0.5584 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0341 | Eval Loss: 1.2436 | Accuracy: 0.6267 | Precision: 0.5511 | Recall: 0.5169 | F1-Score: 0.5075 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0360 | Eval Loss: 1.2280 | Accuracy: 0.6933 | Precision: 0.6519 | Recall: 0.6155 | F1-Score: 0.6156 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0298 | Eval Loss: 1.2489 | Accuracy: 0.6667 | Precision: 0.6070 | Recall: 0.5524 | F1-Score: 0.5437 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0287 | Eval Loss: 1.2399 | Accuracy: 0.6667 | Precision: 0.5667 | Recall: 0.5655 | F1-Score: 0.5510 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0225 | Eval Loss: 1.2456 | Accuracy: 0.6400 | Precision: 0.5433 | Recall: 0.5419 | F1-Score: 0.5397 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0238 | Eval Loss: 1.2442 | Accuracy: 0.6533 | Precision: 0.5798 | Recall: 0.5307 | F1-Score: 0.5211 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0180 | Eval Loss: 1.2434 | Accuracy: 0.6533 | Precision: 0.5891 | Recall: 0.5512 | F1-Score: 0.5353 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0120 | Eval Loss: 1.2518 | Accuracy: 0.6400 | Precision: 0.5509 | Recall: 0.5517 | F1-Score: 0.5358 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0186 | Eval Loss: 1.2179 | Accuracy: 0.7067 | Precision: 0.6903 | Recall: 0.6167 | F1-Score: 0.6320 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0112 | Eval Loss: 1.2438 | Accuracy: 0.6933 | Precision: 0.6342 | Recall: 0.5941 | F1-Score: 0.5780 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0093 | Eval Loss: 1.2154 | Accuracy: 0.7067 | Precision: 0.6243 | Recall: 0.6191 | F1-Score: 0.6140 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0135 | Eval Loss: 1.2237 | Accuracy: 0.6800 | Precision: 0.5081 | Recall: 0.5486 | F1-Score: 0.5253 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0150 | Eval Loss: 1.2705 | Accuracy: 0.6133 | Precision: 0.5418 | Recall: 0.5305 | F1-Score: 0.5083 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0109 | Eval Loss: 1.2498 | Accuracy: 0.6533 | Precision: 0.5111 | Recall: 0.5479 | F1-Score: 0.5148 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0061 | Eval Loss: 1.2432 | Accuracy: 0.6667 | Precision: 0.5961 | Recall: 0.5524 | F1-Score: 0.5449 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0025 | Eval Loss: 1.2801 | Accuracy: 0.6267 | Precision: 0.5776 | Recall: 0.5374 | F1-Score: 0.5200 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 14/24 [2:06:14<1:28:04, 528.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57        12\n",
      "           1       0.38      0.67      0.49        15\n",
      "           2       0.30      0.33      0.32         9\n",
      "           3       0.57      0.21      0.31        19\n",
      "           4       0.75      0.83      0.79        29\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.53      0.51      0.49        84\n",
      "weighted avg       0.58      0.56      0.54        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.335266, test accuracy: 0.5595, test precision: 0.5345, test recall: 0.5076, test F1-score: 0.4939\n",
      "Parámetros:  mean 1 1 850\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 1, 'LSTM': 1, 'LSTM_out': 850, 'Loss_final': 1.0024833679199219, 'Accuracy_eval': 0.6423076923076922, 'Precision_eval': 0.5556125761971829, 'Recall_eval': 0.5370367563471011, 'F1_eval': 0.5191807535472064, 'Loss_eval': 1.2800781726837158, 'Loss_tst': 1.335265874862671, 'Accuracy_tst': 0.5595238095238095, 'Precision_tst': 0.5345421245421246, 'Recall_tst': 0.507622504537205, 'F1_tst': 0.49392009535110193}\n",
      "Entrenando modelo con aggr=mean, conv=1, lstm=1,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5073 | Eval Loss: 1.3373 | Accuracy: 0.5867 | Precision: 0.3193 | Recall: 0.4502 | F1-Score: 0.3706 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3487 | Eval Loss: 1.2858 | Accuracy: 0.6267 | Precision: 0.3473 | Recall: 0.5062 | F1-Score: 0.4068 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.2919 | Eval Loss: 1.2902 | Accuracy: 0.6400 | Precision: 0.5623 | Recall: 0.5484 | F1-Score: 0.4821 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2684 | Eval Loss: 1.3061 | Accuracy: 0.5733 | Precision: 0.4369 | Recall: 0.4917 | F1-Score: 0.4075 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2582 | Eval Loss: 1.2999 | Accuracy: 0.6000 | Precision: 0.4443 | Recall: 0.4998 | F1-Score: 0.4608 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2482 | Eval Loss: 1.2924 | Accuracy: 0.6267 | Precision: 0.4580 | Recall: 0.5193 | F1-Score: 0.4767 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2402 | Eval Loss: 1.2826 | Accuracy: 0.6133 | Precision: 0.4304 | Recall: 0.4845 | F1-Score: 0.4518 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2303 | Eval Loss: 1.3073 | Accuracy: 0.5733 | Precision: 0.3978 | Recall: 0.4417 | F1-Score: 0.4062 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2309 | Eval Loss: 1.2755 | Accuracy: 0.6267 | Precision: 0.4438 | Recall: 0.4988 | F1-Score: 0.4672 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2212 | Eval Loss: 1.2700 | Accuracy: 0.6533 | Precision: 0.4693 | Recall: 0.5274 | F1-Score: 0.4952 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2103 | Eval Loss: 1.2955 | Accuracy: 0.6133 | Precision: 0.4479 | Recall: 0.5050 | F1-Score: 0.4667 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2050 | Eval Loss: 1.2955 | Accuracy: 0.6267 | Precision: 0.4511 | Recall: 0.5193 | F1-Score: 0.4779 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2108 | Eval Loss: 1.3124 | Accuracy: 0.5600 | Precision: 0.3792 | Recall: 0.4553 | F1-Score: 0.4024 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2193 | Eval Loss: 1.3014 | Accuracy: 0.5867 | Precision: 0.4048 | Recall: 0.4838 | F1-Score: 0.4091 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2239 | Eval Loss: 1.2725 | Accuracy: 0.6400 | Precision: 0.4654 | Recall: 0.5188 | F1-Score: 0.4830 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2041 | Eval Loss: 1.2887 | Accuracy: 0.6133 | Precision: 0.4345 | Recall: 0.4845 | F1-Score: 0.4538 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1961 | Eval Loss: 1.2697 | Accuracy: 0.6267 | Precision: 0.4438 | Recall: 0.4988 | F1-Score: 0.4672 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1864 | Eval Loss: 1.2875 | Accuracy: 0.6133 | Precision: 0.4382 | Recall: 0.5050 | F1-Score: 0.4615 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1887 | Eval Loss: 1.2705 | Accuracy: 0.6267 | Precision: 0.4427 | Recall: 0.4988 | F1-Score: 0.4678 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1910 | Eval Loss: 1.2980 | Accuracy: 0.6133 | Precision: 0.4410 | Recall: 0.4845 | F1-Score: 0.4524 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1808 | Eval Loss: 1.2832 | Accuracy: 0.6133 | Precision: 0.4475 | Recall: 0.4845 | F1-Score: 0.4497 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1815 | Eval Loss: 1.2690 | Accuracy: 0.6667 | Precision: 0.4984 | Recall: 0.5605 | F1-Score: 0.5145 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1797 | Eval Loss: 1.2686 | Accuracy: 0.6133 | Precision: 0.4221 | Recall: 0.4976 | F1-Score: 0.4515 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1822 | Eval Loss: 1.2909 | Accuracy: 0.5733 | Precision: 0.4053 | Recall: 0.4491 | F1-Score: 0.4142 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1637 | Eval Loss: 1.2655 | Accuracy: 0.6400 | Precision: 0.4707 | Recall: 0.5057 | F1-Score: 0.4754 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1731 | Eval Loss: 1.2824 | Accuracy: 0.6133 | Precision: 0.4545 | Recall: 0.4919 | F1-Score: 0.4685 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1512 | Eval Loss: 1.2894 | Accuracy: 0.5867 | Precision: 0.4264 | Recall: 0.4781 | F1-Score: 0.4488 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1394 | Eval Loss: 1.2956 | Accuracy: 0.6000 | Precision: 0.4882 | Recall: 0.4957 | F1-Score: 0.4794 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1240 | Eval Loss: 1.2870 | Accuracy: 0.6000 | Precision: 0.4529 | Recall: 0.4981 | F1-Score: 0.4707 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1213 | Eval Loss: 1.2804 | Accuracy: 0.6000 | Precision: 0.4552 | Recall: 0.4907 | F1-Score: 0.4558 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1159 | Eval Loss: 1.2934 | Accuracy: 0.6000 | Precision: 0.4632 | Recall: 0.5055 | F1-Score: 0.4764 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1123 | Eval Loss: 1.2740 | Accuracy: 0.6267 | Precision: 0.4825 | Recall: 0.5136 | F1-Score: 0.4898 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1012 | Eval Loss: 1.2604 | Accuracy: 0.6133 | Precision: 0.4596 | Recall: 0.4845 | F1-Score: 0.4569 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1112 | Eval Loss: 1.2788 | Accuracy: 0.6000 | Precision: 0.4852 | Recall: 0.4645 | F1-Score: 0.4437 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1352 | Eval Loss: 1.2678 | Accuracy: 0.6400 | Precision: 0.5693 | Recall: 0.5493 | F1-Score: 0.5429 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1006 | Eval Loss: 1.2492 | Accuracy: 0.6533 | Precision: 0.5245 | Recall: 0.5348 | F1-Score: 0.5199 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0887 | Eval Loss: 1.2475 | Accuracy: 0.6533 | Precision: 0.5511 | Recall: 0.5381 | F1-Score: 0.5331 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0899 | Eval Loss: 1.2511 | Accuracy: 0.6533 | Precision: 0.5776 | Recall: 0.5381 | F1-Score: 0.5307 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0873 | Eval Loss: 1.2646 | Accuracy: 0.6267 | Precision: 0.4592 | Recall: 0.5119 | F1-Score: 0.4797 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0792 | Eval Loss: 1.2679 | Accuracy: 0.6400 | Precision: 0.5008 | Recall: 0.5336 | F1-Score: 0.4989 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0702 | Eval Loss: 1.2556 | Accuracy: 0.6400 | Precision: 0.5022 | Recall: 0.5131 | F1-Score: 0.4991 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0584 | Eval Loss: 1.2477 | Accuracy: 0.6400 | Precision: 0.5622 | Recall: 0.5493 | F1-Score: 0.5469 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0538 | Eval Loss: 1.2412 | Accuracy: 0.6533 | Precision: 0.5839 | Recall: 0.5619 | F1-Score: 0.5588 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0519 | Eval Loss: 1.2540 | Accuracy: 0.6800 | Precision: 0.5740 | Recall: 0.5724 | F1-Score: 0.5581 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0488 | Eval Loss: 1.2620 | Accuracy: 0.6267 | Precision: 0.4780 | Recall: 0.5119 | F1-Score: 0.4816 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0379 | Eval Loss: 1.2550 | Accuracy: 0.6267 | Precision: 0.5647 | Recall: 0.5226 | F1-Score: 0.5043 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0398 | Eval Loss: 1.2485 | Accuracy: 0.6400 | Precision: 0.4949 | Recall: 0.5262 | F1-Score: 0.4902 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0439 | Eval Loss: 1.2588 | Accuracy: 0.6533 | Precision: 0.5873 | Recall: 0.5693 | F1-Score: 0.5635 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0381 | Eval Loss: 1.2473 | Accuracy: 0.6267 | Precision: 0.5378 | Recall: 0.5424 | F1-Score: 0.5389 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0440 | Eval Loss: 1.2425 | Accuracy: 0.6400 | Precision: 0.4966 | Recall: 0.5000 | F1-Score: 0.4795 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0437 | Eval Loss: 1.2491 | Accuracy: 0.6667 | Precision: 0.5178 | Recall: 0.5548 | F1-Score: 0.5228 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0271 | Eval Loss: 1.2539 | Accuracy: 0.6533 | Precision: 0.4954 | Recall: 0.5479 | F1-Score: 0.5156 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 15/24 [2:12:40<1:12:48, 485.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        12\n",
      "           1       0.38      0.67      0.49        15\n",
      "           2       0.40      0.22      0.29         9\n",
      "           3       0.29      0.11      0.15        19\n",
      "           4       0.75      0.83      0.79        29\n",
      "\n",
      "    accuracy                           0.57        84\n",
      "   macro avg       0.51      0.53      0.50        84\n",
      "weighted avg       0.54      0.57      0.53        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.313837, test accuracy: 0.5714, test precision: 0.5069, test recall: 0.5310, test F1-score: 0.4967\n",
      "Parámetros:  mean 1 1 900\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 1, 'LSTM': 1, 'LSTM_out': 900, 'Loss_final': 1.027050495147705, 'Accuracy_eval': 0.6230769230769232, 'Precision_eval': 0.47398547431344934, 'Recall_eval': 0.5100004736642668, 'F1_eval': 0.47742697636536574, 'Loss_eval': 1.2538886070251465, 'Loss_tst': 1.313836693763733, 'Accuracy_tst': 0.5714285714285714, 'Precision_tst': 0.5069230769230769, 'Recall_tst': 0.5310143174027021, 'F1_tst': 0.49669626654832566}\n",
      "Entrenando modelo con aggr=mean, conv=1, lstm=2,out_lstm=800\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5509 | Eval Loss: 1.4020 | Accuracy: 0.5733 | Precision: 0.2250 | Recall: 0.4000 | F1-Score: 0.2824 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4113 | Eval Loss: 1.3252 | Accuracy: 0.5467 | Precision: 0.2986 | Recall: 0.4124 | F1-Score: 0.3237 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3381 | Eval Loss: 1.2815 | Accuracy: 0.6133 | Precision: 0.3413 | Recall: 0.4993 | F1-Score: 0.4003 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3044 | Eval Loss: 1.2736 | Accuracy: 0.6400 | Precision: 0.4365 | Recall: 0.5057 | F1-Score: 0.4490 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.3003 | Eval Loss: 1.2904 | Accuracy: 0.6000 | Precision: 0.4141 | Recall: 0.4702 | F1-Score: 0.4353 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2812 | Eval Loss: 1.3127 | Accuracy: 0.6133 | Precision: 0.4160 | Recall: 0.5198 | F1-Score: 0.4333 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2730 | Eval Loss: 1.2978 | Accuracy: 0.5867 | Precision: 0.4002 | Recall: 0.5043 | F1-Score: 0.4210 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2681 | Eval Loss: 1.2817 | Accuracy: 0.6133 | Precision: 0.4428 | Recall: 0.4919 | F1-Score: 0.4603 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2521 | Eval Loss: 1.3367 | Accuracy: 0.5467 | Precision: 0.3913 | Recall: 0.4746 | F1-Score: 0.3955 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2878 | Eval Loss: 1.3219 | Accuracy: 0.5733 | Precision: 0.4458 | Recall: 0.5105 | F1-Score: 0.4528 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2805 | Eval Loss: 1.2739 | Accuracy: 0.6400 | Precision: 0.4784 | Recall: 0.5598 | F1-Score: 0.4556 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.3167 | Eval Loss: 1.3255 | Accuracy: 0.5600 | Precision: 0.3886 | Recall: 0.4217 | F1-Score: 0.3871 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2647 | Eval Loss: 1.3074 | Accuracy: 0.5733 | Precision: 0.3981 | Recall: 0.4491 | F1-Score: 0.4135 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2284 | Eval Loss: 1.2879 | Accuracy: 0.5867 | Precision: 0.4107 | Recall: 0.4707 | F1-Score: 0.4361 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2544 | Eval Loss: 1.3013 | Accuracy: 0.6000 | Precision: 0.4227 | Recall: 0.4850 | F1-Score: 0.4468 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2483 | Eval Loss: 1.3346 | Accuracy: 0.5333 | Precision: 0.3608 | Recall: 0.4005 | F1-Score: 0.3603 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2433 | Eval Loss: 1.3280 | Accuracy: 0.5600 | Precision: 0.3766 | Recall: 0.4160 | F1-Score: 0.3900 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2711 | Eval Loss: 1.2871 | Accuracy: 0.6267 | Precision: 0.4588 | Recall: 0.5381 | F1-Score: 0.4830 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2573 | Eval Loss: 1.2822 | Accuracy: 0.6267 | Precision: 0.4384 | Recall: 0.5455 | F1-Score: 0.4483 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2924 | Eval Loss: 1.2780 | Accuracy: 0.6267 | Precision: 0.4572 | Recall: 0.5193 | F1-Score: 0.4632 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2343 | Eval Loss: 1.3061 | Accuracy: 0.5733 | Precision: 0.4082 | Recall: 0.4753 | F1-Score: 0.4277 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2040 | Eval Loss: 1.3355 | Accuracy: 0.5600 | Precision: 0.4158 | Recall: 0.4627 | F1-Score: 0.4221 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2147 | Eval Loss: 1.2985 | Accuracy: 0.6000 | Precision: 0.4363 | Recall: 0.5112 | F1-Score: 0.4629 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.2400 | Eval Loss: 1.3446 | Accuracy: 0.5600 | Precision: 0.4260 | Recall: 0.4700 | F1-Score: 0.4227 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.2628 | Eval Loss: 1.3360 | Accuracy: 0.5467 | Precision: 0.3836 | Recall: 0.3960 | F1-Score: 0.3770 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2253 | Eval Loss: 1.3221 | Accuracy: 0.5733 | Precision: 0.6047 | Recall: 0.4803 | F1-Score: 0.4573 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.2012 | Eval Loss: 1.3013 | Accuracy: 0.5867 | Precision: 0.5100 | Recall: 0.4962 | F1-Score: 0.4882 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1978 | Eval Loss: 1.3161 | Accuracy: 0.5867 | Precision: 0.4357 | Recall: 0.4969 | F1-Score: 0.4508 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.2177 | Eval Loss: 1.2937 | Accuracy: 0.6133 | Precision: 0.4763 | Recall: 0.4788 | F1-Score: 0.4694 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.2042 | Eval Loss: 1.2768 | Accuracy: 0.6133 | Precision: 0.6399 | Recall: 0.5157 | F1-Score: 0.5016 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1904 | Eval Loss: 1.3020 | Accuracy: 0.5867 | Precision: 0.4396 | Recall: 0.4781 | F1-Score: 0.4546 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1837 | Eval Loss: 1.3080 | Accuracy: 0.5733 | Precision: 0.6043 | Recall: 0.4672 | F1-Score: 0.4549 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1842 | Eval Loss: 1.3207 | Accuracy: 0.5467 | Precision: 0.5778 | Recall: 0.4527 | F1-Score: 0.4693 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.2103 | Eval Loss: 1.3004 | Accuracy: 0.5733 | Precision: 0.4843 | Recall: 0.4819 | F1-Score: 0.4605 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1689 | Eval Loss: 1.2822 | Accuracy: 0.6133 | Precision: 0.4367 | Recall: 0.4845 | F1-Score: 0.4555 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1527 | Eval Loss: 1.2756 | Accuracy: 0.6133 | Precision: 0.5395 | Recall: 0.5315 | F1-Score: 0.5291 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1674 | Eval Loss: 1.2601 | Accuracy: 0.6400 | Precision: 0.6514 | Recall: 0.5181 | F1-Score: 0.5137 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1915 | Eval Loss: 1.3325 | Accuracy: 0.5600 | Precision: 0.4897 | Recall: 0.4908 | F1-Score: 0.4868 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1802 | Eval Loss: 1.2856 | Accuracy: 0.6267 | Precision: 0.5557 | Recall: 0.5736 | F1-Score: 0.5584 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.2242 | Eval Loss: 1.2586 | Accuracy: 0.6400 | Precision: 0.4714 | Recall: 0.5000 | F1-Score: 0.4774 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.2262 | Eval Loss: 1.3399 | Accuracy: 0.5600 | Precision: 0.6029 | Recall: 0.4341 | F1-Score: 0.4355 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.2862 | Eval Loss: 1.2839 | Accuracy: 0.6133 | Precision: 0.6493 | Recall: 0.5231 | F1-Score: 0.5071 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.2295 | Eval Loss: 1.3555 | Accuracy: 0.5067 | Precision: 0.4465 | Recall: 0.4327 | F1-Score: 0.4089 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1721 | Eval Loss: 1.2906 | Accuracy: 0.6000 | Precision: 0.5198 | Recall: 0.5286 | F1-Score: 0.5207 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.1669 | Eval Loss: 1.2557 | Accuracy: 0.6400 | Precision: 0.6543 | Recall: 0.5419 | F1-Score: 0.5416 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.1655 | Eval Loss: 1.3210 | Accuracy: 0.5467 | Precision: 0.3808 | Recall: 0.4279 | F1-Score: 0.3986 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.1818 | Eval Loss: 1.2731 | Accuracy: 0.6533 | Precision: 0.5896 | Recall: 0.5569 | F1-Score: 0.5437 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.1568 | Eval Loss: 1.2609 | Accuracy: 0.6267 | Precision: 0.5337 | Recall: 0.5505 | F1-Score: 0.5239 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.1451 | Eval Loss: 1.2489 | Accuracy: 0.6667 | Precision: 0.6176 | Recall: 0.5886 | F1-Score: 0.5965 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.1529 | Eval Loss: 1.2531 | Accuracy: 0.6400 | Precision: 0.6608 | Recall: 0.5238 | F1-Score: 0.5214 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.1241 | Eval Loss: 1.2532 | Accuracy: 0.6800 | Precision: 0.6633 | Recall: 0.6086 | F1-Score: 0.6173 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.1222 | Eval Loss: 1.2831 | Accuracy: 0.6267 | Precision: 0.5561 | Recall: 0.5431 | F1-Score: 0.5124 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [2:21:47<1:07:13, 504.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69        12\n",
      "           1       0.39      0.80      0.52        15\n",
      "           2       0.20      0.11      0.14         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.76      0.90      0.83        29\n",
      "\n",
      "    accuracy                           0.57        84\n",
      "   macro avg       0.40      0.51      0.44        84\n",
      "weighted avg       0.45      0.57      0.49        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.321662, test accuracy: 0.5714, test precision: 0.3989, test recall: 0.5115, test F1-score: 0.4365\n",
      "Parámetros:  mean 1 2 800\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 1, 'LSTM': 2, 'LSTM_out': 800, 'Loss_final': 1.1221727132797241, 'Accuracy_eval': 0.5958974358974359, 'Precision_eval': 0.47813851386317957, 'Recall_eval': 0.49261557408109125, 'F1_eval': 0.457789347055944, 'Loss_eval': 1.2831307649612427, 'Loss_tst': 1.3216619491577148, 'Accuracy_tst': 0.5714285714285714, 'Precision_tst': 0.3989319598807265, 'Recall_tst': 0.5115325670498084, 'F1_tst': 0.43646015819928874}\n",
      "Entrenando modelo con aggr=mean, conv=1, lstm=2,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5551 | Eval Loss: 1.3943 | Accuracy: 0.5733 | Precision: 0.2265 | Recall: 0.4000 | F1-Score: 0.2826 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4038 | Eval Loss: 1.3035 | Accuracy: 0.6133 | Precision: 0.3388 | Recall: 0.4919 | F1-Score: 0.3995 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3199 | Eval Loss: 1.2824 | Accuracy: 0.6400 | Precision: 0.5520 | Recall: 0.5205 | F1-Score: 0.4379 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3072 | Eval Loss: 1.3036 | Accuracy: 0.5867 | Precision: 0.3748 | Recall: 0.4724 | F1-Score: 0.4088 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2880 | Eval Loss: 1.2920 | Accuracy: 0.6400 | Precision: 0.4913 | Recall: 0.5803 | F1-Score: 0.4910 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2957 | Eval Loss: 1.3217 | Accuracy: 0.5733 | Precision: 0.3935 | Recall: 0.4712 | F1-Score: 0.4177 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.3296 | Eval Loss: 1.3212 | Accuracy: 0.5333 | Precision: 0.3769 | Recall: 0.4227 | F1-Score: 0.3977 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2804 | Eval Loss: 1.3174 | Accuracy: 0.5600 | Precision: 0.3952 | Recall: 0.4422 | F1-Score: 0.4068 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2515 | Eval Loss: 1.3202 | Accuracy: 0.5733 | Precision: 0.4055 | Recall: 0.4433 | F1-Score: 0.4157 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2517 | Eval Loss: 1.3295 | Accuracy: 0.5600 | Precision: 0.3825 | Recall: 0.4274 | F1-Score: 0.3920 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2516 | Eval Loss: 1.3148 | Accuracy: 0.5467 | Precision: 0.3893 | Recall: 0.4222 | F1-Score: 0.3976 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2495 | Eval Loss: 1.2990 | Accuracy: 0.5867 | Precision: 0.4837 | Recall: 0.5069 | F1-Score: 0.4652 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2494 | Eval Loss: 1.2805 | Accuracy: 0.6267 | Precision: 0.5461 | Recall: 0.5350 | F1-Score: 0.5382 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2173 | Eval Loss: 1.2959 | Accuracy: 0.5733 | Precision: 0.6103 | Recall: 0.4803 | F1-Score: 0.4617 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2103 | Eval Loss: 1.3009 | Accuracy: 0.5867 | Precision: 0.4370 | Recall: 0.5027 | F1-Score: 0.4490 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2297 | Eval Loss: 1.2965 | Accuracy: 0.5733 | Precision: 0.4111 | Recall: 0.4638 | F1-Score: 0.4264 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2177 | Eval Loss: 1.2569 | Accuracy: 0.6400 | Precision: 0.5800 | Recall: 0.5526 | F1-Score: 0.5602 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2084 | Eval Loss: 1.3272 | Accuracy: 0.5733 | Precision: 0.4243 | Recall: 0.4753 | F1-Score: 0.4275 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2043 | Eval Loss: 1.3264 | Accuracy: 0.5600 | Precision: 0.4908 | Recall: 0.4915 | F1-Score: 0.4852 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1951 | Eval Loss: 1.2706 | Accuracy: 0.6000 | Precision: 0.5150 | Recall: 0.5065 | F1-Score: 0.4981 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1788 | Eval Loss: 1.2984 | Accuracy: 0.6133 | Precision: 0.6088 | Recall: 0.5667 | F1-Score: 0.5534 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1645 | Eval Loss: 1.2838 | Accuracy: 0.6400 | Precision: 0.6518 | Recall: 0.5657 | F1-Score: 0.5751 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1566 | Eval Loss: 1.2562 | Accuracy: 0.6533 | Precision: 0.5795 | Recall: 0.5817 | F1-Score: 0.5796 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1557 | Eval Loss: 1.2844 | Accuracy: 0.6267 | Precision: 0.5982 | Recall: 0.5605 | F1-Score: 0.5637 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1331 | Eval Loss: 1.3338 | Accuracy: 0.5467 | Precision: 0.4862 | Recall: 0.5084 | F1-Score: 0.4804 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1622 | Eval Loss: 1.3010 | Accuracy: 0.6133 | Precision: 0.5693 | Recall: 0.5798 | F1-Score: 0.5571 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1754 | Eval Loss: 1.2853 | Accuracy: 0.6000 | Precision: 0.5458 | Recall: 0.5682 | F1-Score: 0.5429 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1611 | Eval Loss: 1.3205 | Accuracy: 0.5733 | Precision: 0.5906 | Recall: 0.4598 | F1-Score: 0.4438 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1459 | Eval Loss: 1.2881 | Accuracy: 0.6000 | Precision: 0.5247 | Recall: 0.4933 | F1-Score: 0.4967 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1520 | Eval Loss: 1.2638 | Accuracy: 0.6400 | Precision: 0.6115 | Recall: 0.5731 | F1-Score: 0.5659 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1443 | Eval Loss: 1.2804 | Accuracy: 0.6133 | Precision: 0.5598 | Recall: 0.5963 | F1-Score: 0.5600 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1214 | Eval Loss: 1.3040 | Accuracy: 0.6267 | Precision: 0.5699 | Recall: 0.5753 | F1-Score: 0.5622 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1592 | Eval Loss: 1.2791 | Accuracy: 0.6267 | Precision: 0.6516 | Recall: 0.5424 | F1-Score: 0.5496 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1313 | Eval Loss: 1.3111 | Accuracy: 0.6000 | Precision: 0.5602 | Recall: 0.5689 | F1-Score: 0.5477 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1193 | Eval Loss: 1.3250 | Accuracy: 0.5600 | Precision: 0.5166 | Recall: 0.4989 | F1-Score: 0.4865 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1273 | Eval Loss: 1.2360 | Accuracy: 0.6667 | Precision: 0.6507 | Recall: 0.6198 | F1-Score: 0.6209 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0977 | Eval Loss: 1.2647 | Accuracy: 0.6400 | Precision: 0.6169 | Recall: 0.5919 | F1-Score: 0.5788 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0820 | Eval Loss: 1.3095 | Accuracy: 0.5733 | Precision: 0.5131 | Recall: 0.5189 | F1-Score: 0.4992 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0845 | Eval Loss: 1.3054 | Accuracy: 0.5867 | Precision: 0.5296 | Recall: 0.5479 | F1-Score: 0.5241 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1046 | Eval Loss: 1.2595 | Accuracy: 0.6533 | Precision: 0.5989 | Recall: 0.6129 | F1-Score: 0.6018 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1083 | Eval Loss: 1.3075 | Accuracy: 0.5600 | Precision: 0.4613 | Recall: 0.4529 | F1-Score: 0.4401 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1061 | Eval Loss: 1.2823 | Accuracy: 0.6133 | Precision: 0.5610 | Recall: 0.5600 | F1-Score: 0.5385 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0705 | Eval Loss: 1.2812 | Accuracy: 0.6133 | Precision: 0.5543 | Recall: 0.5717 | F1-Score: 0.5560 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0814 | Eval Loss: 1.3271 | Accuracy: 0.5600 | Precision: 0.4959 | Recall: 0.4703 | F1-Score: 0.4757 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0995 | Eval Loss: 1.3088 | Accuracy: 0.5867 | Precision: 0.5317 | Recall: 0.5570 | F1-Score: 0.5226 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.1069 | Eval Loss: 1.2940 | Accuracy: 0.5867 | Precision: 0.5286 | Recall: 0.5332 | F1-Score: 0.5139 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0886 | Eval Loss: 1.2960 | Accuracy: 0.6000 | Precision: 0.5793 | Recall: 0.5377 | F1-Score: 0.5344 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0890 | Eval Loss: 1.3287 | Accuracy: 0.5467 | Precision: 0.4726 | Recall: 0.4715 | F1-Score: 0.4620 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0848 | Eval Loss: 1.2948 | Accuracy: 0.5867 | Precision: 0.5506 | Recall: 0.5348 | F1-Score: 0.5234 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0594 | Eval Loss: 1.2696 | Accuracy: 0.6267 | Precision: 0.5860 | Recall: 0.5703 | F1-Score: 0.5335 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0710 | Eval Loss: 1.3301 | Accuracy: 0.5867 | Precision: 0.5236 | Recall: 0.5308 | F1-Score: 0.5181 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0634 | Eval Loss: 1.2941 | Accuracy: 0.6133 | Precision: 0.5452 | Recall: 0.5674 | F1-Score: 0.5439 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [2:30:28<59:23, 509.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        12\n",
      "           1       0.39      0.73      0.51        15\n",
      "           2       0.25      0.22      0.24         9\n",
      "           3       0.14      0.05      0.08        19\n",
      "           4       0.73      0.76      0.75        29\n",
      "\n",
      "    accuracy                           0.51        84\n",
      "   macro avg       0.43      0.47      0.44        84\n",
      "weighted avg       0.47      0.51      0.48        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.361353, test accuracy: 0.5119, test precision: 0.4311, test recall: 0.4700, test F1-score: 0.4357\n",
      "Parámetros:  mean 1 2 850\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 1, 'LSTM': 2, 'LSTM_out': 850, 'Loss_final': 1.063355565071106, 'Accuracy_eval': 0.5971794871794871, 'Precision_eval': 0.5143905563320422, 'Recall_eval': 0.5210884804850322, 'F1_eval': 0.4963426380590586, 'Loss_eval': 1.294084072113037, 'Loss_tst': 1.3613531589508057, 'Accuracy_tst': 0.5119047619047619, 'Precision_tst': 0.43108225108225107, 'Recall_tst': 0.4700282314982859, 'F1_tst': 0.43566069311704}\n",
      "Entrenando modelo con aggr=mean, conv=1, lstm=2,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5496 | Eval Loss: 1.3853 | Accuracy: 0.5600 | Precision: 0.2209 | Recall: 0.3857 | F1-Score: 0.2746 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4107 | Eval Loss: 1.2985 | Accuracy: 0.6133 | Precision: 0.3437 | Recall: 0.4731 | F1-Score: 0.3878 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3273 | Eval Loss: 1.3040 | Accuracy: 0.5867 | Precision: 0.4467 | Recall: 0.4667 | F1-Score: 0.3977 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.3239 | Eval Loss: 1.3053 | Accuracy: 0.6133 | Precision: 0.5407 | Recall: 0.4993 | F1-Score: 0.4216 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2856 | Eval Loss: 1.2737 | Accuracy: 0.6400 | Precision: 0.5572 | Recall: 0.5262 | F1-Score: 0.4405 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2708 | Eval Loss: 1.3176 | Accuracy: 0.5600 | Precision: 0.3676 | Recall: 0.4381 | F1-Score: 0.3938 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2696 | Eval Loss: 1.2937 | Accuracy: 0.5867 | Precision: 0.4235 | Recall: 0.5174 | F1-Score: 0.4389 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.3413 | Eval Loss: 1.3320 | Accuracy: 0.5600 | Precision: 0.2786 | Recall: 0.4062 | F1-Score: 0.3245 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.3226 | Eval Loss: 1.3097 | Accuracy: 0.5867 | Precision: 0.3589 | Recall: 0.5027 | F1-Score: 0.3987 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2645 | Eval Loss: 1.3024 | Accuracy: 0.5867 | Precision: 0.4154 | Recall: 0.4633 | F1-Score: 0.4304 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2443 | Eval Loss: 1.2750 | Accuracy: 0.6000 | Precision: 0.4064 | Recall: 0.4702 | F1-Score: 0.4304 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2292 | Eval Loss: 1.2893 | Accuracy: 0.6000 | Precision: 0.4222 | Recall: 0.4965 | F1-Score: 0.4429 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2669 | Eval Loss: 1.2944 | Accuracy: 0.6000 | Precision: 0.4218 | Recall: 0.4850 | F1-Score: 0.4398 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2420 | Eval Loss: 1.2813 | Accuracy: 0.6267 | Precision: 0.4418 | Recall: 0.5307 | F1-Score: 0.4565 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2265 | Eval Loss: 1.3140 | Accuracy: 0.5733 | Precision: 0.4140 | Recall: 0.4827 | F1-Score: 0.4272 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2335 | Eval Loss: 1.3113 | Accuracy: 0.5467 | Precision: 0.3970 | Recall: 0.4427 | F1-Score: 0.4082 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2175 | Eval Loss: 1.3385 | Accuracy: 0.5467 | Precision: 0.3976 | Recall: 0.4427 | F1-Score: 0.4078 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2313 | Eval Loss: 1.3890 | Accuracy: 0.5200 | Precision: 0.4291 | Recall: 0.4682 | F1-Score: 0.4113 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2521 | Eval Loss: 1.3420 | Accuracy: 0.5333 | Precision: 0.4093 | Recall: 0.4432 | F1-Score: 0.4117 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2804 | Eval Loss: 1.3250 | Accuracy: 0.5600 | Precision: 0.4024 | Recall: 0.4381 | F1-Score: 0.4163 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2309 | Eval Loss: 1.3513 | Accuracy: 0.5467 | Precision: 0.4166 | Recall: 0.4820 | F1-Score: 0.4253 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2290 | Eval Loss: 1.3113 | Accuracy: 0.5867 | Precision: 0.6133 | Recall: 0.4815 | F1-Score: 0.4722 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2181 | Eval Loss: 1.2904 | Accuracy: 0.6000 | Precision: 0.5291 | Recall: 0.5015 | F1-Score: 0.4803 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.2289 | Eval Loss: 1.3178 | Accuracy: 0.5733 | Precision: 0.5781 | Recall: 0.4467 | F1-Score: 0.4360 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.2130 | Eval Loss: 1.2750 | Accuracy: 0.6267 | Precision: 0.6520 | Recall: 0.5169 | F1-Score: 0.5092 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2124 | Eval Loss: 1.2926 | Accuracy: 0.6133 | Precision: 0.5710 | Recall: 0.5167 | F1-Score: 0.5152 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.2192 | Eval Loss: 1.3178 | Accuracy: 0.5467 | Precision: 0.4036 | Recall: 0.3960 | F1-Score: 0.3822 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.2313 | Eval Loss: 1.2853 | Accuracy: 0.6267 | Precision: 0.4696 | Recall: 0.4988 | F1-Score: 0.4716 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.2069 | Eval Loss: 1.2916 | Accuracy: 0.6133 | Precision: 0.6322 | Recall: 0.5083 | F1-Score: 0.4905 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1979 | Eval Loss: 1.2653 | Accuracy: 0.6133 | Precision: 0.6252 | Recall: 0.5215 | F1-Score: 0.4807 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.2017 | Eval Loss: 1.2799 | Accuracy: 0.6400 | Precision: 0.6695 | Recall: 0.5231 | F1-Score: 0.5397 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1936 | Eval Loss: 1.2835 | Accuracy: 0.6000 | Precision: 0.6066 | Recall: 0.4991 | F1-Score: 0.5000 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1883 | Eval Loss: 1.2846 | Accuracy: 0.6267 | Precision: 0.6516 | Recall: 0.5538 | F1-Score: 0.5457 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1809 | Eval Loss: 1.3172 | Accuracy: 0.5733 | Precision: 0.5637 | Recall: 0.5189 | F1-Score: 0.5002 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.2450 | Eval Loss: 1.3662 | Accuracy: 0.5067 | Precision: 0.4600 | Recall: 0.4575 | F1-Score: 0.4301 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.2784 | Eval Loss: 1.2654 | Accuracy: 0.6267 | Precision: 0.6402 | Recall: 0.5095 | F1-Score: 0.4980 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.2008 | Eval Loss: 1.2990 | Accuracy: 0.6267 | Precision: 0.6683 | Recall: 0.5612 | F1-Score: 0.5553 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1717 | Eval Loss: 1.2887 | Accuracy: 0.6133 | Precision: 0.6356 | Recall: 0.5396 | F1-Score: 0.5299 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1491 | Eval Loss: 1.2861 | Accuracy: 0.6000 | Precision: 0.5149 | Recall: 0.5212 | F1-Score: 0.5156 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1438 | Eval Loss: 1.2796 | Accuracy: 0.6133 | Precision: 0.5622 | Recall: 0.5315 | F1-Score: 0.5378 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1496 | Eval Loss: 1.2830 | Accuracy: 0.6133 | Precision: 0.5509 | Recall: 0.5133 | F1-Score: 0.5110 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1670 | Eval Loss: 1.2828 | Accuracy: 0.6000 | Precision: 0.6203 | Recall: 0.4826 | F1-Score: 0.4808 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.1484 | Eval Loss: 1.3047 | Accuracy: 0.6133 | Precision: 0.5554 | Recall: 0.5396 | F1-Score: 0.5214 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1461 | Eval Loss: 1.2865 | Accuracy: 0.5867 | Precision: 0.4246 | Recall: 0.4838 | F1-Score: 0.4451 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.1368 | Eval Loss: 1.2981 | Accuracy: 0.6133 | Precision: 0.5663 | Recall: 0.5315 | F1-Score: 0.5425 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.1756 | Eval Loss: 1.3146 | Accuracy: 0.5733 | Precision: 0.4133 | Recall: 0.4565 | F1-Score: 0.4228 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.1279 | Eval Loss: 1.2960 | Accuracy: 0.6000 | Precision: 0.6230 | Recall: 0.5253 | F1-Score: 0.5143 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.1285 | Eval Loss: 1.2841 | Accuracy: 0.5867 | Precision: 0.4833 | Recall: 0.4996 | F1-Score: 0.4784 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.1477 | Eval Loss: 1.3073 | Accuracy: 0.6000 | Precision: 0.5458 | Recall: 0.5246 | F1-Score: 0.5246 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.1245 | Eval Loss: 1.2641 | Accuracy: 0.6267 | Precision: 0.5476 | Recall: 0.5424 | F1-Score: 0.5401 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.1178 | Eval Loss: 1.2833 | Accuracy: 0.6267 | Precision: 0.5920 | Recall: 0.5350 | F1-Score: 0.5378 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.1090 | Eval Loss: 1.2845 | Accuracy: 0.6133 | Precision: 0.5942 | Recall: 0.5315 | F1-Score: 0.5461 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [2:39:18<51:31, 515.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50        12\n",
      "           1       0.44      0.53      0.48        15\n",
      "           2       0.31      0.56      0.40         9\n",
      "           3       0.25      0.05      0.09        19\n",
      "           4       0.74      0.97      0.84        29\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.47      0.50      0.46        84\n",
      "weighted avg       0.51      0.56      0.51        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.307437, test accuracy: 0.5595, test precision: 0.4738, test recall: 0.5047, test F1-score: 0.4615\n",
      "Parámetros:  mean 1 2 900\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 1, 'LSTM': 2, 'LSTM_out': 900, 'Loss_final': 1.1090408563613892, 'Accuracy_eval': 0.5928205128205127, 'Precision_eval': 0.5014386318975824, 'Recall_eval': 0.4928723001136795, 'F1_eval': 0.46233140927336575, 'Loss_eval': 1.2845083475112915, 'Loss_tst': 1.3074373006820679, 'Accuracy_tst': 0.5595238095238095, 'Precision_tst': 0.47375730994152043, 'Recall_tst': 0.5047408751764468, 'F1_tst': 0.4615251804220007}\n",
      "Entrenando modelo con aggr=mean, conv=2, lstm=1,out_lstm=800\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5166 | Eval Loss: 1.3299 | Accuracy: 0.6133 | Precision: 0.4361 | Recall: 0.4657 | F1-Score: 0.4059 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3304 | Eval Loss: 1.2666 | Accuracy: 0.6400 | Precision: 0.3534 | Recall: 0.5131 | F1-Score: 0.4150 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.2764 | Eval Loss: 1.2722 | Accuracy: 0.6400 | Precision: 0.4687 | Recall: 0.5205 | F1-Score: 0.4760 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2571 | Eval Loss: 1.3022 | Accuracy: 0.5733 | Precision: 0.4141 | Recall: 0.4769 | F1-Score: 0.4198 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2547 | Eval Loss: 1.2993 | Accuracy: 0.5733 | Precision: 0.4050 | Recall: 0.4843 | F1-Score: 0.4050 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2568 | Eval Loss: 1.2749 | Accuracy: 0.6133 | Precision: 0.4351 | Recall: 0.4993 | F1-Score: 0.4585 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2433 | Eval Loss: 1.3107 | Accuracy: 0.5733 | Precision: 0.3879 | Recall: 0.4343 | F1-Score: 0.3967 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2368 | Eval Loss: 1.2947 | Accuracy: 0.5867 | Precision: 0.4234 | Recall: 0.4838 | F1-Score: 0.4459 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2138 | Eval Loss: 1.2773 | Accuracy: 0.6133 | Precision: 0.4270 | Recall: 0.4845 | F1-Score: 0.4493 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2052 | Eval Loss: 1.2704 | Accuracy: 0.6267 | Precision: 0.4339 | Recall: 0.4914 | F1-Score: 0.4599 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.1908 | Eval Loss: 1.2673 | Accuracy: 0.6267 | Precision: 0.4471 | Recall: 0.4988 | F1-Score: 0.4682 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.1823 | Eval Loss: 1.2775 | Accuracy: 0.6000 | Precision: 0.4270 | Recall: 0.4702 | F1-Score: 0.4372 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.1846 | Eval Loss: 1.2996 | Accuracy: 0.6000 | Precision: 0.4307 | Recall: 0.4833 | F1-Score: 0.4340 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.1999 | Eval Loss: 1.2585 | Accuracy: 0.6267 | Precision: 0.4367 | Recall: 0.5119 | F1-Score: 0.4599 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2062 | Eval Loss: 1.2518 | Accuracy: 0.6667 | Precision: 0.4789 | Recall: 0.5343 | F1-Score: 0.5031 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1815 | Eval Loss: 1.2813 | Accuracy: 0.6000 | Precision: 0.4168 | Recall: 0.4629 | F1-Score: 0.4270 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1751 | Eval Loss: 1.2524 | Accuracy: 0.6400 | Precision: 0.5589 | Recall: 0.5164 | F1-Score: 0.5115 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1598 | Eval Loss: 1.2533 | Accuracy: 0.6533 | Precision: 0.5320 | Recall: 0.5307 | F1-Score: 0.5255 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1439 | Eval Loss: 1.2570 | Accuracy: 0.6533 | Precision: 0.5343 | Recall: 0.5455 | F1-Score: 0.5372 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1291 | Eval Loss: 1.2618 | Accuracy: 0.6400 | Precision: 0.5502 | Recall: 0.5493 | F1-Score: 0.5410 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1146 | Eval Loss: 1.2897 | Accuracy: 0.6133 | Precision: 0.5303 | Recall: 0.5322 | F1-Score: 0.5195 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1214 | Eval Loss: 1.2954 | Accuracy: 0.6533 | Precision: 0.5906 | Recall: 0.5998 | F1-Score: 0.5847 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1278 | Eval Loss: 1.2532 | Accuracy: 0.6400 | Precision: 0.4739 | Recall: 0.5188 | F1-Score: 0.4823 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1166 | Eval Loss: 1.2796 | Accuracy: 0.6267 | Precision: 0.5706 | Recall: 0.5276 | F1-Score: 0.5160 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1084 | Eval Loss: 1.2711 | Accuracy: 0.6000 | Precision: 0.4820 | Recall: 0.5088 | F1-Score: 0.4826 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1117 | Eval Loss: 1.2472 | Accuracy: 0.6533 | Precision: 0.5741 | Recall: 0.5636 | F1-Score: 0.5624 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.0929 | Eval Loss: 1.2811 | Accuracy: 0.6533 | Precision: 0.6146 | Recall: 0.5488 | F1-Score: 0.5376 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0809 | Eval Loss: 1.2686 | Accuracy: 0.6400 | Precision: 0.5666 | Recall: 0.5888 | F1-Score: 0.5696 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0802 | Eval Loss: 1.2276 | Accuracy: 0.7067 | Precision: 0.6705 | Recall: 0.6043 | F1-Score: 0.6053 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0730 | Eval Loss: 1.2604 | Accuracy: 0.6267 | Precision: 0.5441 | Recall: 0.5457 | F1-Score: 0.5423 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0649 | Eval Loss: 1.2425 | Accuracy: 0.6533 | Precision: 0.4896 | Recall: 0.5405 | F1-Score: 0.5101 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0616 | Eval Loss: 1.2497 | Accuracy: 0.6533 | Precision: 0.5521 | Recall: 0.5381 | F1-Score: 0.5298 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0561 | Eval Loss: 1.2501 | Accuracy: 0.6400 | Precision: 0.4792 | Recall: 0.5131 | F1-Score: 0.4865 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0517 | Eval Loss: 1.2484 | Accuracy: 0.6800 | Precision: 0.6047 | Recall: 0.5807 | F1-Score: 0.5817 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0395 | Eval Loss: 1.2639 | Accuracy: 0.6133 | Precision: 0.4473 | Recall: 0.4845 | F1-Score: 0.4637 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0392 | Eval Loss: 1.2280 | Accuracy: 0.6533 | Precision: 0.5521 | Recall: 0.5438 | F1-Score: 0.5336 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0396 | Eval Loss: 1.2590 | Accuracy: 0.6400 | Precision: 0.5829 | Recall: 0.5312 | F1-Score: 0.5335 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0573 | Eval Loss: 1.2616 | Accuracy: 0.6267 | Precision: 0.5563 | Recall: 0.5300 | F1-Score: 0.5106 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0488 | Eval Loss: 1.2417 | Accuracy: 0.6533 | Precision: 0.5120 | Recall: 0.5479 | F1-Score: 0.5104 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0440 | Eval Loss: 1.2438 | Accuracy: 0.6533 | Precision: 0.5695 | Recall: 0.5381 | F1-Score: 0.5282 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0264 | Eval Loss: 1.2524 | Accuracy: 0.6400 | Precision: 0.5477 | Recall: 0.5591 | F1-Score: 0.5470 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0191 | Eval Loss: 1.2314 | Accuracy: 0.6533 | Precision: 0.5191 | Recall: 0.5274 | F1-Score: 0.5109 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0123 | Eval Loss: 1.2467 | Accuracy: 0.6667 | Precision: 0.5119 | Recall: 0.5548 | F1-Score: 0.5243 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0071 | Eval Loss: 1.2473 | Accuracy: 0.6267 | Precision: 0.5292 | Recall: 0.5374 | F1-Score: 0.5281 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0019 | Eval Loss: 1.2383 | Accuracy: 0.6533 | Precision: 0.5044 | Recall: 0.5405 | F1-Score: 0.5154 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 0.9996 | Eval Loss: 1.2473 | Accuracy: 0.6533 | Precision: 0.5173 | Recall: 0.5479 | F1-Score: 0.5267 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 0.9947 | Eval Loss: 1.2339 | Accuracy: 0.6800 | Precision: 0.5256 | Recall: 0.5691 | F1-Score: 0.5414 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 0.9892 | Eval Loss: 1.2287 | Accuracy: 0.6667 | Precision: 0.5211 | Recall: 0.5474 | F1-Score: 0.5240 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 0.9853 | Eval Loss: 1.2201 | Accuracy: 0.7067 | Precision: 0.6256 | Recall: 0.6191 | F1-Score: 0.6143 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 0.9813 | Eval Loss: 1.2227 | Accuracy: 0.6933 | Precision: 0.6023 | Recall: 0.5974 | F1-Score: 0.5949 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 0.9841 | Eval Loss: 1.2173 | Accuracy: 0.7200 | Precision: 0.6581 | Recall: 0.6260 | F1-Score: 0.6236 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 0.9753 | Eval Loss: 1.2183 | Accuracy: 0.7200 | Precision: 0.6136 | Recall: 0.6079 | F1-Score: 0.5963 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19/24 [2:47:37<42:32, 510.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        12\n",
      "           1       0.36      0.67      0.47        15\n",
      "           2       0.43      0.33      0.38         9\n",
      "           3       0.17      0.05      0.08        19\n",
      "           4       0.74      0.79      0.77        29\n",
      "\n",
      "    accuracy                           0.54        84\n",
      "   macro avg       0.47      0.50      0.47        84\n",
      "weighted avg       0.50      0.54      0.50        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.347917, test accuracy: 0.5357, test precision: 0.4722, test recall: 0.5025, test F1-score: 0.4707\n",
      "Parámetros:  mean 2 1 800\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 2, 'LSTM': 1, 'LSTM_out': 800, 'Loss_final': 0.9752752780914307, 'Accuracy_eval': 0.6407692307692306, 'Precision_eval': 0.5122324047486186, 'Recall_eval': 0.5322641151951497, 'F1_eval': 0.5079592892903462, 'Loss_eval': 1.218258023262024, 'Loss_tst': 1.347917079925537, 'Accuracy_tst': 0.5357142857142857, 'Precision_tst': 0.4721966205837173, 'Recall_tst': 0.5024803387779795, 'F1_tst': 0.4706899224806202}\n",
      "Entrenando modelo con aggr=mean, conv=2, lstm=1,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5059 | Eval Loss: 1.3240 | Accuracy: 0.6000 | Precision: 0.3199 | Recall: 0.4457 | F1-Score: 0.3661 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3311 | Eval Loss: 1.2717 | Accuracy: 0.6267 | Precision: 0.3474 | Recall: 0.5062 | F1-Score: 0.4064 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.2792 | Eval Loss: 1.2834 | Accuracy: 0.6267 | Precision: 0.4525 | Recall: 0.5062 | F1-Score: 0.4574 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2520 | Eval Loss: 1.2895 | Accuracy: 0.6000 | Precision: 0.4402 | Recall: 0.5038 | F1-Score: 0.4482 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2451 | Eval Loss: 1.2901 | Accuracy: 0.6133 | Precision: 0.4402 | Recall: 0.5124 | F1-Score: 0.4560 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2434 | Eval Loss: 1.2947 | Accuracy: 0.6133 | Precision: 0.4610 | Recall: 0.5067 | F1-Score: 0.4631 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2306 | Eval Loss: 1.3080 | Accuracy: 0.5600 | Precision: 0.3725 | Recall: 0.4274 | F1-Score: 0.3885 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2113 | Eval Loss: 1.3099 | Accuracy: 0.5733 | Precision: 0.3994 | Recall: 0.4491 | F1-Score: 0.4097 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2020 | Eval Loss: 1.2891 | Accuracy: 0.6133 | Precision: 0.4522 | Recall: 0.4993 | F1-Score: 0.4670 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2034 | Eval Loss: 1.2615 | Accuracy: 0.6267 | Precision: 0.4356 | Recall: 0.4988 | F1-Score: 0.4623 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.1938 | Eval Loss: 1.2784 | Accuracy: 0.6133 | Precision: 0.4383 | Recall: 0.4845 | F1-Score: 0.4504 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.1832 | Eval Loss: 1.2871 | Accuracy: 0.6133 | Precision: 0.4505 | Recall: 0.4976 | F1-Score: 0.4532 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.1904 | Eval Loss: 1.2864 | Accuracy: 0.5867 | Precision: 0.4429 | Recall: 0.4781 | F1-Score: 0.4524 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.1973 | Eval Loss: 1.2456 | Accuracy: 0.6400 | Precision: 0.5536 | Recall: 0.5419 | F1-Score: 0.5347 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1769 | Eval Loss: 1.3141 | Accuracy: 0.5467 | Precision: 0.3975 | Recall: 0.4279 | F1-Score: 0.4026 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1698 | Eval Loss: 1.2808 | Accuracy: 0.6267 | Precision: 0.5275 | Recall: 0.5243 | F1-Score: 0.5083 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1496 | Eval Loss: 1.2906 | Accuracy: 0.6000 | Precision: 0.5011 | Recall: 0.5031 | F1-Score: 0.4918 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1348 | Eval Loss: 1.2849 | Accuracy: 0.6000 | Precision: 0.4523 | Recall: 0.4907 | F1-Score: 0.4647 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1251 | Eval Loss: 1.2953 | Accuracy: 0.6000 | Precision: 0.4333 | Recall: 0.4702 | F1-Score: 0.4416 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1218 | Eval Loss: 1.2820 | Accuracy: 0.6000 | Precision: 0.4253 | Recall: 0.4629 | F1-Score: 0.4370 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1114 | Eval Loss: 1.2828 | Accuracy: 0.6000 | Precision: 0.4347 | Recall: 0.4907 | F1-Score: 0.4548 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.0981 | Eval Loss: 1.2854 | Accuracy: 0.6267 | Precision: 0.5319 | Recall: 0.5374 | F1-Score: 0.5193 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.0993 | Eval Loss: 1.2587 | Accuracy: 0.6267 | Precision: 0.5443 | Recall: 0.5243 | F1-Score: 0.5172 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.0985 | Eval Loss: 1.2819 | Accuracy: 0.6000 | Precision: 0.4526 | Recall: 0.4457 | F1-Score: 0.4139 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1141 | Eval Loss: 1.2799 | Accuracy: 0.6000 | Precision: 0.4321 | Recall: 0.4776 | F1-Score: 0.4438 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.0877 | Eval Loss: 1.2726 | Accuracy: 0.6000 | Precision: 0.4335 | Recall: 0.4850 | F1-Score: 0.4550 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.0865 | Eval Loss: 1.2549 | Accuracy: 0.6267 | Precision: 0.5149 | Recall: 0.5095 | F1-Score: 0.4968 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0701 | Eval Loss: 1.2685 | Accuracy: 0.6267 | Precision: 0.4662 | Recall: 0.4988 | F1-Score: 0.4700 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0583 | Eval Loss: 1.2619 | Accuracy: 0.6267 | Precision: 0.4537 | Recall: 0.4988 | F1-Score: 0.4726 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0568 | Eval Loss: 1.2586 | Accuracy: 0.6400 | Precision: 0.5045 | Recall: 0.5205 | F1-Score: 0.4981 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0409 | Eval Loss: 1.2473 | Accuracy: 0.6533 | Precision: 0.5733 | Recall: 0.5488 | F1-Score: 0.5473 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0373 | Eval Loss: 1.2485 | Accuracy: 0.6400 | Precision: 0.4869 | Recall: 0.5131 | F1-Score: 0.4912 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0278 | Eval Loss: 1.2575 | Accuracy: 0.6400 | Precision: 0.4702 | Recall: 0.5131 | F1-Score: 0.4860 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0255 | Eval Loss: 1.2561 | Accuracy: 0.6267 | Precision: 0.4578 | Recall: 0.4988 | F1-Score: 0.4710 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0226 | Eval Loss: 1.2752 | Accuracy: 0.6267 | Precision: 0.4830 | Recall: 0.4931 | F1-Score: 0.4632 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0205 | Eval Loss: 1.2681 | Accuracy: 0.6267 | Precision: 0.5378 | Recall: 0.5219 | F1-Score: 0.5245 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0108 | Eval Loss: 1.2562 | Accuracy: 0.6667 | Precision: 0.6029 | Recall: 0.5705 | F1-Score: 0.5727 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0139 | Eval Loss: 1.2510 | Accuracy: 0.6667 | Precision: 0.5223 | Recall: 0.5360 | F1-Score: 0.5159 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0118 | Eval Loss: 1.2657 | Accuracy: 0.6133 | Precision: 0.4595 | Recall: 0.4919 | F1-Score: 0.4621 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0065 | Eval Loss: 1.2525 | Accuracy: 0.6533 | Precision: 0.4848 | Recall: 0.5405 | F1-Score: 0.5085 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0219 | Eval Loss: 1.2798 | Accuracy: 0.6133 | Precision: 0.4975 | Recall: 0.4764 | F1-Score: 0.4736 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0190 | Eval Loss: 1.2680 | Accuracy: 0.6133 | Precision: 0.4674 | Recall: 0.4919 | F1-Score: 0.4608 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0052 | Eval Loss: 1.2385 | Accuracy: 0.6800 | Precision: 0.5298 | Recall: 0.5822 | F1-Score: 0.5461 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0057 | Eval Loss: 1.2623 | Accuracy: 0.6800 | Precision: 0.5784 | Recall: 0.5815 | F1-Score: 0.5753 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0156 | Eval Loss: 1.2458 | Accuracy: 0.6267 | Precision: 0.5549 | Recall: 0.4907 | F1-Score: 0.4878 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0094 | Eval Loss: 1.2516 | Accuracy: 0.6667 | Precision: 0.6024 | Recall: 0.5655 | F1-Score: 0.5501 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0013 | Eval Loss: 1.2347 | Accuracy: 0.6667 | Precision: 0.4931 | Recall: 0.5400 | F1-Score: 0.5112 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0039 | Eval Loss: 1.2400 | Accuracy: 0.6400 | Precision: 0.4744 | Recall: 0.5188 | F1-Score: 0.4930 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 0.9950 | Eval Loss: 1.2487 | Accuracy: 0.6667 | Precision: 0.5691 | Recall: 0.5581 | F1-Score: 0.5442 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 0.9899 | Eval Loss: 1.2497 | Accuracy: 0.6267 | Precision: 0.4638 | Recall: 0.5045 | F1-Score: 0.4747 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 0.9843 | Eval Loss: 1.2341 | Accuracy: 0.6667 | Precision: 0.5459 | Recall: 0.5524 | F1-Score: 0.5435 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 0.9823 | Eval Loss: 1.2378 | Accuracy: 0.6667 | Precision: 0.5227 | Recall: 0.5474 | F1-Score: 0.5203 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [2:55:30<33:16, 499.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        12\n",
      "           1       0.39      0.73      0.51        15\n",
      "           2       0.38      0.33      0.35         9\n",
      "           3       0.29      0.11      0.15        19\n",
      "           4       0.74      0.79      0.77        29\n",
      "\n",
      "    accuracy                           0.54        84\n",
      "   macro avg       0.48      0.49      0.47        84\n",
      "weighted avg       0.52      0.54      0.51        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.354858, test accuracy: 0.5357, test precision: 0.4791, test recall: 0.4930, test F1-score: 0.4661\n",
      "Parámetros:  mean 2 1 850\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 2, 'LSTM': 1, 'LSTM_out': 850, 'Loss_final': 0.9822741746902466, 'Accuracy_eval': 0.6246153846153847, 'Precision_eval': 0.4786391754588592, 'Recall_eval': 0.5069747063281546, 'F1_eval': 0.47934684793913906, 'Loss_eval': 1.2378281354904175, 'Loss_tst': 1.354858160018921, 'Accuracy_tst': 0.5357142857142857, 'Precision_tst': 0.4791013824884793, 'Recall_tst': 0.49300665456745313, 'F1_tst': 0.46610728988293965}\n",
      "Entrenando modelo con aggr=mean, conv=2, lstm=1,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5045 | Eval Loss: 1.3153 | Accuracy: 0.6267 | Precision: 0.5319 | Recall: 0.4800 | F1-Score: 0.4137 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3285 | Eval Loss: 1.2618 | Accuracy: 0.6533 | Precision: 0.5577 | Recall: 0.5274 | F1-Score: 0.4453 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.2804 | Eval Loss: 1.2759 | Accuracy: 0.6400 | Precision: 0.4703 | Recall: 0.5205 | F1-Score: 0.4834 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2546 | Eval Loss: 1.2976 | Accuracy: 0.5867 | Precision: 0.4129 | Recall: 0.4633 | F1-Score: 0.4230 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2421 | Eval Loss: 1.2781 | Accuracy: 0.6000 | Precision: 0.4446 | Recall: 0.5055 | F1-Score: 0.4366 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2471 | Eval Loss: 1.2852 | Accuracy: 0.5867 | Precision: 0.4302 | Recall: 0.4781 | F1-Score: 0.4404 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2358 | Eval Loss: 1.3012 | Accuracy: 0.6000 | Precision: 0.4221 | Recall: 0.4702 | F1-Score: 0.4331 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2104 | Eval Loss: 1.2918 | Accuracy: 0.5867 | Precision: 0.4060 | Recall: 0.4560 | F1-Score: 0.4223 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.1985 | Eval Loss: 1.2869 | Accuracy: 0.6000 | Precision: 0.4228 | Recall: 0.4776 | F1-Score: 0.4453 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.1897 | Eval Loss: 1.2839 | Accuracy: 0.6133 | Precision: 0.4311 | Recall: 0.4919 | F1-Score: 0.4532 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.1856 | Eval Loss: 1.2769 | Accuracy: 0.6000 | Precision: 0.4237 | Recall: 0.4702 | F1-Score: 0.4405 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.1824 | Eval Loss: 1.3159 | Accuracy: 0.5733 | Precision: 0.3928 | Recall: 0.4548 | F1-Score: 0.4103 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2026 | Eval Loss: 1.2702 | Accuracy: 0.6133 | Precision: 0.4294 | Recall: 0.5181 | F1-Score: 0.4480 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2261 | Eval Loss: 1.3087 | Accuracy: 0.5867 | Precision: 0.4353 | Recall: 0.4838 | F1-Score: 0.4431 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.1986 | Eval Loss: 1.2895 | Accuracy: 0.5867 | Precision: 0.4111 | Recall: 0.4560 | F1-Score: 0.4272 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.1789 | Eval Loss: 1.2880 | Accuracy: 0.6000 | Precision: 0.4942 | Recall: 0.4883 | F1-Score: 0.4775 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.1683 | Eval Loss: 1.2882 | Accuracy: 0.5867 | Precision: 0.4294 | Recall: 0.4822 | F1-Score: 0.4398 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.1551 | Eval Loss: 1.2714 | Accuracy: 0.6000 | Precision: 0.4657 | Recall: 0.4957 | F1-Score: 0.4649 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.1458 | Eval Loss: 1.2814 | Accuracy: 0.6133 | Precision: 0.5021 | Recall: 0.5026 | F1-Score: 0.4993 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1228 | Eval Loss: 1.2615 | Accuracy: 0.6400 | Precision: 0.5564 | Recall: 0.5312 | F1-Score: 0.5228 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1206 | Eval Loss: 1.2637 | Accuracy: 0.6267 | Precision: 0.5075 | Recall: 0.5169 | F1-Score: 0.5045 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1088 | Eval Loss: 1.2407 | Accuracy: 0.6667 | Precision: 0.5568 | Recall: 0.5655 | F1-Score: 0.5464 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.0977 | Eval Loss: 1.2700 | Accuracy: 0.6533 | Precision: 0.5952 | Recall: 0.5686 | F1-Score: 0.5694 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1120 | Eval Loss: 1.2836 | Accuracy: 0.6000 | Precision: 0.4351 | Recall: 0.4907 | F1-Score: 0.4522 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1071 | Eval Loss: 1.2755 | Accuracy: 0.6133 | Precision: 0.5239 | Recall: 0.5207 | F1-Score: 0.5100 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.0939 | Eval Loss: 1.2732 | Accuracy: 0.6400 | Precision: 0.5636 | Recall: 0.5526 | F1-Score: 0.5558 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.0859 | Eval Loss: 1.2512 | Accuracy: 0.6533 | Precision: 0.5925 | Recall: 0.5455 | F1-Score: 0.5400 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.0857 | Eval Loss: 1.2631 | Accuracy: 0.6267 | Precision: 0.5313 | Recall: 0.5300 | F1-Score: 0.5129 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.0734 | Eval Loss: 1.2645 | Accuracy: 0.6133 | Precision: 0.5037 | Recall: 0.5157 | F1-Score: 0.5020 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.0693 | Eval Loss: 1.2517 | Accuracy: 0.6800 | Precision: 0.6358 | Recall: 0.6062 | F1-Score: 0.6065 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.0687 | Eval Loss: 1.2527 | Accuracy: 0.6400 | Precision: 0.5665 | Recall: 0.5600 | F1-Score: 0.5587 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.0562 | Eval Loss: 1.2401 | Accuracy: 0.6667 | Precision: 0.5999 | Recall: 0.5943 | F1-Score: 0.5902 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.0497 | Eval Loss: 1.2376 | Accuracy: 0.6667 | Precision: 0.5903 | Recall: 0.5581 | F1-Score: 0.5459 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.0502 | Eval Loss: 1.2565 | Accuracy: 0.6800 | Precision: 0.6143 | Recall: 0.5988 | F1-Score: 0.5969 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0335 | Eval Loss: 1.2486 | Accuracy: 0.6667 | Precision: 0.5621 | Recall: 0.5581 | F1-Score: 0.5488 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0293 | Eval Loss: 1.2366 | Accuracy: 0.7067 | Precision: 0.6560 | Recall: 0.6331 | F1-Score: 0.6343 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0229 | Eval Loss: 1.2644 | Accuracy: 0.6400 | Precision: 0.5207 | Recall: 0.5238 | F1-Score: 0.5175 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0211 | Eval Loss: 1.2529 | Accuracy: 0.6533 | Precision: 0.5648 | Recall: 0.5612 | F1-Score: 0.5609 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0115 | Eval Loss: 1.2480 | Accuracy: 0.6800 | Precision: 0.5804 | Recall: 0.5593 | F1-Score: 0.5544 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.0072 | Eval Loss: 1.2662 | Accuracy: 0.6133 | Precision: 0.5124 | Recall: 0.5231 | F1-Score: 0.5082 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0065 | Eval Loss: 1.2451 | Accuracy: 0.6533 | Precision: 0.5723 | Recall: 0.5636 | F1-Score: 0.5611 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.0027 | Eval Loss: 1.2537 | Accuracy: 0.6667 | Precision: 0.5759 | Recall: 0.5581 | F1-Score: 0.5486 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0000 | Eval Loss: 1.2679 | Accuracy: 0.6267 | Precision: 0.5152 | Recall: 0.5374 | F1-Score: 0.5193 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0034 | Eval Loss: 1.2568 | Accuracy: 0.6267 | Precision: 0.5313 | Recall: 0.5226 | F1-Score: 0.5082 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0011 | Eval Loss: 1.2456 | Accuracy: 0.6533 | Precision: 0.5917 | Recall: 0.5512 | F1-Score: 0.5380 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0037 | Eval Loss: 1.2736 | Accuracy: 0.6133 | Precision: 0.5365 | Recall: 0.5157 | F1-Score: 0.4937 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0090 | Eval Loss: 1.2441 | Accuracy: 0.6800 | Precision: 0.6296 | Recall: 0.5979 | F1-Score: 0.5935 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0166 | Eval Loss: 1.2380 | Accuracy: 0.6667 | Precision: 0.5550 | Recall: 0.5393 | F1-Score: 0.5413 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0174 | Eval Loss: 1.2336 | Accuracy: 0.6800 | Precision: 0.5213 | Recall: 0.5486 | F1-Score: 0.5306 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0262 | Eval Loss: 1.2555 | Accuracy: 0.6533 | Precision: 0.5071 | Recall: 0.5331 | F1-Score: 0.5050 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0095 | Eval Loss: 1.2958 | Accuracy: 0.6000 | Precision: 0.5141 | Recall: 0.5293 | F1-Score: 0.5155 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0192 | Eval Loss: 1.2440 | Accuracy: 0.6267 | Precision: 0.5230 | Recall: 0.4981 | F1-Score: 0.5049 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 21/24 [3:03:50<24:58, 499.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.47      0.53      0.50        15\n",
      "           2       0.43      0.33      0.38         9\n",
      "           3       0.54      0.37      0.44        19\n",
      "           4       0.74      0.90      0.81        29\n",
      "\n",
      "    accuracy                           0.63        84\n",
      "   macro avg       0.59      0.58      0.57        84\n",
      "weighted avg       0.62      0.63      0.62        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.278305, test accuracy: 0.6310, test precision: 0.5861, test recall: 0.5763, test F1-score: 0.5750\n",
      "Parámetros:  mean 2 1 900\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 2, 'LSTM': 1, 'LSTM_out': 900, 'Loss_final': 1.0191569328308105, 'Accuracy_eval': 0.6312820512820512, 'Precision_eval': 0.5164558924712327, 'Recall_eval': 0.5255991852974612, 'F1_eval': 0.5047083634608762, 'Loss_eval': 1.244017243385315, 'Loss_tst': 1.278305172920227, 'Accuracy_tst': 0.6309523809523809, 'Precision_tst': 0.5860956690368455, 'Recall_tst': 0.5763278886872353, 'F1_tst': 0.575}\n",
      "Entrenando modelo con aggr=mean, conv=2, lstm=2,out_lstm=800\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5487 | Eval Loss: 1.3772 | Accuracy: 0.5600 | Precision: 0.2171 | Recall: 0.3857 | F1-Score: 0.2775 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4065 | Eval Loss: 1.3415 | Accuracy: 0.5333 | Precision: 0.2985 | Recall: 0.4055 | F1-Score: 0.3184 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3445 | Eval Loss: 1.2884 | Accuracy: 0.6000 | Precision: 0.3319 | Recall: 0.4850 | F1-Score: 0.3908 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2952 | Eval Loss: 1.3105 | Accuracy: 0.5467 | Precision: 0.3779 | Recall: 0.4336 | F1-Score: 0.3899 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2760 | Eval Loss: 1.2709 | Accuracy: 0.6267 | Precision: 0.4176 | Recall: 0.4988 | F1-Score: 0.4452 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2633 | Eval Loss: 1.2853 | Accuracy: 0.5867 | Precision: 0.4085 | Recall: 0.4633 | F1-Score: 0.4310 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2598 | Eval Loss: 1.3217 | Accuracy: 0.6000 | Precision: 0.4657 | Recall: 0.5448 | F1-Score: 0.4779 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2699 | Eval Loss: 1.3304 | Accuracy: 0.5733 | Precision: 0.3803 | Recall: 0.4769 | F1-Score: 0.4056 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2507 | Eval Loss: 1.2808 | Accuracy: 0.6133 | Precision: 0.4335 | Recall: 0.5050 | F1-Score: 0.4421 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2626 | Eval Loss: 1.2816 | Accuracy: 0.6133 | Precision: 0.4465 | Recall: 0.4976 | F1-Score: 0.4598 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2365 | Eval Loss: 1.3631 | Accuracy: 0.5200 | Precision: 0.3788 | Recall: 0.4141 | F1-Score: 0.3803 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2486 | Eval Loss: 1.3330 | Accuracy: 0.5333 | Precision: 0.3736 | Recall: 0.4341 | F1-Score: 0.3833 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2455 | Eval Loss: 1.3095 | Accuracy: 0.5867 | Precision: 0.4005 | Recall: 0.4855 | F1-Score: 0.4092 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2724 | Eval Loss: 1.3266 | Accuracy: 0.5733 | Precision: 0.4045 | Recall: 0.4245 | F1-Score: 0.4064 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2723 | Eval Loss: 1.3383 | Accuracy: 0.5467 | Precision: 0.3796 | Recall: 0.4336 | F1-Score: 0.3896 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2276 | Eval Loss: 1.2880 | Accuracy: 0.6000 | Precision: 0.4400 | Recall: 0.5038 | F1-Score: 0.4594 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2357 | Eval Loss: 1.2931 | Accuracy: 0.6133 | Precision: 0.3582 | Recall: 0.5181 | F1-Score: 0.4130 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2355 | Eval Loss: 1.3301 | Accuracy: 0.5600 | Precision: 0.3915 | Recall: 0.4365 | F1-Score: 0.4088 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2303 | Eval Loss: 1.2987 | Accuracy: 0.6000 | Precision: 0.4156 | Recall: 0.4702 | F1-Score: 0.4375 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2096 | Eval Loss: 1.3017 | Accuracy: 0.6000 | Precision: 0.4357 | Recall: 0.4965 | F1-Score: 0.4460 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2053 | Eval Loss: 1.2990 | Accuracy: 0.5867 | Precision: 0.4123 | Recall: 0.4707 | F1-Score: 0.4299 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.2018 | Eval Loss: 1.2954 | Accuracy: 0.6000 | Precision: 0.4954 | Recall: 0.5031 | F1-Score: 0.4943 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.2077 | Eval Loss: 1.3228 | Accuracy: 0.5600 | Precision: 0.4128 | Recall: 0.4610 | F1-Score: 0.4180 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1993 | Eval Loss: 1.2633 | Accuracy: 0.6133 | Precision: 0.4388 | Recall: 0.4919 | F1-Score: 0.4489 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1928 | Eval Loss: 1.3159 | Accuracy: 0.5600 | Precision: 0.4239 | Recall: 0.4700 | F1-Score: 0.4353 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.1703 | Eval Loss: 1.3407 | Accuracy: 0.5600 | Precision: 0.4985 | Recall: 0.4710 | F1-Score: 0.4639 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1970 | Eval Loss: 1.2947 | Accuracy: 0.5867 | Precision: 0.5037 | Recall: 0.4888 | F1-Score: 0.4435 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1965 | Eval Loss: 1.3143 | Accuracy: 0.5467 | Precision: 0.4173 | Recall: 0.4484 | F1-Score: 0.4214 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1716 | Eval Loss: 1.2873 | Accuracy: 0.5867 | Precision: 0.4578 | Recall: 0.4855 | F1-Score: 0.4506 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1707 | Eval Loss: 1.3136 | Accuracy: 0.5600 | Precision: 0.4770 | Recall: 0.4710 | F1-Score: 0.4651 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1732 | Eval Loss: 1.2793 | Accuracy: 0.6133 | Precision: 0.5593 | Recall: 0.4945 | F1-Score: 0.5007 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.2044 | Eval Loss: 1.3030 | Accuracy: 0.5867 | Precision: 0.5480 | Recall: 0.5644 | F1-Score: 0.5331 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1938 | Eval Loss: 1.2449 | Accuracy: 0.6667 | Precision: 0.6255 | Recall: 0.5705 | F1-Score: 0.5753 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1448 | Eval Loss: 1.2860 | Accuracy: 0.6000 | Precision: 0.5391 | Recall: 0.5353 | F1-Score: 0.5314 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1386 | Eval Loss: 1.2883 | Accuracy: 0.5867 | Precision: 0.5432 | Recall: 0.5062 | F1-Score: 0.5052 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1635 | Eval Loss: 1.2872 | Accuracy: 0.6133 | Precision: 0.5709 | Recall: 0.5207 | F1-Score: 0.5211 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1468 | Eval Loss: 1.3070 | Accuracy: 0.5600 | Precision: 0.4941 | Recall: 0.4908 | F1-Score: 0.4900 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1263 | Eval Loss: 1.2854 | Accuracy: 0.6133 | Precision: 0.5232 | Recall: 0.5315 | F1-Score: 0.5193 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1381 | Eval Loss: 1.2999 | Accuracy: 0.5733 | Precision: 0.3988 | Recall: 0.4360 | F1-Score: 0.4047 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1649 | Eval Loss: 1.2843 | Accuracy: 0.6133 | Precision: 0.5929 | Recall: 0.5422 | F1-Score: 0.5471 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1690 | Eval Loss: 1.2745 | Accuracy: 0.5867 | Precision: 0.5014 | Recall: 0.5200 | F1-Score: 0.5033 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1493 | Eval Loss: 1.2617 | Accuracy: 0.6267 | Precision: 0.4401 | Recall: 0.5062 | F1-Score: 0.4570 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.1289 | Eval Loss: 1.2939 | Accuracy: 0.6000 | Precision: 0.5050 | Recall: 0.5279 | F1-Score: 0.5105 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1147 | Eval Loss: 1.2798 | Accuracy: 0.6000 | Precision: 0.5569 | Recall: 0.5007 | F1-Score: 0.5062 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.1016 | Eval Loss: 1.2941 | Accuracy: 0.6000 | Precision: 0.5208 | Recall: 0.4852 | F1-Score: 0.4918 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.1582 | Eval Loss: 1.2833 | Accuracy: 0.6133 | Precision: 0.5365 | Recall: 0.5231 | F1-Score: 0.5082 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.1314 | Eval Loss: 1.2811 | Accuracy: 0.6133 | Precision: 0.5581 | Recall: 0.5519 | F1-Score: 0.5446 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0736 | Eval Loss: 1.2893 | Accuracy: 0.6133 | Precision: 0.5603 | Recall: 0.5355 | F1-Score: 0.5335 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0517 | Eval Loss: 1.2696 | Accuracy: 0.6533 | Precision: 0.5876 | Recall: 0.5793 | F1-Score: 0.5828 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0603 | Eval Loss: 1.2867 | Accuracy: 0.6133 | Precision: 0.5500 | Recall: 0.5100 | F1-Score: 0.4998 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0663 | Eval Loss: 1.2772 | Accuracy: 0.6267 | Precision: 0.6077 | Recall: 0.5293 | F1-Score: 0.5322 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0742 | Eval Loss: 1.2665 | Accuracy: 0.6533 | Precision: 0.6110 | Recall: 0.6367 | F1-Score: 0.6170 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 22/24 [3:13:55<17:42, 531.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71        12\n",
      "           1       0.31      0.60      0.41        15\n",
      "           2       0.14      0.11      0.12         9\n",
      "           3       0.33      0.11      0.16        19\n",
      "           4       0.81      0.72      0.76        29\n",
      "\n",
      "    accuracy                           0.51        84\n",
      "   macro avg       0.44      0.47      0.43        84\n",
      "weighted avg       0.51      0.51      0.49        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.352933, test accuracy: 0.5119, test precision: 0.4438, test recall: 0.4748, test F1-score: 0.4344\n",
      "Parámetros:  mean 2 2 800\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 2, 'LSTM': 2, 'LSTM_out': 800, 'Loss_final': 1.074155569076538, 'Accuracy_eval': 0.5917948717948718, 'Precision_eval': 0.4658408489214176, 'Recall_eval': 0.493711159530125, 'F1_eval': 0.4626487726647558, 'Loss_eval': 1.2665330171585083, 'Loss_tst': 1.3529326915740967, 'Accuracy_tst': 0.5119047619047619, 'Precision_tst': 0.44384552229379814, 'Recall_tst': 0.4747691066747328, 'F1_tst': 0.4344025974025974}\n",
      "Entrenando modelo con aggr=mean, conv=2, lstm=2,out_lstm=850\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5485 | Eval Loss: 1.3690 | Accuracy: 0.5600 | Precision: 0.2156 | Recall: 0.3857 | F1-Score: 0.2749 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3902 | Eval Loss: 1.3215 | Accuracy: 0.5733 | Precision: 0.3115 | Recall: 0.4393 | F1-Score: 0.3503 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3099 | Eval Loss: 1.2889 | Accuracy: 0.6400 | Precision: 0.5691 | Recall: 0.5541 | F1-Score: 0.4697 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2936 | Eval Loss: 1.3217 | Accuracy: 0.5600 | Precision: 0.3725 | Recall: 0.4586 | F1-Score: 0.3891 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2914 | Eval Loss: 1.2804 | Accuracy: 0.6133 | Precision: 0.4581 | Recall: 0.5329 | F1-Score: 0.4360 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2609 | Eval Loss: 1.2829 | Accuracy: 0.5867 | Precision: 0.4294 | Recall: 0.5027 | F1-Score: 0.4501 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2361 | Eval Loss: 1.3052 | Accuracy: 0.5867 | Precision: 0.4036 | Recall: 0.4633 | F1-Score: 0.4224 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2644 | Eval Loss: 1.3003 | Accuracy: 0.6133 | Precision: 0.4598 | Recall: 0.5329 | F1-Score: 0.4367 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2447 | Eval Loss: 1.2932 | Accuracy: 0.6000 | Precision: 0.4445 | Recall: 0.5096 | F1-Score: 0.4627 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2607 | Eval Loss: 1.3709 | Accuracy: 0.5067 | Precision: 0.3910 | Recall: 0.4220 | F1-Score: 0.3855 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2465 | Eval Loss: 1.3110 | Accuracy: 0.5867 | Precision: 0.4273 | Recall: 0.5043 | F1-Score: 0.4463 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2613 | Eval Loss: 1.2853 | Accuracy: 0.6000 | Precision: 0.4016 | Recall: 0.4867 | F1-Score: 0.4111 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2596 | Eval Loss: 1.3042 | Accuracy: 0.5867 | Precision: 0.4489 | Recall: 0.4912 | F1-Score: 0.4412 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2484 | Eval Loss: 1.3251 | Accuracy: 0.5467 | Precision: 0.3932 | Recall: 0.4353 | F1-Score: 0.4013 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2405 | Eval Loss: 1.3277 | Accuracy: 0.5467 | Precision: 0.3632 | Recall: 0.4205 | F1-Score: 0.3771 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2387 | Eval Loss: 1.2938 | Accuracy: 0.6000 | Precision: 0.4282 | Recall: 0.4850 | F1-Score: 0.4474 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2094 | Eval Loss: 1.3037 | Accuracy: 0.5600 | Precision: 0.3978 | Recall: 0.4422 | F1-Score: 0.4092 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2094 | Eval Loss: 1.3001 | Accuracy: 0.5867 | Precision: 0.4988 | Recall: 0.4724 | F1-Score: 0.4503 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2202 | Eval Loss: 1.2652 | Accuracy: 0.6533 | Precision: 0.6774 | Recall: 0.5693 | F1-Score: 0.5723 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.1988 | Eval Loss: 1.2822 | Accuracy: 0.6000 | Precision: 0.5462 | Recall: 0.5450 | F1-Score: 0.5294 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.1722 | Eval Loss: 1.2728 | Accuracy: 0.6267 | Precision: 0.5718 | Recall: 0.5917 | F1-Score: 0.5747 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1671 | Eval Loss: 1.2973 | Accuracy: 0.6133 | Precision: 0.5899 | Recall: 0.5600 | F1-Score: 0.5420 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1541 | Eval Loss: 1.3239 | Accuracy: 0.5867 | Precision: 0.5865 | Recall: 0.5463 | F1-Score: 0.5208 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1325 | Eval Loss: 1.2972 | Accuracy: 0.5867 | Precision: 0.5308 | Recall: 0.5432 | F1-Score: 0.5268 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.1708 | Eval Loss: 1.2900 | Accuracy: 0.6000 | Precision: 0.5301 | Recall: 0.5098 | F1-Score: 0.5036 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2000 | Eval Loss: 1.3046 | Accuracy: 0.6000 | Precision: 0.5115 | Recall: 0.5148 | F1-Score: 0.5051 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.1975 | Eval Loss: 1.3437 | Accuracy: 0.5467 | Precision: 0.4895 | Recall: 0.5075 | F1-Score: 0.4673 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.1605 | Eval Loss: 1.2923 | Accuracy: 0.6000 | Precision: 0.5522 | Recall: 0.5165 | F1-Score: 0.5267 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1553 | Eval Loss: 1.3417 | Accuracy: 0.5600 | Precision: 0.3960 | Recall: 0.4348 | F1-Score: 0.3945 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1517 | Eval Loss: 1.3063 | Accuracy: 0.5867 | Precision: 0.4566 | Recall: 0.4855 | F1-Score: 0.4592 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1388 | Eval Loss: 1.3044 | Accuracy: 0.5600 | Precision: 0.4145 | Recall: 0.4307 | F1-Score: 0.4131 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1318 | Eval Loss: 1.3662 | Accuracy: 0.4933 | Precision: 0.4033 | Recall: 0.4110 | F1-Score: 0.3947 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1149 | Eval Loss: 1.2778 | Accuracy: 0.6000 | Precision: 0.5314 | Recall: 0.5146 | F1-Score: 0.4933 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1001 | Eval Loss: 1.2915 | Accuracy: 0.6000 | Precision: 0.4646 | Recall: 0.5129 | F1-Score: 0.4776 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.0796 | Eval Loss: 1.3013 | Accuracy: 0.5867 | Precision: 0.5222 | Recall: 0.5382 | F1-Score: 0.5248 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.0755 | Eval Loss: 1.2786 | Accuracy: 0.6400 | Precision: 0.4898 | Recall: 0.5262 | F1-Score: 0.4873 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.0966 | Eval Loss: 1.3144 | Accuracy: 0.5600 | Precision: 0.4739 | Recall: 0.4939 | F1-Score: 0.4700 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.0770 | Eval Loss: 1.3167 | Accuracy: 0.5867 | Precision: 0.4741 | Recall: 0.5043 | F1-Score: 0.4746 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.0726 | Eval Loss: 1.2637 | Accuracy: 0.6267 | Precision: 0.5613 | Recall: 0.4924 | F1-Score: 0.4939 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1411 | Eval Loss: 1.3311 | Accuracy: 0.5733 | Precision: 0.5092 | Recall: 0.4796 | F1-Score: 0.4732 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.1622 | Eval Loss: 1.2966 | Accuracy: 0.5867 | Precision: 0.5217 | Recall: 0.5348 | F1-Score: 0.5207 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1094 | Eval Loss: 1.2873 | Accuracy: 0.5867 | Precision: 0.4748 | Recall: 0.4815 | F1-Score: 0.4693 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.0731 | Eval Loss: 1.2864 | Accuracy: 0.5867 | Precision: 0.5080 | Recall: 0.5019 | F1-Score: 0.4829 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.0695 | Eval Loss: 1.3017 | Accuracy: 0.6133 | Precision: 0.6576 | Recall: 0.5083 | F1-Score: 0.4962 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0718 | Eval Loss: 1.3147 | Accuracy: 0.5733 | Precision: 0.5088 | Recall: 0.5182 | F1-Score: 0.5088 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0838 | Eval Loss: 1.2620 | Accuracy: 0.6400 | Precision: 0.6068 | Recall: 0.5986 | F1-Score: 0.5965 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0849 | Eval Loss: 1.3544 | Accuracy: 0.5333 | Precision: 0.4857 | Recall: 0.4613 | F1-Score: 0.4516 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0836 | Eval Loss: 1.3223 | Accuracy: 0.6000 | Precision: 0.6350 | Recall: 0.5400 | F1-Score: 0.5287 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0787 | Eval Loss: 1.3146 | Accuracy: 0.6133 | Precision: 0.5822 | Recall: 0.5569 | F1-Score: 0.5494 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0671 | Eval Loss: 1.3005 | Accuracy: 0.5867 | Precision: 0.5637 | Recall: 0.5127 | F1-Score: 0.4945 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0925 | Eval Loss: 1.2677 | Accuracy: 0.6267 | Precision: 0.5701 | Recall: 0.5317 | F1-Score: 0.5244 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0705 | Eval Loss: 1.3622 | Accuracy: 0.5467 | Precision: 0.4835 | Recall: 0.4903 | F1-Score: 0.4645 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 23/24 [3:25:52<09:46, 586.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.33      0.73      0.46        15\n",
      "           2       0.43      0.33      0.38         9\n",
      "           3       0.40      0.11      0.17        19\n",
      "           4       0.81      0.76      0.79        29\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.55      0.54      0.51        84\n",
      "weighted avg       0.58      0.56      0.54        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.336611, test accuracy: 0.5595, test precision: 0.5453, test recall: 0.5361, test F1-score: 0.5071\n",
      "Parámetros:  mean 2 2 850\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 2, 'LSTM': 2, 'LSTM_out': 850, 'Loss_final': 1.0704625844955444, 'Accuracy_eval': 0.5871794871794872, 'Precision_eval': 0.4864313578751152, 'Recall_eval': 0.5000573133762789, 'F1_eval': 0.468730602673971, 'Loss_eval': 1.3622488975524902, 'Loss_tst': 1.336611032485962, 'Accuracy_tst': 0.5595238095238095, 'Precision_tst': 0.5453439153439154, 'Recall_tst': 0.5361101028433153, 'F1_tst': 0.5071428571428571}\n",
      "Entrenando modelo con aggr=mean, conv=2, lstm=2,out_lstm=900\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 390\n",
      "Validation dataset: 75\n",
      "Test dataset: 84\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5461 | Eval Loss: 1.3563 | Accuracy: 0.5600 | Precision: 0.2156 | Recall: 0.3857 | F1-Score: 0.2749 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.3831 | Eval Loss: 1.2987 | Accuracy: 0.5867 | Precision: 0.3269 | Recall: 0.4707 | F1-Score: 0.3792 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.3071 | Eval Loss: 1.3103 | Accuracy: 0.6000 | Precision: 0.4398 | Recall: 0.4998 | F1-Score: 0.4178 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.2787 | Eval Loss: 1.3174 | Accuracy: 0.5600 | Precision: 0.4066 | Recall: 0.4627 | F1-Score: 0.4176 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.2840 | Eval Loss: 1.3354 | Accuracy: 0.5600 | Precision: 0.3319 | Recall: 0.4848 | F1-Score: 0.3787 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.2706 | Eval Loss: 1.2738 | Accuracy: 0.6267 | Precision: 0.4153 | Recall: 0.5005 | F1-Score: 0.4432 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.2878 | Eval Loss: 1.3110 | Accuracy: 0.5733 | Precision: 0.4148 | Recall: 0.4753 | F1-Score: 0.4263 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.2657 | Eval Loss: 1.3242 | Accuracy: 0.5600 | Precision: 0.4015 | Recall: 0.4422 | F1-Score: 0.4079 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.2455 | Eval Loss: 1.3100 | Accuracy: 0.5867 | Precision: 0.4209 | Recall: 0.4879 | F1-Score: 0.4335 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.2606 | Eval Loss: 1.2832 | Accuracy: 0.6000 | Precision: 0.3386 | Recall: 0.4776 | F1-Score: 0.3928 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.2566 | Eval Loss: 1.3225 | Accuracy: 0.5600 | Precision: 0.3961 | Recall: 0.4160 | F1-Score: 0.3944 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.2673 | Eval Loss: 1.3207 | Accuracy: 0.5733 | Precision: 0.3921 | Recall: 0.4417 | F1-Score: 0.4072 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.2280 | Eval Loss: 1.3071 | Accuracy: 0.5733 | Precision: 0.4165 | Recall: 0.4769 | F1-Score: 0.4373 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.2309 | Eval Loss: 1.3294 | Accuracy: 0.5467 | Precision: 0.3894 | Recall: 0.4353 | F1-Score: 0.3941 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.2243 | Eval Loss: 1.3540 | Accuracy: 0.5200 | Precision: 0.3521 | Recall: 0.3919 | F1-Score: 0.3574 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.2132 | Eval Loss: 1.2999 | Accuracy: 0.5600 | Precision: 0.4655 | Recall: 0.4727 | F1-Score: 0.4649 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.2176 | Eval Loss: 1.3547 | Accuracy: 0.5600 | Precision: 0.4236 | Recall: 0.4684 | F1-Score: 0.4229 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.2816 | Eval Loss: 1.3537 | Accuracy: 0.5467 | Precision: 0.3956 | Recall: 0.3771 | F1-Score: 0.3484 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.2637 | Eval Loss: 1.3321 | Accuracy: 0.5600 | Precision: 0.3793 | Recall: 0.4274 | F1-Score: 0.3891 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.2179 | Eval Loss: 1.2477 | Accuracy: 0.6667 | Precision: 0.6062 | Recall: 0.5631 | F1-Score: 0.5619 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.2030 | Eval Loss: 1.2956 | Accuracy: 0.6000 | Precision: 0.5579 | Recall: 0.5367 | F1-Score: 0.4948 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.1942 | Eval Loss: 1.3011 | Accuracy: 0.5867 | Precision: 0.4260 | Recall: 0.4765 | F1-Score: 0.4384 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.1990 | Eval Loss: 1.3261 | Accuracy: 0.5733 | Precision: 0.6043 | Recall: 0.4672 | F1-Score: 0.4549 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.1890 | Eval Loss: 1.2984 | Accuracy: 0.5600 | Precision: 0.3771 | Recall: 0.4086 | F1-Score: 0.3865 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.2134 | Eval Loss: 1.3271 | Accuracy: 0.5733 | Precision: 0.5832 | Recall: 0.4524 | F1-Score: 0.4356 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.2044 | Eval Loss: 1.3298 | Accuracy: 0.5600 | Precision: 0.4027 | Recall: 0.3971 | F1-Score: 0.3745 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3057 | Eval Loss: 1.3062 | Accuracy: 0.6133 | Precision: 0.5887 | Recall: 0.5748 | F1-Score: 0.5443 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.2203 | Eval Loss: 1.3053 | Accuracy: 0.5733 | Precision: 0.6258 | Recall: 0.5205 | F1-Score: 0.5143 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.1975 | Eval Loss: 1.2983 | Accuracy: 0.6267 | Precision: 0.5819 | Recall: 0.6008 | F1-Score: 0.5814 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.1542 | Eval Loss: 1.2886 | Accuracy: 0.6533 | Precision: 0.6248 | Recall: 0.5955 | F1-Score: 0.5658 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.1576 | Eval Loss: 1.2969 | Accuracy: 0.6133 | Precision: 0.5282 | Recall: 0.5281 | F1-Score: 0.5232 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.1614 | Eval Loss: 1.2909 | Accuracy: 0.6133 | Precision: 0.5676 | Recall: 0.5569 | F1-Score: 0.5539 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.1355 | Eval Loss: 1.3231 | Accuracy: 0.5600 | Precision: 0.4461 | Recall: 0.5036 | F1-Score: 0.4454 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.1334 | Eval Loss: 1.2983 | Accuracy: 0.6267 | Precision: 0.5921 | Recall: 0.5491 | F1-Score: 0.5535 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.1422 | Eval Loss: 1.3382 | Accuracy: 0.5600 | Precision: 0.5792 | Recall: 0.4529 | F1-Score: 0.4377 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.1749 | Eval Loss: 1.2886 | Accuracy: 0.6133 | Precision: 0.5264 | Recall: 0.5431 | F1-Score: 0.5257 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.1508 | Eval Loss: 1.3054 | Accuracy: 0.6267 | Precision: 0.5739 | Recall: 0.5605 | F1-Score: 0.5539 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.1227 | Eval Loss: 1.2811 | Accuracy: 0.6267 | Precision: 0.5844 | Recall: 0.5612 | F1-Score: 0.5442 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.1009 | Eval Loss: 1.2628 | Accuracy: 0.6400 | Precision: 0.6524 | Recall: 0.5731 | F1-Score: 0.5810 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.1029 | Eval Loss: 1.2688 | Accuracy: 0.6400 | Precision: 0.6082 | Recall: 0.5715 | F1-Score: 0.5704 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.0943 | Eval Loss: 1.2931 | Accuracy: 0.5867 | Precision: 0.5056 | Recall: 0.4676 | F1-Score: 0.4728 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.1316 | Eval Loss: 1.2856 | Accuracy: 0.6267 | Precision: 0.6473 | Recall: 0.5038 | F1-Score: 0.5034 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.1891 | Eval Loss: 1.2271 | Accuracy: 0.7067 | Precision: 0.6560 | Recall: 0.6824 | F1-Score: 0.6605 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.1075 | Eval Loss: 1.2567 | Accuracy: 0.6133 | Precision: 0.5718 | Recall: 0.5593 | F1-Score: 0.5540 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.0863 | Eval Loss: 1.2584 | Accuracy: 0.6533 | Precision: 0.6352 | Recall: 0.5743 | F1-Score: 0.5841 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.0923 | Eval Loss: 1.3144 | Accuracy: 0.5867 | Precision: 0.5236 | Recall: 0.5358 | F1-Score: 0.5250 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.0714 | Eval Loss: 1.2526 | Accuracy: 0.6267 | Precision: 0.5338 | Recall: 0.5343 | F1-Score: 0.5259 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.0994 | Eval Loss: 1.2713 | Accuracy: 0.6533 | Precision: 0.5875 | Recall: 0.5967 | F1-Score: 0.5820 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.0925 | Eval Loss: 1.3249 | Accuracy: 0.5600 | Precision: 0.4479 | Recall: 0.4529 | F1-Score: 0.4381 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.0728 | Eval Loss: 1.2575 | Accuracy: 0.6400 | Precision: 0.6724 | Recall: 0.5574 | F1-Score: 0.5310 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.0502 | Eval Loss: 1.2854 | Accuracy: 0.5733 | Precision: 0.4931 | Recall: 0.5027 | F1-Score: 0.4955 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.0566 | Eval Loss: 1.2693 | Accuracy: 0.6267 | Precision: 0.6388 | Recall: 0.5333 | F1-Score: 0.5342 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [3:37:37<00:00, 544.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        12\n",
      "           1       0.50      0.67      0.57        15\n",
      "           2       0.18      0.22      0.20         9\n",
      "           3       0.25      0.05      0.09        19\n",
      "           4       0.72      0.97      0.82        29\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.45      0.48      0.45        84\n",
      "weighted avg       0.50      0.56      0.51        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.303308, test accuracy: 0.5595, test precision: 0.4500, test recall: 0.4814, test F1-score: 0.4455\n",
      "Parámetros:  mean 2 2 900\n",
      "Resultados:  {'Aggr': 'mean', 'Conv': 2, 'LSTM': 2, 'LSTM_out': 900, 'Loss_final': 1.05661141872406, 'Accuracy_eval': 0.5956410256410256, 'Precision_eval': 0.4975411878106985, 'Recall_eval': 0.5017009283819628, 'F1_eval': 0.47375615706801394, 'Loss_eval': 1.2693215608596802, 'Loss_tst': 1.303308129310608, 'Accuracy_tst': 0.5595238095238095, 'Precision_tst': 0.44995337995338, 'Recall_tst': 0.4814075418431135, 'F1_tst': 0.4454738100773906}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"aggr\": [\"add\", \"mean\"],\n",
    "    \"conv\": [1,2],\n",
    "    \"lstm\": [1,2],\n",
    "    \"out_lstm\": [ 800,850, 900], #Number of input channels has to be smaller than number of output channels\n",
    "}\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": 4,\n",
    "    \"data_split_ratio\": [0.7, 0.15, 0.15],\n",
    "    \"seed\": 42,\n",
    "    \"keep_same\": True,\n",
    "    \"use_batch\": True\n",
    "}\n",
    "\n",
    "num_early_stop = 10\n",
    "num_epochs = 100\n",
    "problem = \"clasificacion\"\n",
    "\n",
    "mejor_trainer, mejores_parametros, mejores_resultados, resultados_df = entrenar_y_evaluar_modelos_dygrencoder(\n",
    "    param_grid, \n",
    "    dataset_full, \n",
    "    dataloader_params, \n",
    "    num_early_stop, \n",
    "    num_epochs, \n",
    "    problem, \"DyGrEncoder\",target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TEST INFO ===================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.47      0.53      0.50        15\n",
      "           2       0.43      0.33      0.38         9\n",
      "           3       0.54      0.37      0.44        19\n",
      "           4       0.74      0.90      0.81        29\n",
      "\n",
      "    accuracy                           0.63        84\n",
      "   macro avg       0.59      0.58      0.57        84\n",
      "weighted avg       0.62      0.63      0.62        84\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.278305, test accuracy: 0.6310, test precision: 0.5861, test recall: 0.5763, test F1-score: 0.5750\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc, test_precision, test_recall, test_f1, test_loss, preds, real = mejor_trainer.test()\n",
    "plot_clasificacion(real, preds, target_names, \"DyGrEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== GUARDANDO RESULTADOS ===================\n",
      "\n",
      "         Modelo                                             Params  \\\n",
      "0     MPNN_LSTM                {'Hidden Size': 64, 'Dropout': 0.2}   \n",
      "1    LSTM_BATCH                  {'Hidden Size': 150, 'Layers': 1}   \n",
      "2  LSTM_NOBATCH                  {'Hidden Size': 150, 'Layers': 2}   \n",
      "3         AGCRN             {'hidden': 50, 'Embedding': 5, 'K': 2}   \n",
      "4         AGCRN  {'aggr': 'mean', 'conv': 2, 'lstm': 1, 'lstm_o...   \n",
      "\n",
      "                      Fichero_resultados_experimento  Loss_tst  Loss_eval  \\\n",
      "0  ../experimentos_split/results/clasificacion/aj...  1.348738   1.286855   \n",
      "1  ../experimentos_split/results/clasificacion/aj...  1.163377   1.213140   \n",
      "2  ../experimentos_split/results/clasificacion/aj...  1.160608   1.194841   \n",
      "3  ../experimentos_split/results/clasificacion/aj...  1.344170   1.293829   \n",
      "4  ../experimentos_split/results/clasificacion/aj...  1.278305   1.244017   \n",
      "\n",
      "   Loss_final  Accuracy_eval  Precision_eval  Recall_eval   F1_eval  \\\n",
      "0    1.270143       0.600000        0.438630     0.498128  0.435153   \n",
      "1    1.075731       0.671875        0.630667     0.671140  0.635028   \n",
      "2    1.076455       0.706667        0.666084     0.685025  0.667648   \n",
      "3    1.254052       0.583333        0.399306     0.481816  0.421265   \n",
      "4    1.019157       0.626667        0.523039     0.498103  0.504885   \n",
      "\n",
      "   Accuracy_tst  Precision_tst  Recall_tst    F1_tst  \n",
      "0      0.535714       0.338182    0.475517  0.388172  \n",
      "1      0.765625       0.705541    0.699405  0.698988  \n",
      "2      0.738095       0.688172    0.677798  0.681843  \n",
      "3      0.547619       0.327039    0.495517  0.389881  \n",
      "4      0.630952       0.586096    0.576328  0.575000  \n",
      "\n",
      "==================== RESULTADOS GUARDADOS ===================\n",
      "\n",
      "\n",
      "==================== RESULTADOS GUARDADOS ===================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_model =\"DyGrEncoder\"\n",
    "results_save_path = \"../experimentos_split/results\"\n",
    "\n",
    "path_save_experiment = results_save_path+f\"/{problem}\"+ f\"/ajustes/{name_model}_results.csv\"\n",
    "resultados_df.to_csv(path_save_experiment, index=False)\n",
    "mejor_trainer.save_model(path_save_experiment=path_save_experiment, params = mejores_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
