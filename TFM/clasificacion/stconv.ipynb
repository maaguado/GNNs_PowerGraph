{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentación - STConv\n",
    "\n",
    "\n",
    "\n",
    "## 1. Obtención de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "sns.set_palette(\"coolwarm_r\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import GCNConv\n",
    "import itertools\n",
    "import os, sys\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "sys.path.insert(1, \"/\".join(path.split(\"/\")[0:-1]))\n",
    "\n",
    "from utils import powergrid\n",
    "\n",
    "\n",
    "from utils import pygt_loader\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable):\n",
    "        return iterable\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from utils.models import STConvModel\n",
    "from utils.trainer import  TrainerSTConv\n",
    "from utils.utils_graph import *\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_path = \"/home/TFM/code_dataset2/datos/Natural Oscillation\"\n",
    "folder_path = \"/Users/maguado/Documents/UGR/Master/TFM/datos_2/Natural Oscillation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n",
      "Processing:  row_307\n",
      "Node:  0  not included, including...\n",
      "Node:  1  not included, including...\n",
      "Node:  2  not included, including...\n",
      "Node:  3  not included, including...\n",
      "Node:  4  not included, including...\n",
      "Node:  5  not included, including...\n",
      "Node:  6  not included, including...\n",
      "Node:  7  not included, including...\n",
      "Node:  8  not included, including...\n",
      "Node:  9  not included, including...\n",
      "Node:  10  not included, including...\n",
      "Node:  11  not included, including...\n",
      "Node:  12  not included, including...\n",
      "Node:  13  not included, including...\n",
      "Node:  14  not included, including...\n",
      "Node:  15  not included, including...\n",
      "Node:  16  not included, including...\n",
      "Node:  17  not included, including...\n",
      "Node:  18  not included, including...\n",
      "Node:  19  not included, including...\n",
      "Node:  20  not included, including...\n",
      "Node:  21  not included, including...\n",
      "Node:  22  not included, including...\n",
      "Processing:  row_135\n",
      "Processing:  row_75\n",
      "Processing:  row_338\n",
      "Processing:  row_81\n",
      "Processing:  row_132\n",
      "Processing:  row_300\n",
      "Processing:  row_86\n",
      "Processing:  row_72\n",
      "Processing:  row_104\n",
      "Processing:  row_336\n",
      "Processing:  row_309\n",
      "Processing:  row_44\n",
      "Processing:  row_331\n",
      "Processing:  row_88\n",
      "Processing:  row_103\n",
      "Processing:  row_43\n",
      "Processing:  row_17\n",
      "Processing:  row_168\n",
      "Processing:  row_28\n",
      "Processing:  row_391\n",
      "Processing:  row_157\n",
      "Processing:  row_365\n",
      "Processing:  row_533\n",
      "Processing:  row_10\n",
      "Processing:  row_534\n",
      "Processing:  row_362\n",
      "Processing:  row_150\n",
      "Processing:  row_396\n",
      "Processing:  row_159\n",
      "Processing:  row_26\n",
      "Processing:  row_354\n",
      "Processing:  row_166\n",
      "Processing:  row_502\n",
      "Processing:  row_19\n",
      "Processing:  row_192\n",
      "Processing:  row_21\n",
      "Processing:  row_398\n",
      "Processing:  row_195\n",
      "Processing:  row_505\n",
      "Processing:  row_161\n",
      "Processing:  row_353\n",
      "Processing:  row_102\n",
      "Processing:  row_330\n",
      "Processing:  row_89\n",
      "Processing:  row_42\n",
      "Processing:  row_337\n",
      "Processing:  row_105\n",
      "Processing:  row_45\n",
      "Processing:  row_308\n",
      "Processing:  row_301\n",
      "Processing:  row_133\n",
      "Processing:  row_73\n",
      "Processing:  row_87\n",
      "Processing:  row_550\n",
      "Processing:  row_134\n",
      "Processing:  row_306\n",
      "Processing:  row_339\n",
      "Processing:  row_80\n",
      "Processing:  row_74\n",
      "Processing:  row_20\n",
      "Processing:  row_399\n",
      "Processing:  row_504\n",
      "Processing:  row_352\n",
      "Processing:  row_160\n",
      "Processing:  row_194\n",
      "Processing:  row_27\n",
      "Processing:  row_158\n",
      "Processing:  row_193\n",
      "Processing:  row_18\n",
      "Processing:  row_167\n",
      "Processing:  row_355\n",
      "Processing:  row_503\n",
      "Processing:  row_11\n",
      "Processing:  row_397\n",
      "Processing:  row_535\n",
      "Processing:  row_151\n",
      "Processing:  row_363\n",
      "Processing:  row_169\n",
      "Processing:  row_16\n",
      "Processing:  row_364\n",
      "Processing:  row_156\n",
      "Processing:  row_532\n",
      "Processing:  row_29\n",
      "Processing:  row_390\n",
      "Processing:  row_440\n",
      "Processing:  row_216\n",
      "Processing:  row_229\n",
      "Processing:  row_211\n",
      "Processing:  row_447\n",
      "Processing:  row_478\n",
      "Processing:  row_471\n",
      "Processing:  row_227\n",
      "Processing:  row_485\n",
      "Processing:  row_218\n",
      "Processing:  row_482\n",
      "Processing:  row_220\n",
      "Processing:  row_476\n",
      "Processing:  row_449\n",
      "Processing:  row_280\n",
      "Processing:  row_274\n",
      "Processing:  row_422\n",
      "Processing:  row_425\n",
      "Processing:  row_273\n",
      "Processing:  row_287\n",
      "Processing:  row_245\n",
      "Processing:  row_413\n",
      "Processing:  row_289\n",
      "Processing:  row_414\n",
      "Processing:  row_242\n",
      "Processing:  row_221\n",
      "Processing:  row_477\n",
      "Processing:  row_483\n",
      "Processing:  row_448\n",
      "Processing:  row_484\n",
      "Processing:  row_470\n",
      "Processing:  row_226\n",
      "Processing:  row_219\n",
      "Processing:  row_210\n",
      "Processing:  row_446\n",
      "Processing:  row_479\n",
      "Processing:  row_441\n",
      "Processing:  row_217\n",
      "Processing:  row_228\n",
      "Processing:  row_288\n",
      "Processing:  row_415\n",
      "Processing:  row_243\n",
      "Processing:  row_244\n",
      "Processing:  row_412\n",
      "Processing:  row_286\n",
      "Processing:  row_424\n",
      "Processing:  row_272\n",
      "Processing:  row_275\n",
      "Processing:  row_423\n",
      "Processing:  row_281\n",
      "Processing:  row_401\n",
      "Processing:  row_257\n",
      "Processing:  row_268\n",
      "Processing:  row_3\n",
      "Processing:  row_250\n",
      "Processing:  row_406\n",
      "Processing:  row_439\n",
      "Processing:  row_4\n",
      "Processing:  row_292\n",
      "Processing:  row_430\n",
      "Processing:  row_266\n",
      "Processing:  row_259\n",
      "Processing:  row_261\n",
      "Processing:  row_437\n",
      "Processing:  row_295\n",
      "Processing:  row_408\n",
      "Processing:  row_235\n",
      "Processing:  row_463\n",
      "Processing:  row_497\n",
      "Processing:  row_490\n",
      "Processing:  row_464\n",
      "Processing:  row_232\n",
      "Processing:  row_499\n",
      "Processing:  row_204\n",
      "Processing:  row_452\n",
      "Processing:  row_455\n",
      "Processing:  row_203\n",
      "Processing:  row_294\n",
      "Processing:  row_260\n",
      "Processing:  row_436\n",
      "Processing:  row_409\n",
      "Processing:  row_431\n",
      "Processing:  row_267\n",
      "Processing:  row_293\n",
      "Processing:  row_258\n",
      "Processing:  row_251\n",
      "Processing:  row_407\n",
      "Processing:  row_438\n",
      "Processing:  row_5\n",
      "Processing:  row_400\n",
      "Processing:  row_256\n",
      "Processing:  row_2\n",
      "Processing:  row_269\n",
      "Processing:  row_454\n",
      "Processing:  row_202\n",
      "Processing:  row_498\n",
      "Processing:  row_205\n",
      "Processing:  row_453\n",
      "Processing:  row_465\n",
      "Processing:  row_233\n",
      "Processing:  row_491\n",
      "Processing:  row_496\n",
      "Processing:  row_234\n",
      "Processing:  row_462\n",
      "Processing:  row_510\n",
      "Processing:  row_174\n",
      "Processing:  row_346\n",
      "Processing:  row_180\n",
      "Processing:  row_379\n",
      "Processing:  row_34\n",
      "Processing:  row_187\n",
      "Processing:  row_341\n",
      "Processing:  row_173\n",
      "Processing:  row_517\n",
      "Processing:  row_33\n",
      "Processing:  row_528\n",
      "Processing:  row_383\n",
      "Processing:  row_521\n",
      "Processing:  row_377\n",
      "Processing:  row_145\n",
      "Processing:  row_348\n",
      "Processing:  row_142\n",
      "Processing:  row_370\n",
      "Processing:  row_526\n",
      "Processing:  row_384\n",
      "Processing:  row_519\n",
      "Processing:  row_189\n",
      "Processing:  row_129\n",
      "Processing:  row_56\n",
      "Processing:  row_324\n",
      "Processing:  row_116\n",
      "Processing:  row_69\n",
      "Processing:  row_51\n",
      "Processing:  row_111\n",
      "Processing:  row_323\n",
      "Processing:  row_67\n",
      "Processing:  row_93\n",
      "Processing:  row_118\n",
      "Processing:  row_58\n",
      "Processing:  row_127\n",
      "Processing:  row_315\n",
      "Processing:  row_543\n",
      "Processing:  row_94\n",
      "Processing:  row_60\n",
      "Processing:  row_544\n",
      "Processing:  row_312\n",
      "Processing:  row_120\n",
      "Processing:  row_385\n",
      "Processing:  row_371\n",
      "Processing:  row_143\n",
      "Processing:  row_527\n",
      "Processing:  row_188\n",
      "Processing:  row_518\n",
      "Processing:  row_520\n",
      "Processing:  row_144\n",
      "Processing:  row_376\n",
      "Processing:  row_382\n",
      "Processing:  row_349\n",
      "Processing:  row_172\n",
      "Processing:  row_340\n",
      "Processing:  row_516\n",
      "Processing:  row_186\n",
      "Processing:  row_529\n",
      "Processing:  row_32\n",
      "Processing:  row_181\n",
      "Processing:  row_511\n",
      "Processing:  row_347\n",
      "Processing:  row_175\n",
      "Processing:  row_35\n",
      "Processing:  row_378\n",
      "Processing:  row_61\n",
      "Processing:  row_95\n",
      "Processing:  row_545\n",
      "Processing:  row_121\n",
      "Processing:  row_313\n",
      "Processing:  row_119\n",
      "Processing:  row_92\n",
      "Processing:  row_66\n",
      "Processing:  row_314\n",
      "Processing:  row_126\n",
      "Processing:  row_542\n",
      "Processing:  row_59\n",
      "Processing:  row_50\n",
      "Processing:  row_322\n",
      "Processing:  row_110\n",
      "Processing:  row_57\n",
      "Processing:  row_128\n",
      "Processing:  row_68\n",
      "Processing:  row_117\n",
      "Processing:  row_325\n",
      "Processing:  row_508\n",
      "Processing:  row_13\n",
      "Processing:  row_198\n",
      "Processing:  row_537\n",
      "Processing:  row_153\n",
      "Processing:  row_361\n",
      "Processing:  row_395\n",
      "Processing:  row_14\n",
      "Processing:  row_359\n",
      "Processing:  row_392\n",
      "Processing:  row_366\n",
      "Processing:  row_154\n",
      "Processing:  row_530\n",
      "Processing:  row_22\n",
      "Processing:  row_539\n",
      "Processing:  row_196\n",
      "Processing:  row_506\n",
      "Processing:  row_350\n",
      "Processing:  row_162\n",
      "Processing:  row_368\n",
      "Processing:  row_25\n",
      "Processing:  row_165\n",
      "Processing:  row_357\n",
      "Processing:  row_501\n",
      "Processing:  row_191\n",
      "Processing:  row_303\n",
      "Processing:  row_131\n",
      "Processing:  row_85\n",
      "Processing:  row_71\n",
      "Processing:  row_49\n",
      "Processing:  row_136\n",
      "Processing:  row_304\n",
      "Processing:  row_76\n",
      "Processing:  row_82\n",
      "Processing:  row_109\n",
      "Processing:  row_100\n",
      "Processing:  row_332\n",
      "Processing:  row_40\n",
      "Processing:  row_335\n",
      "Processing:  row_107\n",
      "Processing:  row_78\n",
      "Processing:  row_138\n",
      "Processing:  row_47\n",
      "Processing:  row_24\n",
      "Processing:  row_369\n",
      "Processing:  row_190\n",
      "Processing:  row_356\n",
      "Processing:  row_164\n",
      "Processing:  row_500\n",
      "Processing:  row_538\n",
      "Processing:  row_23\n",
      "Processing:  row_507\n",
      "Processing:  row_163\n",
      "Processing:  row_351\n",
      "Processing:  row_197\n",
      "Processing:  row_358\n",
      "Processing:  row_15\n",
      "Processing:  row_155\n",
      "Processing:  row_367\n",
      "Processing:  row_531\n",
      "Processing:  row_393\n",
      "Processing:  row_199\n",
      "Processing:  row_12\n",
      "Processing:  row_509\n",
      "Processing:  row_394\n",
      "Processing:  row_536\n",
      "Processing:  row_360\n",
      "Processing:  row_152\n",
      "Processing:  row_79\n",
      "Processing:  row_106\n",
      "Processing:  row_334\n",
      "Processing:  row_46\n",
      "Processing:  row_139\n",
      "Processing:  row_333\n",
      "Processing:  row_101\n",
      "Processing:  row_41\n",
      "Processing:  row_305\n",
      "Processing:  row_137\n",
      "Processing:  row_48\n",
      "Processing:  row_108\n",
      "Processing:  row_83\n",
      "Processing:  row_77\n",
      "Processing:  row_130\n",
      "Processing:  row_302\n",
      "Processing:  row_70\n",
      "Processing:  row_84\n",
      "Processing:  row_419\n",
      "Processing:  row_426\n",
      "Processing:  row_270\n",
      "Processing:  row_284\n",
      "Processing:  row_248\n",
      "Processing:  row_283\n",
      "Processing:  row_277\n",
      "Processing:  row_421\n",
      "Processing:  row_428\n",
      "Processing:  row_417\n",
      "Processing:  row_241\n",
      "Processing:  row_279\n",
      "Processing:  row_246\n",
      "Processing:  row_410\n",
      "Processing:  row_212\n",
      "Processing:  row_444\n",
      "Processing:  row_443\n",
      "Processing:  row_215\n",
      "Processing:  row_488\n",
      "Processing:  row_481\n",
      "Processing:  row_223\n",
      "Processing:  row_475\n",
      "Processing:  row_472\n",
      "Processing:  row_224\n",
      "Processing:  row_486\n",
      "Processing:  row_278\n",
      "Processing:  row_247\n",
      "Processing:  row_411\n",
      "Processing:  row_429\n",
      "Processing:  row_416\n",
      "Processing:  row_240\n",
      "Processing:  row_249\n",
      "Processing:  row_276\n",
      "Processing:  row_420\n",
      "Processing:  row_282\n",
      "Processing:  row_418\n",
      "Processing:  row_285\n",
      "Processing:  row_427\n",
      "Processing:  row_271\n",
      "Processing:  row_487\n",
      "Processing:  row_473\n",
      "Processing:  row_225\n",
      "Processing:  row_222\n",
      "Processing:  row_474\n",
      "Processing:  row_480\n",
      "Processing:  row_442\n",
      "Processing:  row_214\n",
      "Processing:  row_489\n",
      "Processing:  row_213\n",
      "Processing:  row_445\n",
      "Processing:  row_458\n",
      "Processing:  row_493\n",
      "Processing:  row_467\n",
      "Processing:  row_231\n",
      "Processing:  row_209\n",
      "Processing:  row_236\n",
      "Processing:  row_460\n",
      "Processing:  row_494\n",
      "Processing:  row_469\n",
      "Processing:  row_456\n",
      "Processing:  row_200\n",
      "Processing:  row_238\n",
      "Processing:  row_207\n",
      "Processing:  row_451\n",
      "Processing:  row_253\n",
      "Processing:  row_405\n",
      "Processing:  row_298\n",
      "Processing:  row_7\n",
      "Processing:  row_402\n",
      "Processing:  row_254\n",
      "Processing:  row_262\n",
      "Processing:  row_9\n",
      "Processing:  row_434\n",
      "Processing:  row_296\n",
      "Processing:  row_291\n",
      "Processing:  row_433\n",
      "Processing:  row_265\n",
      "Processing:  row_239\n",
      "Processing:  row_206\n",
      "Processing:  row_450\n",
      "Processing:  row_468\n",
      "Processing:  row_457\n",
      "Processing:  row_201\n",
      "Processing:  row_208\n",
      "Processing:  row_495\n",
      "Processing:  row_237\n",
      "Processing:  row_461\n",
      "Processing:  row_459\n",
      "Processing:  row_466\n",
      "Processing:  row_230\n",
      "Processing:  row_492\n",
      "Processing:  row_432\n",
      "Processing:  row_264\n",
      "Processing:  row_290\n",
      "Processing:  row_297\n",
      "Processing:  row_8\n",
      "Processing:  row_263\n",
      "Processing:  row_435\n",
      "Processing:  row_403\n",
      "Processing:  row_255\n",
      "Processing:  row_1\n",
      "Processing:  row_252\n",
      "Processing:  row_404\n",
      "Processing:  row_6\n",
      "Processing:  row_299\n",
      "Processing:  row_52\n",
      "Processing:  row_549\n",
      "Processing:  row_99\n",
      "Processing:  row_320\n",
      "Processing:  row_112\n",
      "Processing:  row_318\n",
      "Processing:  row_55\n",
      "Processing:  row_115\n",
      "Processing:  row_327\n",
      "Processing:  row_97\n",
      "Processing:  row_63\n",
      "Processing:  row_547\n",
      "Processing:  row_123\n",
      "Processing:  row_311\n",
      "Processing:  row_64\n",
      "Processing:  row_90\n",
      "Processing:  row_329\n",
      "Processing:  row_316\n",
      "Processing:  row_124\n",
      "Processing:  row_540\n",
      "Processing:  row_184\n",
      "Processing:  row_170\n",
      "Processing:  row_342\n",
      "Processing:  row_514\n",
      "Processing:  row_389\n",
      "Processing:  row_30\n",
      "Processing:  row_513\n",
      "Processing:  row_345\n",
      "Processing:  row_177\n",
      "Processing:  row_183\n",
      "Processing:  row_148\n",
      "Processing:  row_37\n",
      "Processing:  row_373\n",
      "Processing:  row_141\n",
      "Processing:  row_525\n",
      "Processing:  row_387\n",
      "Processing:  row_380\n",
      "Processing:  row_39\n",
      "Processing:  row_522\n",
      "Processing:  row_146\n",
      "Processing:  row_374\n",
      "Processing:  row_179\n",
      "Processing:  row_91\n",
      "Processing:  row_328\n",
      "Skipping  row_328\n",
      "Processing:  row_65\n",
      "Processing:  row_125\n",
      "Processing:  row_317\n",
      "Processing:  row_541\n",
      "Processing:  row_62\n",
      "Processing:  row_96\n",
      "Processing:  row_546\n",
      "Processing:  row_310\n",
      "Processing:  row_122\n",
      "Processing:  row_54\n",
      "Processing:  row_319\n",
      "Processing:  row_326\n",
      "Processing:  row_114\n",
      "Processing:  row_548\n",
      "Processing:  row_53\n",
      "Processing:  row_113\n",
      "Processing:  row_98\n",
      "Processing:  row_321\n",
      "Processing:  row_523\n",
      "Processing:  row_375\n",
      "Processing:  row_147\n",
      "Processing:  row_381\n",
      "Processing:  row_38\n",
      "Processing:  row_178\n",
      "Processing:  row_386\n",
      "Processing:  row_140\n",
      "Processing:  row_372\n",
      "Processing:  row_524\n",
      "Processing:  row_182\n",
      "Processing:  row_512\n",
      "Processing:  row_176\n",
      "Processing:  row_344\n",
      "Processing:  row_36\n",
      "Processing:  row_149\n",
      "Processing:  row_343\n",
      "Processing:  row_171\n",
      "Processing:  row_515\n",
      "Processing:  row_185\n",
      "Processing:  row_388\n",
      "Processing:  row_31\n",
      "Number of situations:  549\n",
      "Number of timestamps:  800\n",
      "Number of situations of the selected type:  549\n"
     ]
    }
   ],
   "source": [
    "loader = powergrid.PowerGridDatasetLoader(folder_path, problem=\"classification_type\")\n",
    "_,_,_ =loader.process()\n",
    "limit = 300\n",
    "dataset_full, situations_each = loader.get_dataset()\n",
    "target_names = loader.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares - entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_y_evaluar_modelos_stconv(param_grid, dataset, dataloader_params, num_early_stop, num_epochs, problem=\"Classification\", name=None, target_names=None, device=torch.device(\"cpu\")):\n",
    "    resultados_list = []\n",
    "\n",
    "    # Variables para guardar el mejor modelo\n",
    "    mejor_loss_test = float('inf')\n",
    "    mejor_trainer = None\n",
    "    mejores_parametros = None\n",
    "    mejores_resultados = None\n",
    "\n",
    "    # Detalles del dataset\n",
    "    n_nodes = dataset.features[0].shape[0]\n",
    "    n_target = dataset.targets[0].shape[0]\n",
    "    n_features = dataset[0].x.shape[1]\n",
    "\n",
    "    device = device\n",
    "    n_iter = 50  \n",
    "    for _ in tqdm(range(n_iter)):\n",
    "        # Selecciona aleatoriamente los parámetros\n",
    "        out_channels = random.choice(param_grid[\"out_channels\"])\n",
    "        kernel_size = random.choice(param_grid[\"kernel_size\"])\n",
    "        hidden_channels = random.choice(param_grid[\"hidden_channels\"])\n",
    "        normalization = random.choice(param_grid[\"normalization\"])\n",
    "       \n",
    "        print(f\"Entrenando modelo con out_channels={out_channels}, kernel_size={kernel_size}, hidden_channels={hidden_channels}, normalization={normalization}\")\n",
    "        model = STConvModel(name=\"STConv\", node_features=n_features, node_count=n_nodes, n_target=n_target, out_channels=out_channels,k=2, kernel_size=kernel_size, hidden_channels=hidden_channels, normalization=normalization, is_classification=True)\n",
    "        \n",
    "        trainer = TrainerSTConv(model, dataset, device, f\"../experimentos_split/results/{problem}\", dataloader_params, is_classification = True)\n",
    "\n",
    "        losses, eval_losses, accs, precisions, recalls, f1s = trainer.train(num_epochs=num_epochs, steps=50, num_early_stop=num_early_stop)\n",
    "        test_acc, test_precision, test_recall, test_f1, test_loss, preds, real = trainer.test()\n",
    "\n",
    "        results_intermedio = {\n",
    "            \"Out channels\": out_channels,\n",
    "            \"Kernel size\": kernel_size,\n",
    "            \"Hidden channels\": hidden_channels,\n",
    "            \"Normalization\": normalization,\n",
    "            \"Loss_final\": losses[-1],  \n",
    "            \"Accuracy_eval\": np.mean(accs),\n",
    "            \"Precision_eval\": np.mean(precisions),\n",
    "            \"Recall_eval\": np.mean(recalls),\n",
    "            \"F1_eval\": np.mean(f1s),\n",
    "            \"Loss_eval\": np.mean(eval_losses[-1]),  \n",
    "            \"Loss_tst\": np.mean(test_loss),\n",
    "            \"Accuracy_tst\": test_acc,\n",
    "            \"Precision_tst\": test_precision,\n",
    "            \"Recall_tst\": test_recall,\n",
    "            \"F1_tst\": test_f1\n",
    "        }\n",
    "    \n",
    "        resultados_list.append(results_intermedio)\n",
    "\n",
    "        # Actualizar el mejor modelo si es necesario\n",
    "        if np.mean(test_loss) < mejor_loss_test:\n",
    "            mejor_loss_test = np.mean(test_loss)\n",
    "            mejor_trainer = trainer\n",
    "            mejores_parametros = {\"Out channels\": out_channels, \"Kernel size\": kernel_size, \"Hidden channels\": hidden_channels, \"Normalization\": normalization}\n",
    "\n",
    "            mejores_resultados = results_intermedio\n",
    "\n",
    "        print(\"Resultados: \", resultados_list[-1])\n",
    "        \n",
    "    resultados_df = pd.DataFrame(resultados_list)\n",
    "    return mejor_trainer, mejores_parametros, mejores_resultados, resultados_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucle rápido para ajustar y guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.models\n",
    "utils.models = reload(utils.models)\n",
    "from utils.models import STConvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.trainer\n",
    "utils.trainer = reload(utils.trainer)\n",
    "from utils.trainer import TrainerSTConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con out_channels=64, kernel_size=7, hidden_channels=64, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5577 | Eval Loss: 1.4872 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5116 | Eval Loss: 1.4354 | Accuracy: 0.5366 | Precision: 0.2215 | Recall: 0.3529 | F1-Score: 0.2696 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.4801 | Eval Loss: 1.3981 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.4665 | Eval Loss: 1.3807 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4564 | Eval Loss: 1.3686 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4509 | Eval Loss: 1.3604 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4452 | Eval Loss: 1.3555 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4424 | Eval Loss: 1.3512 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4385 | Eval Loss: 1.3482 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4366 | Eval Loss: 1.3459 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4342 | Eval Loss: 1.3437 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4325 | Eval Loss: 1.3420 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4310 | Eval Loss: 1.3404 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4295 | Eval Loss: 1.3391 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4285 | Eval Loss: 1.3380 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4273 | Eval Loss: 1.3369 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.4262 | Eval Loss: 1.3361 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.4255 | Eval Loss: 1.3353 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.4245 | Eval Loss: 1.3344 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.4237 | Eval Loss: 1.3338 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.4228 | Eval Loss: 1.3332 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.4221 | Eval Loss: 1.3325 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.4214 | Eval Loss: 1.3322 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.4207 | Eval Loss: 1.3315 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.4195 | Eval Loss: 1.3314 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.4196 | Eval Loss: 1.3312 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.4182 | Eval Loss: 1.3307 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.4177 | Eval Loss: 1.3311 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.4169 | Eval Loss: 1.3309 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.4165 | Eval Loss: 1.3314 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.4158 | Eval Loss: 1.3319 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.4146 | Eval Loss: 1.3336 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.4141 | Eval Loss: 1.3380 | Accuracy: 0.5854 | Precision: 0.3681 | Recall: 0.4031 | F1-Score: 0.3332 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.4125 | Eval Loss: 1.3513 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.4103 | Eval Loss: 1.3748 | Accuracy: 0.5854 | Precision: 0.3370 | Recall: 0.4031 | F1-Score: 0.3326 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.4048 | Eval Loss: 1.3921 | Accuracy: 0.5976 | Precision: 0.3620 | Recall: 0.4165 | F1-Score: 0.3540 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.3975 | Eval Loss: 1.3984 | Accuracy: 0.6341 | Precision: 0.4339 | Recall: 0.4749 | F1-Score: 0.4217 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.3838 | Eval Loss: 1.3835 | Accuracy: 0.6463 | Precision: 0.4489 | Recall: 0.4965 | F1-Score: 0.4519 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.3737 | Eval Loss: 1.3949 | Accuracy: 0.6829 | Precision: 0.4893 | Recall: 0.5769 | F1-Score: 0.5157 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.3685 | Eval Loss: 1.3884 | Accuracy: 0.6463 | Precision: 0.4633 | Recall: 0.5552 | F1-Score: 0.4926 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.3478 | Eval Loss: 1.3804 | Accuracy: 0.6707 | Precision: 0.5013 | Recall: 0.5620 | F1-Score: 0.4934 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.3368 | Eval Loss: 1.3898 | Accuracy: 0.6707 | Precision: 0.5587 | Recall: 0.5335 | F1-Score: 0.4909 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.3306 | Eval Loss: 1.3416 | Accuracy: 0.6341 | Precision: 0.5798 | Recall: 0.4816 | F1-Score: 0.4227 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.3221 | Eval Loss: 1.3452 | Accuracy: 0.6585 | Precision: 0.5393 | Recall: 0.5082 | F1-Score: 0.4683 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.3357 | Eval Loss: 1.3837 | Accuracy: 0.6463 | Precision: 0.4709 | Recall: 0.5605 | F1-Score: 0.5025 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.3194 | Eval Loss: 1.3383 | Accuracy: 0.5976 | Precision: 0.4686 | Recall: 0.4351 | F1-Score: 0.3725 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.3083 | Eval Loss: 1.3491 | Accuracy: 0.6463 | Precision: 0.5061 | Recall: 0.4965 | F1-Score: 0.4596 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.3000 | Eval Loss: 1.3891 | Accuracy: 0.6707 | Precision: 0.5240 | Recall: 0.5532 | F1-Score: 0.5255 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.3029 | Eval Loss: 1.3474 | Accuracy: 0.6951 | Precision: 0.6143 | Recall: 0.5667 | F1-Score: 0.5057 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2949 | Eval Loss: 1.3589 | Accuracy: 0.6829 | Precision: 0.5714 | Recall: 0.5469 | F1-Score: 0.5102 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.3010 | Eval Loss: 1.3614 | Accuracy: 0.6707 | Precision: 0.5106 | Recall: 0.5532 | F1-Score: 0.5245 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.3077 | Eval Loss: 1.3761 | Accuracy: 0.6585 | Precision: 0.5475 | Recall: 0.5895 | F1-Score: 0.5069 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [14:16:58<699:52:00, 51418.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.82      0.44        11\n",
      "           1       0.52      0.73      0.61        15\n",
      "           2       0.67      0.22      0.33         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.72      0.72      0.72        29\n",
      "\n",
      "    accuracy                           0.52        83\n",
      "   macro avg       0.44      0.50      0.42        83\n",
      "weighted avg       0.46      0.52      0.46        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.445542, test accuracy: 0.5181, test precision: 0.4429, test recall: 0.4996, test F1-score: 0.4215\n",
      "Resultados:  {'Out channels': 64, 'Kernel size': 7, 'Hidden channels': 64, 'Normalization': 'rw', 'Loss_final': 1.3076761960983276, 'Accuracy_eval': 0.5992026266416511, 'Precision_eval': 0.3700127324970248, 'Recall_eval': 0.43336885126258945, 'F1_eval': 0.35672511372610255, 'Loss_eval': 1.37605881690979, 'Loss_tst': 1.4455422163009644, 'Accuracy_tst': 0.5180722891566265, 'Precision_tst': 0.44292282430213464, 'Recall_tst': 0.49957506095437126, 'F1_tst': 0.42152135314456596}\n",
      "Entrenando modelo con out_channels=32, kernel_size=7, hidden_channels=64, normalization=sym\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5583 | Eval Loss: 1.4993 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5299 | Eval Loss: 1.4759 | Accuracy: 0.4878 | Precision: 0.2197 | Recall: 0.3059 | F1-Score: 0.2414 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5128 | Eval Loss: 1.4569 | Accuracy: 0.5610 | Precision: 0.2288 | Recall: 0.3765 | F1-Score: 0.2838 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.5017 | Eval Loss: 1.4350 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4932 | Eval Loss: 1.4215 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4859 | Eval Loss: 1.4087 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4785 | Eval Loss: 1.3990 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4726 | Eval Loss: 1.3925 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4671 | Eval Loss: 1.3873 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4626 | Eval Loss: 1.3828 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4583 | Eval Loss: 1.3794 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4550 | Eval Loss: 1.3772 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4512 | Eval Loss: 1.3753 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4491 | Eval Loss: 1.3793 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4459 | Eval Loss: 1.3730 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4423 | Eval Loss: 1.3729 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.4408 | Eval Loss: 1.3881 | Accuracy: 0.5610 | Precision: 0.2221 | Recall: 0.3818 | F1-Score: 0.2807 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.4364 | Eval Loss: 1.3734 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.4321 | Eval Loss: 1.3883 | Accuracy: 0.5610 | Precision: 0.2221 | Recall: 0.3818 | F1-Score: 0.2807 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.4297 | Eval Loss: 1.3879 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.4248 | Eval Loss: 1.4031 | Accuracy: 0.5732 | Precision: 0.2335 | Recall: 0.3882 | F1-Score: 0.2916 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.4215 | Eval Loss: 1.3931 | Accuracy: 0.5732 | Precision: 0.2335 | Recall: 0.3882 | F1-Score: 0.2916 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.4144 | Eval Loss: 1.3888 | Accuracy: 0.5976 | Precision: 0.3033 | Recall: 0.4282 | F1-Score: 0.3483 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.4069 | Eval Loss: 1.3877 | Accuracy: 0.5976 | Precision: 0.3013 | Recall: 0.4282 | F1-Score: 0.3457 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3993 | Eval Loss: 1.3890 | Accuracy: 0.6098 | Precision: 0.3226 | Recall: 0.4482 | F1-Score: 0.3671 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3938 | Eval Loss: 1.3957 | Accuracy: 0.6220 | Precision: 0.3420 | Recall: 0.4682 | F1-Score: 0.3868 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3882 | Eval Loss: 1.3935 | Accuracy: 0.6463 | Precision: 0.5590 | Recall: 0.5016 | F1-Score: 0.4328 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3804 | Eval Loss: 1.3952 | Accuracy: 0.6341 | Precision: 0.5743 | Recall: 0.4951 | F1-Score: 0.4331 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3756 | Eval Loss: 1.3979 | Accuracy: 0.6585 | Precision: 0.5159 | Recall: 0.5351 | F1-Score: 0.4735 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3721 | Eval Loss: 1.3921 | Accuracy: 0.6829 | Precision: 0.6188 | Recall: 0.5887 | F1-Score: 0.4995 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.3650 | Eval Loss: 1.3941 | Accuracy: 0.6707 | Precision: 0.6086 | Recall: 0.5687 | F1-Score: 0.4864 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.3626 | Eval Loss: 1.3915 | Accuracy: 0.6951 | Precision: 0.6281 | Recall: 0.6004 | F1-Score: 0.5078 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.3577 | Eval Loss: 1.3912 | Accuracy: 0.6707 | Precision: 0.6097 | Recall: 0.5875 | F1-Score: 0.4878 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.3495 | Eval Loss: 1.3819 | Accuracy: 0.6585 | Precision: 0.5017 | Recall: 0.5269 | F1-Score: 0.4604 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.3497 | Eval Loss: 1.3776 | Accuracy: 0.6951 | Precision: 0.6294 | Recall: 0.5869 | F1-Score: 0.5050 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.3434 | Eval Loss: 1.3782 | Accuracy: 0.6951 | Precision: 0.6281 | Recall: 0.6004 | F1-Score: 0.5078 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.3419 | Eval Loss: 1.3839 | Accuracy: 0.6829 | Precision: 0.5237 | Recall: 0.5804 | F1-Score: 0.4961 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.3388 | Eval Loss: 1.3756 | Accuracy: 0.6951 | Precision: 0.6281 | Recall: 0.6004 | F1-Score: 0.5078 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.3289 | Eval Loss: 1.3677 | Accuracy: 0.6707 | Precision: 0.6189 | Recall: 0.5469 | F1-Score: 0.4801 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.3306 | Eval Loss: 1.3760 | Accuracy: 0.6951 | Precision: 0.5354 | Recall: 0.5869 | F1-Score: 0.5066 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.3283 | Eval Loss: 1.3709 | Accuracy: 0.6829 | Precision: 0.6183 | Recall: 0.5940 | F1-Score: 0.4976 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.3208 | Eval Loss: 1.3721 | Accuracy: 0.6951 | Precision: 0.6281 | Recall: 0.6004 | F1-Score: 0.5078 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.3205 | Eval Loss: 1.3718 | Accuracy: 0.6951 | Precision: 0.6294 | Recall: 0.5869 | F1-Score: 0.5050 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.3181 | Eval Loss: 1.3633 | Accuracy: 0.6951 | Precision: 0.6281 | Recall: 0.6004 | F1-Score: 0.5078 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.3120 | Eval Loss: 1.3651 | Accuracy: 0.6951 | Precision: 0.6294 | Recall: 0.5869 | F1-Score: 0.5050 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.3119 | Eval Loss: 1.3808 | Accuracy: 0.6829 | Precision: 0.5495 | Recall: 0.5873 | F1-Score: 0.5094 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.3121 | Eval Loss: 1.3606 | Accuracy: 0.6829 | Precision: 0.6183 | Recall: 0.5940 | F1-Score: 0.4976 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.3029 | Eval Loss: 1.3642 | Accuracy: 0.6951 | Precision: 0.6294 | Recall: 0.5869 | F1-Score: 0.5050 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.3027 | Eval Loss: 1.3725 | Accuracy: 0.6951 | Precision: 0.5676 | Recall: 0.5871 | F1-Score: 0.5265 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.3008 | Eval Loss: 1.3593 | Accuracy: 0.6829 | Precision: 0.6175 | Recall: 0.5804 | F1-Score: 0.4945 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.2935 | Eval Loss: 1.3692 | Accuracy: 0.6829 | Precision: 0.6192 | Recall: 0.5669 | F1-Score: 0.4908 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2965 | Eval Loss: 1.3659 | Accuracy: 0.7073 | Precision: 0.5818 | Recall: 0.5869 | F1-Score: 0.5408 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [35:08:59<871:28:49, 65361.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.73      0.40        11\n",
      "           1       0.73      0.73      0.73        15\n",
      "           2       0.50      0.22      0.31         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.77      0.93      0.84        29\n",
      "\n",
      "    accuracy                           0.58        83\n",
      "   macro avg       0.46      0.52      0.46        83\n",
      "weighted avg       0.49      0.58      0.51        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.444225, test accuracy: 0.5783, test precision: 0.4561, test recall: 0.5228, test F1-score: 0.4570\n",
      "Resultados:  {'Out channels': 32, 'Kernel size': 7, 'Hidden channels': 64, 'Normalization': 'sym', 'Loss_final': 1.296454906463623, 'Accuracy_eval': 0.6228893058161352, 'Precision_eval': 0.4165571582617609, 'Recall_eval': 0.47969469177249063, 'F1_eval': 0.39280360409807213, 'Loss_eval': 1.365902066230774, 'Loss_tst': 1.4442253112792969, 'Accuracy_tst': 0.5783132530120482, 'Precision_tst': 0.4561247947454844, 'Recall_tst': 0.5227725531173807, 'F1_tst': 0.45695512820512824}\n",
      "Entrenando modelo con out_channels=32, kernel_size=5, hidden_channels=32, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5817 | Eval Loss: 1.5343 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5572 | Eval Loss: 1.5197 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5319 | Eval Loss: 1.4956 | Accuracy: 0.4390 | Precision: 0.1626 | Recall: 0.2667 | F1-Score: 0.1942 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.5108 | Eval Loss: 1.4746 | Accuracy: 0.5000 | Precision: 0.1888 | Recall: 0.3333 | F1-Score: 0.2409 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4971 | Eval Loss: 1.4610 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4885 | Eval Loss: 1.4480 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4817 | Eval Loss: 1.4375 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4756 | Eval Loss: 1.4267 | Accuracy: 0.5244 | Precision: 0.3940 | Recall: 0.3569 | F1-Score: 0.2872 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4705 | Eval Loss: 1.4195 | Accuracy: 0.5244 | Precision: 0.3135 | Recall: 0.3522 | F1-Score: 0.3074 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4660 | Eval Loss: 1.4148 | Accuracy: 0.5122 | Precision: 0.2799 | Recall: 0.3357 | F1-Score: 0.2930 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4619 | Eval Loss: 1.4061 | Accuracy: 0.5488 | Precision: 0.2789 | Recall: 0.3663 | F1-Score: 0.2969 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4574 | Eval Loss: 1.3992 | Accuracy: 0.5732 | Precision: 0.3357 | Recall: 0.3898 | F1-Score: 0.3124 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4548 | Eval Loss: 1.4012 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4521 | Eval Loss: 1.3937 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4462 | Eval Loss: 1.3877 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4443 | Eval Loss: 1.3968 | Accuracy: 0.5610 | Precision: 0.2236 | Recall: 0.3818 | F1-Score: 0.2820 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.4415 | Eval Loss: 1.3874 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.4362 | Eval Loss: 1.3815 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.4329 | Eval Loss: 1.3788 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.4312 | Eval Loss: 1.3875 | Accuracy: 0.5610 | Precision: 0.2221 | Recall: 0.3818 | F1-Score: 0.2807 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.4288 | Eval Loss: 1.3851 | Accuracy: 0.5610 | Precision: 0.2221 | Recall: 0.3818 | F1-Score: 0.2807 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.4222 | Eval Loss: 1.3721 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.4167 | Eval Loss: 1.3751 | Accuracy: 0.5732 | Precision: 0.2273 | Recall: 0.3882 | F1-Score: 0.2867 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.4134 | Eval Loss: 1.3869 | Accuracy: 0.5610 | Precision: 0.2209 | Recall: 0.3818 | F1-Score: 0.2797 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.4118 | Eval Loss: 1.3906 | Accuracy: 0.5610 | Precision: 0.2209 | Recall: 0.3818 | F1-Score: 0.2797 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.4041 | Eval Loss: 1.3736 | Accuracy: 0.5732 | Precision: 0.2273 | Recall: 0.3882 | F1-Score: 0.2867 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3953 | Eval Loss: 1.3700 | Accuracy: 0.5732 | Precision: 0.2273 | Recall: 0.3882 | F1-Score: 0.2867 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3911 | Eval Loss: 1.3784 | Accuracy: 0.5610 | Precision: 0.2200 | Recall: 0.3818 | F1-Score: 0.2788 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3923 | Eval Loss: 1.3836 | Accuracy: 0.5976 | Precision: 0.3364 | Recall: 0.4418 | F1-Score: 0.3656 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3882 | Eval Loss: 1.3757 | Accuracy: 0.6220 | Precision: 0.3401 | Recall: 0.4682 | F1-Score: 0.3887 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.3733 | Eval Loss: 1.3600 | Accuracy: 0.5976 | Precision: 0.3186 | Recall: 0.4282 | F1-Score: 0.3485 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.3675 | Eval Loss: 1.3792 | Accuracy: 0.6220 | Precision: 0.3589 | Recall: 0.4682 | F1-Score: 0.3920 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.3613 | Eval Loss: 1.3891 | Accuracy: 0.6220 | Precision: 0.3435 | Recall: 0.4682 | F1-Score: 0.3870 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.3553 | Eval Loss: 1.3915 | Accuracy: 0.6341 | Precision: 0.3946 | Recall: 0.4882 | F1-Score: 0.4164 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.3499 | Eval Loss: 1.3776 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.3448 | Eval Loss: 1.3581 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4682 | F1-Score: 0.3894 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.3337 | Eval Loss: 1.3663 | Accuracy: 0.6463 | Precision: 0.5617 | Recall: 0.5016 | F1-Score: 0.4328 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.3287 | Eval Loss: 1.3696 | Accuracy: 0.6463 | Precision: 0.4993 | Recall: 0.5016 | F1-Score: 0.4443 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.3270 | Eval Loss: 1.3479 | Accuracy: 0.6341 | Precision: 0.3946 | Recall: 0.4882 | F1-Score: 0.4164 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.3191 | Eval Loss: 1.3583 | Accuracy: 0.6585 | Precision: 0.5111 | Recall: 0.5216 | F1-Score: 0.4627 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.3154 | Eval Loss: 1.3449 | Accuracy: 0.6463 | Precision: 0.4993 | Recall: 0.5016 | F1-Score: 0.4443 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.3124 | Eval Loss: 1.3388 | Accuracy: 0.6463 | Precision: 0.5969 | Recall: 0.5016 | F1-Score: 0.4435 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.3081 | Eval Loss: 1.3443 | Accuracy: 0.6707 | Precision: 0.5216 | Recall: 0.5416 | F1-Score: 0.4795 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.3056 | Eval Loss: 1.3228 | Accuracy: 0.6463 | Precision: 0.4993 | Recall: 0.5016 | F1-Score: 0.4443 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.3031 | Eval Loss: 1.3271 | Accuracy: 0.6463 | Precision: 0.4993 | Recall: 0.5016 | F1-Score: 0.4443 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.2995 | Eval Loss: 1.3285 | Accuracy: 0.6585 | Precision: 0.4851 | Recall: 0.5298 | F1-Score: 0.4729 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.2976 | Eval Loss: 1.3290 | Accuracy: 0.6707 | Precision: 0.4935 | Recall: 0.5416 | F1-Score: 0.4811 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.2956 | Eval Loss: 1.3031 | Accuracy: 0.6463 | Precision: 0.4993 | Recall: 0.5016 | F1-Score: 0.4443 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.2926 | Eval Loss: 1.3087 | Accuracy: 0.6463 | Precision: 0.4987 | Recall: 0.5031 | F1-Score: 0.4598 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2943 | Eval Loss: 1.2831 | Accuracy: 0.6341 | Precision: 0.4813 | Recall: 0.4831 | F1-Score: 0.4393 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.3008 | Eval Loss: 1.2936 | Accuracy: 0.6463 | Precision: 0.5868 | Recall: 0.4933 | F1-Score: 0.4304 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2919 | Eval Loss: 1.2861 | Accuracy: 0.6585 | Precision: 0.5616 | Recall: 0.5216 | F1-Score: 0.4462 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [42:52:56<629:37:41, 48226.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.82      0.56        11\n",
      "           1       0.52      0.73      0.61        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.70      0.97      0.81        29\n",
      "\n",
      "    accuracy                           0.58        83\n",
      "   macro avg       0.33      0.50      0.40        83\n",
      "weighted avg       0.40      0.58      0.47        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.377444, test accuracy: 0.5783, test precision: 0.3305, test recall: 0.5034, test F1-score: 0.3970\n",
      "Resultados:  {'Out channels': 32, 'Kernel size': 5, 'Hidden channels': 32, 'Normalization': 'rw', 'Loss_final': 1.291947841644287, 'Accuracy_eval': 0.5823170731707317, 'Precision_eval': 0.33255012377797677, 'Recall_eval': 0.41901571546732835, 'F1_eval': 0.34020440455722034, 'Loss_eval': 1.286113977432251, 'Loss_tst': 1.377443552017212, 'Accuracy_tst': 0.5783132530120482, 'Precision_tst': 0.3304761904761905, 'Recall_tst': 0.5034064785788923, 'F1_tst': 0.3970410628019324}\n",
      "Entrenando modelo con out_channels=32, kernel_size=3, hidden_channels=32, normalization=sym\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5833 | Eval Loss: 1.5269 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5543 | Eval Loss: 1.5106 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5363 | Eval Loss: 1.4927 | Accuracy: 0.5000 | Precision: 0.2080 | Recall: 0.3176 | F1-Score: 0.2448 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.5138 | Eval Loss: 1.4658 | Accuracy: 0.5366 | Precision: 0.2215 | Recall: 0.3529 | F1-Score: 0.2696 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4966 | Eval Loss: 1.4412 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4843 | Eval Loss: 1.4239 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4730 | Eval Loss: 1.4113 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4640 | Eval Loss: 1.3976 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4569 | Eval Loss: 1.3973 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4513 | Eval Loss: 1.3961 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4439 | Eval Loss: 1.3975 | Accuracy: 0.5488 | Precision: 0.2198 | Recall: 0.3753 | F1-Score: 0.2772 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4369 | Eval Loss: 1.3985 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4274 | Eval Loss: 1.3944 | Accuracy: 0.5854 | Precision: 0.3167 | Recall: 0.4218 | F1-Score: 0.3456 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4185 | Eval Loss: 1.3891 | Accuracy: 0.5854 | Precision: 0.3167 | Recall: 0.4218 | F1-Score: 0.3456 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4096 | Eval Loss: 1.3914 | Accuracy: 0.5854 | Precision: 0.3143 | Recall: 0.4218 | F1-Score: 0.3433 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4022 | Eval Loss: 1.3886 | Accuracy: 0.5854 | Precision: 0.3153 | Recall: 0.4218 | F1-Score: 0.3444 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.3956 | Eval Loss: 1.3900 | Accuracy: 0.5976 | Precision: 0.3302 | Recall: 0.4553 | F1-Score: 0.3764 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.3884 | Eval Loss: 1.3869 | Accuracy: 0.6098 | Precision: 0.3259 | Recall: 0.4618 | F1-Score: 0.3797 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.3784 | Eval Loss: 1.3912 | Accuracy: 0.6098 | Precision: 0.3295 | Recall: 0.4671 | F1-Score: 0.3801 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.3720 | Eval Loss: 1.3853 | Accuracy: 0.6098 | Precision: 0.3295 | Recall: 0.4618 | F1-Score: 0.3806 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.3648 | Eval Loss: 1.3873 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.3597 | Eval Loss: 1.3862 | Accuracy: 0.6220 | Precision: 0.3337 | Recall: 0.4735 | F1-Score: 0.3861 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.3537 | Eval Loss: 1.3800 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.3482 | Eval Loss: 1.3764 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3433 | Eval Loss: 1.3740 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3399 | Eval Loss: 1.3708 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3357 | Eval Loss: 1.3709 | Accuracy: 0.6341 | Precision: 0.3479 | Recall: 0.4882 | F1-Score: 0.4013 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3325 | Eval Loss: 1.3688 | Accuracy: 0.6341 | Precision: 0.3526 | Recall: 0.4882 | F1-Score: 0.4031 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3292 | Eval Loss: 1.3669 | Accuracy: 0.6220 | Precision: 0.3435 | Recall: 0.4682 | F1-Score: 0.3870 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3269 | Eval Loss: 1.3655 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4682 | F1-Score: 0.3894 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.3246 | Eval Loss: 1.3620 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4682 | F1-Score: 0.3894 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.3222 | Eval Loss: 1.3587 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4682 | F1-Score: 0.3894 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.3195 | Eval Loss: 1.3568 | Accuracy: 0.6220 | Precision: 0.3504 | Recall: 0.4682 | F1-Score: 0.3891 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.3171 | Eval Loss: 1.3561 | Accuracy: 0.6220 | Precision: 0.3639 | Recall: 0.4682 | F1-Score: 0.3923 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.3152 | Eval Loss: 1.3557 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.3134 | Eval Loss: 1.3554 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.3117 | Eval Loss: 1.3526 | Accuracy: 0.6220 | Precision: 0.3788 | Recall: 0.4682 | F1-Score: 0.3957 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.3105 | Eval Loss: 1.3514 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.3092 | Eval Loss: 1.3487 | Accuracy: 0.6220 | Precision: 0.3788 | Recall: 0.4682 | F1-Score: 0.3957 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.3074 | Eval Loss: 1.3473 | Accuracy: 0.6220 | Precision: 0.3788 | Recall: 0.4682 | F1-Score: 0.3957 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.3058 | Eval Loss: 1.3476 | Accuracy: 0.6220 | Precision: 0.3788 | Recall: 0.4682 | F1-Score: 0.3957 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.3044 | Eval Loss: 1.3463 | Accuracy: 0.6341 | Precision: 0.3860 | Recall: 0.4800 | F1-Score: 0.4033 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.3035 | Eval Loss: 1.3464 | Accuracy: 0.6341 | Precision: 0.3860 | Recall: 0.4800 | F1-Score: 0.4033 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.3024 | Eval Loss: 1.3439 | Accuracy: 0.6341 | Precision: 0.3860 | Recall: 0.4800 | F1-Score: 0.4033 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.3016 | Eval Loss: 1.3427 | Accuracy: 0.6341 | Precision: 0.3860 | Recall: 0.4800 | F1-Score: 0.4033 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.3002 | Eval Loss: 1.3414 | Accuracy: 0.6341 | Precision: 0.3860 | Recall: 0.4800 | F1-Score: 0.4033 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.2992 | Eval Loss: 1.3416 | Accuracy: 0.6463 | Precision: 0.5884 | Recall: 0.4933 | F1-Score: 0.4306 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.2982 | Eval Loss: 1.3404 | Accuracy: 0.6463 | Precision: 0.5884 | Recall: 0.4933 | F1-Score: 0.4306 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.2975 | Eval Loss: 1.3393 | Accuracy: 0.6463 | Precision: 0.5884 | Recall: 0.4933 | F1-Score: 0.4306 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2966 | Eval Loss: 1.3412 | Accuracy: 0.6463 | Precision: 0.4909 | Recall: 0.4933 | F1-Score: 0.4315 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.2960 | Eval Loss: 1.3352 | Accuracy: 0.6463 | Precision: 0.5884 | Recall: 0.4933 | F1-Score: 0.4306 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2950 | Eval Loss: 1.3363 | Accuracy: 0.6463 | Precision: 0.4909 | Recall: 0.4933 | F1-Score: 0.4315 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [51:06:32<522:20:46, 40879.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.91      0.44        11\n",
      "           1       0.80      0.53      0.64        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.72      0.97      0.82        29\n",
      "\n",
      "    accuracy                           0.55        83\n",
      "   macro avg       0.36      0.48      0.38        83\n",
      "weighted avg       0.43      0.55      0.46        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.424784, test accuracy: 0.5542, test precision: 0.3624, test recall: 0.4816, test F1-score: 0.3816\n",
      "Resultados:  {'Out channels': 32, 'Kernel size': 3, 'Hidden channels': 32, 'Normalization': 'sym', 'Loss_final': 1.2949799299240112, 'Accuracy_eval': 0.598499061913696, 'Precision_eval': 0.33975347486871615, 'Recall_eval': 0.4396920157641219, 'F1_eval': 0.3594776199142314, 'Loss_eval': 1.3362722396850586, 'Loss_tst': 1.4247835874557495, 'Accuracy_tst': 0.5542168674698795, 'Precision_tst': 0.36241327300150833, 'Recall_tst': 0.4815882967607106, 'F1_tst': 0.38159477124183006}\n",
      "Entrenando modelo con out_channels=32, kernel_size=5, hidden_channels=16, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5766 | Eval Loss: 1.5114 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5527 | Eval Loss: 1.5025 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5371 | Eval Loss: 1.4868 | Accuracy: 0.4268 | Precision: 0.1601 | Recall: 0.2533 | F1-Score: 0.1831 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.5150 | Eval Loss: 1.4628 | Accuracy: 0.4878 | Precision: 0.1852 | Recall: 0.3200 | F1-Score: 0.2336 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4960 | Eval Loss: 1.4403 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4827 | Eval Loss: 1.4225 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4737 | Eval Loss: 1.4094 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4666 | Eval Loss: 1.3991 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4612 | Eval Loss: 1.3911 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4562 | Eval Loss: 1.3809 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4518 | Eval Loss: 1.3754 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4485 | Eval Loss: 1.3728 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4454 | Eval Loss: 1.3712 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4425 | Eval Loss: 1.3712 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4395 | Eval Loss: 1.3711 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4361 | Eval Loss: 1.3718 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.4323 | Eval Loss: 1.3708 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.4279 | Eval Loss: 1.3705 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.4226 | Eval Loss: 1.3708 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.4162 | Eval Loss: 1.3719 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.4087 | Eval Loss: 1.3668 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.4002 | Eval Loss: 1.3696 | Accuracy: 0.5854 | Precision: 0.3653 | Recall: 0.4218 | F1-Score: 0.3501 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.3917 | Eval Loss: 1.3702 | Accuracy: 0.5854 | Precision: 0.3153 | Recall: 0.4218 | F1-Score: 0.3444 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.3821 | Eval Loss: 1.3715 | Accuracy: 0.6098 | Precision: 0.3437 | Recall: 0.4618 | F1-Score: 0.3859 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3735 | Eval Loss: 1.3738 | Accuracy: 0.6098 | Precision: 0.3296 | Recall: 0.4618 | F1-Score: 0.3800 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3657 | Eval Loss: 1.3703 | Accuracy: 0.6220 | Precision: 0.3312 | Recall: 0.4682 | F1-Score: 0.3860 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3580 | Eval Loss: 1.3709 | Accuracy: 0.6220 | Precision: 0.3307 | Recall: 0.4682 | F1-Score: 0.3852 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3514 | Eval Loss: 1.3719 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3454 | Eval Loss: 1.3649 | Accuracy: 0.6220 | Precision: 0.3307 | Recall: 0.4682 | F1-Score: 0.3852 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3398 | Eval Loss: 1.3645 | Accuracy: 0.6220 | Precision: 0.3306 | Recall: 0.4682 | F1-Score: 0.3846 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.3344 | Eval Loss: 1.3598 | Accuracy: 0.6341 | Precision: 0.3449 | Recall: 0.4882 | F1-Score: 0.4023 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.3300 | Eval Loss: 1.3557 | Accuracy: 0.6341 | Precision: 0.3449 | Recall: 0.4882 | F1-Score: 0.4023 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.3269 | Eval Loss: 1.3547 | Accuracy: 0.6341 | Precision: 0.3450 | Recall: 0.4882 | F1-Score: 0.4017 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.3250 | Eval Loss: 1.3416 | Accuracy: 0.6220 | Precision: 0.3307 | Recall: 0.4682 | F1-Score: 0.3852 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.3210 | Eval Loss: 1.3446 | Accuracy: 0.6220 | Precision: 0.3344 | Recall: 0.4682 | F1-Score: 0.3856 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.3157 | Eval Loss: 1.3389 | Accuracy: 0.6220 | Precision: 0.3343 | Recall: 0.4682 | F1-Score: 0.3860 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.3124 | Eval Loss: 1.3414 | Accuracy: 0.6341 | Precision: 0.3559 | Recall: 0.4882 | F1-Score: 0.4051 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.3092 | Eval Loss: 1.3370 | Accuracy: 0.6341 | Precision: 0.3559 | Recall: 0.4882 | F1-Score: 0.4051 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.3076 | Eval Loss: 1.3313 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4818 | F1-Score: 0.3994 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.3055 | Eval Loss: 1.3252 | Accuracy: 0.6098 | Precision: 0.3453 | Recall: 0.4618 | F1-Score: 0.3834 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.3024 | Eval Loss: 1.3214 | Accuracy: 0.6098 | Precision: 0.3441 | Recall: 0.4618 | F1-Score: 0.3834 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.2991 | Eval Loss: 1.3208 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4818 | F1-Score: 0.3994 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.2974 | Eval Loss: 1.3181 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4818 | F1-Score: 0.3994 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.2960 | Eval Loss: 1.3127 | Accuracy: 0.6220 | Precision: 0.3500 | Recall: 0.4818 | F1-Score: 0.3996 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.2943 | Eval Loss: 1.3093 | Accuracy: 0.6098 | Precision: 0.3433 | Recall: 0.4618 | F1-Score: 0.3836 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.2920 | Eval Loss: 1.3054 | Accuracy: 0.6341 | Precision: 0.3629 | Recall: 0.5018 | F1-Score: 0.4163 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.2905 | Eval Loss: 1.3063 | Accuracy: 0.6341 | Precision: 0.3629 | Recall: 0.5018 | F1-Score: 0.4163 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.2893 | Eval Loss: 1.3004 | Accuracy: 0.6341 | Precision: 0.3629 | Recall: 0.5018 | F1-Score: 0.4163 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.2873 | Eval Loss: 1.3000 | Accuracy: 0.6098 | Precision: 0.3352 | Recall: 0.4618 | F1-Score: 0.3815 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2855 | Eval Loss: 1.2967 | Accuracy: 0.6341 | Precision: 0.3629 | Recall: 0.5018 | F1-Score: 0.4163 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.2846 | Eval Loss: 1.2957 | Accuracy: 0.6341 | Precision: 0.4629 | Recall: 0.5034 | F1-Score: 0.4369 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2829 | Eval Loss: 1.2939 | Accuracy: 0.6220 | Precision: 0.5385 | Recall: 0.4751 | F1-Score: 0.4092 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [59:02:59<455:34:57, 36446.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.82      0.53        11\n",
      "           1       0.56      0.67      0.61        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.68      0.97      0.80        29\n",
      "\n",
      "    accuracy                           0.57        83\n",
      "   macro avg       0.33      0.49      0.39        83\n",
      "weighted avg       0.39      0.57      0.46        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.371745, test accuracy: 0.5663, test precision: 0.3260, test recall: 0.4901, test F1-score: 0.3871\n",
      "Resultados:  {'Out channels': 32, 'Kernel size': 5, 'Hidden channels': 16, 'Normalization': 'rw', 'Loss_final': 1.28294837474823, 'Accuracy_eval': 0.5827861163227017, 'Precision_eval': 0.2929614659462833, 'Recall_eval': 0.42394759889067285, 'F1_eval': 0.33759347851682703, 'Loss_eval': 1.29389488697052, 'Loss_tst': 1.371745228767395, 'Accuracy_tst': 0.5662650602409639, 'Precision_tst': 0.32595734652998704, 'Recall_tst': 0.49007314524555906, 'F1_tst': 0.3870944741532977}\n",
      "Entrenando modelo con out_channels=64, kernel_size=3, hidden_channels=16, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5737 | Eval Loss: 1.5276 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5521 | Eval Loss: 1.5031 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5395 | Eval Loss: 1.4894 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.5183 | Eval Loss: 1.4594 | Accuracy: 0.4878 | Precision: 0.2197 | Recall: 0.3059 | F1-Score: 0.2414 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4918 | Eval Loss: 1.4200 | Accuracy: 0.5488 | Precision: 0.2268 | Recall: 0.3647 | F1-Score: 0.2778 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4706 | Eval Loss: 1.3915 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4571 | Eval Loss: 1.3748 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4488 | Eval Loss: 1.3651 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4431 | Eval Loss: 1.3605 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4383 | Eval Loss: 1.3585 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4338 | Eval Loss: 1.3584 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4282 | Eval Loss: 1.3651 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4185 | Eval Loss: 1.3726 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4065 | Eval Loss: 1.3806 | Accuracy: 0.5854 | Precision: 0.3060 | Recall: 0.4218 | F1-Score: 0.3441 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.3921 | Eval Loss: 1.3805 | Accuracy: 0.5976 | Precision: 0.3134 | Recall: 0.4418 | F1-Score: 0.3623 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.3762 | Eval Loss: 1.3661 | Accuracy: 0.6098 | Precision: 0.3187 | Recall: 0.4482 | F1-Score: 0.3685 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.3618 | Eval Loss: 1.3567 | Accuracy: 0.6098 | Precision: 0.3187 | Recall: 0.4482 | F1-Score: 0.3685 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.3529 | Eval Loss: 1.3624 | Accuracy: 0.5854 | Precision: 0.3110 | Recall: 0.4489 | F1-Score: 0.3654 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.3446 | Eval Loss: 1.3620 | Accuracy: 0.6220 | Precision: 0.3481 | Recall: 0.5089 | F1-Score: 0.4088 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.3365 | Eval Loss: 1.3612 | Accuracy: 0.6341 | Precision: 0.3606 | Recall: 0.5289 | F1-Score: 0.4215 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.3287 | Eval Loss: 1.3579 | Accuracy: 0.6341 | Precision: 0.3606 | Recall: 0.5289 | F1-Score: 0.4215 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.3219 | Eval Loss: 1.3592 | Accuracy: 0.6341 | Precision: 0.3665 | Recall: 0.5289 | F1-Score: 0.4229 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.3165 | Eval Loss: 1.3584 | Accuracy: 0.6707 | Precision: 0.3890 | Recall: 0.5482 | F1-Score: 0.4494 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.3126 | Eval Loss: 1.3592 | Accuracy: 0.6951 | Precision: 0.5949 | Recall: 0.5816 | F1-Score: 0.4853 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3078 | Eval Loss: 1.3675 | Accuracy: 0.7073 | Precision: 0.6182 | Recall: 0.6016 | F1-Score: 0.5068 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3039 | Eval Loss: 1.3599 | Accuracy: 0.6951 | Precision: 0.5109 | Recall: 0.5816 | F1-Score: 0.4949 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3005 | Eval Loss: 1.3621 | Accuracy: 0.6829 | Precision: 0.5167 | Recall: 0.5616 | F1-Score: 0.4893 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.2999 | Eval Loss: 1.3541 | Accuracy: 0.6829 | Precision: 0.6046 | Recall: 0.5616 | F1-Score: 0.4838 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3034 | Eval Loss: 1.3454 | Accuracy: 0.6463 | Precision: 0.4993 | Recall: 0.5016 | F1-Score: 0.4443 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3025 | Eval Loss: 1.3390 | Accuracy: 0.6341 | Precision: 0.4854 | Recall: 0.4816 | F1-Score: 0.4240 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.2984 | Eval Loss: 1.3312 | Accuracy: 0.6463 | Precision: 0.5933 | Recall: 0.5016 | F1-Score: 0.4429 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.2932 | Eval Loss: 1.3452 | Accuracy: 0.6463 | Precision: 0.4937 | Recall: 0.5151 | F1-Score: 0.4524 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.2922 | Eval Loss: 1.3427 | Accuracy: 0.6829 | Precision: 0.6140 | Recall: 0.5616 | F1-Score: 0.4883 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.2924 | Eval Loss: 1.3411 | Accuracy: 0.6341 | Precision: 0.4806 | Recall: 0.4951 | F1-Score: 0.4345 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.2920 | Eval Loss: 1.3360 | Accuracy: 0.6463 | Precision: 0.5889 | Recall: 0.5151 | F1-Score: 0.4512 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.2900 | Eval Loss: 1.3343 | Accuracy: 0.6463 | Precision: 0.5889 | Recall: 0.5151 | F1-Score: 0.4512 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.2875 | Eval Loss: 1.3391 | Accuracy: 0.6585 | Precision: 0.6003 | Recall: 0.5351 | F1-Score: 0.4676 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.2875 | Eval Loss: 1.3326 | Accuracy: 0.6463 | Precision: 0.5889 | Recall: 0.5151 | F1-Score: 0.4512 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.2862 | Eval Loss: 1.3337 | Accuracy: 0.6463 | Precision: 0.4608 | Recall: 0.5151 | F1-Score: 0.4531 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.2856 | Eval Loss: 1.3288 | Accuracy: 0.6463 | Precision: 0.4608 | Recall: 0.5151 | F1-Score: 0.4531 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.2834 | Eval Loss: 1.3329 | Accuracy: 0.6585 | Precision: 0.4584 | Recall: 0.5351 | F1-Score: 0.4709 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.2828 | Eval Loss: 1.3301 | Accuracy: 0.6585 | Precision: 0.4584 | Recall: 0.5351 | F1-Score: 0.4709 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.2828 | Eval Loss: 1.3271 | Accuracy: 0.6463 | Precision: 0.4470 | Recall: 0.5151 | F1-Score: 0.4545 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.2813 | Eval Loss: 1.3274 | Accuracy: 0.6585 | Precision: 0.4800 | Recall: 0.5285 | F1-Score: 0.4760 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.2797 | Eval Loss: 1.3283 | Accuracy: 0.6829 | Precision: 0.5019 | Recall: 0.5685 | F1-Score: 0.5076 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.2793 | Eval Loss: 1.3221 | Accuracy: 0.6829 | Precision: 0.4918 | Recall: 0.5685 | F1-Score: 0.5084 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.2811 | Eval Loss: 1.3158 | Accuracy: 0.6463 | Precision: 0.4672 | Recall: 0.5085 | F1-Score: 0.4582 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.2775 | Eval Loss: 1.3270 | Accuracy: 0.6707 | Precision: 0.4914 | Recall: 0.5485 | F1-Score: 0.4924 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.2773 | Eval Loss: 1.3211 | Accuracy: 0.6829 | Precision: 0.5019 | Recall: 0.5685 | F1-Score: 0.5076 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2763 | Eval Loss: 1.3103 | Accuracy: 0.6829 | Precision: 0.4857 | Recall: 0.5685 | F1-Score: 0.5095 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.2802 | Eval Loss: 1.2985 | Accuracy: 0.6463 | Precision: 0.4510 | Recall: 0.5085 | F1-Score: 0.4601 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2760 | Eval Loss: 1.3114 | Accuracy: 0.6951 | Precision: 0.5002 | Recall: 0.5802 | F1-Score: 0.5168 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [74:31:02<525:23:52, 42987.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.82      0.50        11\n",
      "           1       0.73      0.73      0.73        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.77      0.93      0.84        29\n",
      "\n",
      "    accuracy                           0.57        83\n",
      "   macro avg       0.37      0.50      0.42        83\n",
      "weighted avg       0.45      0.57      0.49        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.398409, test accuracy: 0.5663, test precision: 0.3730, test recall: 0.4965, test F1-score: 0.4154\n",
      "Resultados:  {'Out channels': 64, 'Kernel size': 3, 'Hidden channels': 16, 'Normalization': 'rw', 'Loss_final': 1.2760146856307983, 'Accuracy_eval': 0.6179643527204502, 'Precision_eval': 0.4026154188927367, 'Recall_eval': 0.47663674402763595, 'F1_eval': 0.3996931001145, 'Loss_eval': 1.3113830089569092, 'Loss_tst': 1.3984088897705078, 'Accuracy_tst': 0.5662650602409639, 'Precision_tst': 0.3729523809523809, 'Recall_tst': 0.4965099268547545, 'F1_tst': 0.41541666666666666}\n",
      "Entrenando modelo con out_channels=64, kernel_size=7, hidden_channels=64, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5577 | Eval Loss: 1.4872 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5116 | Eval Loss: 1.4354 | Accuracy: 0.5366 | Precision: 0.2215 | Recall: 0.3529 | F1-Score: 0.2696 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.4801 | Eval Loss: 1.3981 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.4665 | Eval Loss: 1.3807 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4564 | Eval Loss: 1.3686 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4509 | Eval Loss: 1.3604 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4452 | Eval Loss: 1.3555 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4424 | Eval Loss: 1.3512 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4385 | Eval Loss: 1.3482 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4366 | Eval Loss: 1.3459 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4342 | Eval Loss: 1.3437 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4325 | Eval Loss: 1.3420 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4310 | Eval Loss: 1.3404 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4295 | Eval Loss: 1.3391 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4285 | Eval Loss: 1.3380 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4273 | Eval Loss: 1.3369 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.4262 | Eval Loss: 1.3361 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.4255 | Eval Loss: 1.3353 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.4245 | Eval Loss: 1.3344 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.4237 | Eval Loss: 1.3338 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.4228 | Eval Loss: 1.3332 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.4221 | Eval Loss: 1.3325 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.4214 | Eval Loss: 1.3322 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.4207 | Eval Loss: 1.3315 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.4195 | Eval Loss: 1.3314 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.4196 | Eval Loss: 1.3312 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.4182 | Eval Loss: 1.3307 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.4177 | Eval Loss: 1.3311 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.4169 | Eval Loss: 1.3309 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.4165 | Eval Loss: 1.3314 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.4158 | Eval Loss: 1.3319 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.4146 | Eval Loss: 1.3336 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.4141 | Eval Loss: 1.3380 | Accuracy: 0.5854 | Precision: 0.3681 | Recall: 0.4031 | F1-Score: 0.3332 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.4125 | Eval Loss: 1.3513 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.4103 | Eval Loss: 1.3748 | Accuracy: 0.5854 | Precision: 0.3370 | Recall: 0.4031 | F1-Score: 0.3326 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.4048 | Eval Loss: 1.3921 | Accuracy: 0.5976 | Precision: 0.3620 | Recall: 0.4165 | F1-Score: 0.3540 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.3975 | Eval Loss: 1.3984 | Accuracy: 0.6341 | Precision: 0.4339 | Recall: 0.4749 | F1-Score: 0.4217 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.3838 | Eval Loss: 1.3835 | Accuracy: 0.6463 | Precision: 0.4489 | Recall: 0.4965 | F1-Score: 0.4519 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.3737 | Eval Loss: 1.3949 | Accuracy: 0.6829 | Precision: 0.4893 | Recall: 0.5769 | F1-Score: 0.5157 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.3685 | Eval Loss: 1.3884 | Accuracy: 0.6463 | Precision: 0.4633 | Recall: 0.5552 | F1-Score: 0.4926 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.3478 | Eval Loss: 1.3804 | Accuracy: 0.6707 | Precision: 0.5013 | Recall: 0.5620 | F1-Score: 0.4934 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.3368 | Eval Loss: 1.3898 | Accuracy: 0.6707 | Precision: 0.5587 | Recall: 0.5335 | F1-Score: 0.4909 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.3306 | Eval Loss: 1.3416 | Accuracy: 0.6341 | Precision: 0.5798 | Recall: 0.4816 | F1-Score: 0.4227 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.3221 | Eval Loss: 1.3452 | Accuracy: 0.6585 | Precision: 0.5393 | Recall: 0.5082 | F1-Score: 0.4683 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.3357 | Eval Loss: 1.3837 | Accuracy: 0.6463 | Precision: 0.4709 | Recall: 0.5605 | F1-Score: 0.5025 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.3194 | Eval Loss: 1.3383 | Accuracy: 0.5976 | Precision: 0.4686 | Recall: 0.4351 | F1-Score: 0.3725 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.3083 | Eval Loss: 1.3491 | Accuracy: 0.6463 | Precision: 0.5061 | Recall: 0.4965 | F1-Score: 0.4596 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.3000 | Eval Loss: 1.3891 | Accuracy: 0.6707 | Precision: 0.5240 | Recall: 0.5532 | F1-Score: 0.5255 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.3029 | Eval Loss: 1.3474 | Accuracy: 0.6951 | Precision: 0.6143 | Recall: 0.5667 | F1-Score: 0.5057 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2949 | Eval Loss: 1.3589 | Accuracy: 0.6829 | Precision: 0.5714 | Recall: 0.5469 | F1-Score: 0.5102 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.3010 | Eval Loss: 1.3614 | Accuracy: 0.6707 | Precision: 0.5106 | Recall: 0.5532 | F1-Score: 0.5245 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.3077 | Eval Loss: 1.3761 | Accuracy: 0.6585 | Precision: 0.5475 | Recall: 0.5895 | F1-Score: 0.5069 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [86:10:23<509:26:59, 42651.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.82      0.44        11\n",
      "           1       0.52      0.73      0.61        15\n",
      "           2       0.67      0.22      0.33         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.72      0.72      0.72        29\n",
      "\n",
      "    accuracy                           0.52        83\n",
      "   macro avg       0.44      0.50      0.42        83\n",
      "weighted avg       0.46      0.52      0.46        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.445542, test accuracy: 0.5181, test precision: 0.4429, test recall: 0.4996, test F1-score: 0.4215\n",
      "Resultados:  {'Out channels': 64, 'Kernel size': 7, 'Hidden channels': 64, 'Normalization': 'rw', 'Loss_final': 1.3076761960983276, 'Accuracy_eval': 0.5992026266416511, 'Precision_eval': 0.3700127324970248, 'Recall_eval': 0.43336885126258945, 'F1_eval': 0.35672511372610255, 'Loss_eval': 1.37605881690979, 'Loss_tst': 1.4455422163009644, 'Accuracy_tst': 0.5180722891566265, 'Precision_tst': 0.44292282430213464, 'Recall_tst': 0.49957506095437126, 'F1_tst': 0.42152135314456596}\n",
      "Entrenando modelo con out_channels=64, kernel_size=7, hidden_channels=32, normalization=sym\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5454 | Eval Loss: 1.4620 | Accuracy: 0.4634 | Precision: 0.2146 | Recall: 0.2824 | F1-Score: 0.2216 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.4946 | Eval Loss: 1.4116 | Accuracy: 0.5610 | Precision: 0.2288 | Recall: 0.3765 | F1-Score: 0.2838 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.4723 | Eval Loss: 1.3826 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.4611 | Eval Loss: 1.3700 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4545 | Eval Loss: 1.3632 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4492 | Eval Loss: 1.3560 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4449 | Eval Loss: 1.3514 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4417 | Eval Loss: 1.3483 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4393 | Eval Loss: 1.3460 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4370 | Eval Loss: 1.3440 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4354 | Eval Loss: 1.3421 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4336 | Eval Loss: 1.3406 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4322 | Eval Loss: 1.3391 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4307 | Eval Loss: 1.3374 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4295 | Eval Loss: 1.3365 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4287 | Eval Loss: 1.3345 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.4267 | Eval Loss: 1.3339 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.4265 | Eval Loss: 1.3328 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.4249 | Eval Loss: 1.3319 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.4242 | Eval Loss: 1.3313 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.4233 | Eval Loss: 1.3301 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.4223 | Eval Loss: 1.3298 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.4221 | Eval Loss: 1.3287 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.4200 | Eval Loss: 1.3281 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.4204 | Eval Loss: 1.3279 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.4201 | Eval Loss: 1.3272 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.4175 | Eval Loss: 1.3268 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.4194 | Eval Loss: 1.3265 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.4159 | Eval Loss: 1.3258 | Accuracy: 0.5732 | Precision: 0.2291 | Recall: 0.3882 | F1-Score: 0.2881 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.4181 | Eval Loss: 1.3258 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.4157 | Eval Loss: 1.3260 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.4157 | Eval Loss: 1.3254 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.4140 | Eval Loss: 1.3257 | Accuracy: 0.5976 | Precision: 0.4379 | Recall: 0.4149 | F1-Score: 0.3418 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.4156 | Eval Loss: 1.3261 | Accuracy: 0.5854 | Precision: 0.4358 | Recall: 0.4016 | F1-Score: 0.3180 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.4116 | Eval Loss: 1.3247 | Accuracy: 0.5854 | Precision: 0.4333 | Recall: 0.4016 | F1-Score: 0.3163 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.4153 | Eval Loss: 1.3261 | Accuracy: 0.5854 | Precision: 0.3681 | Recall: 0.4031 | F1-Score: 0.3332 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.4109 | Eval Loss: 1.3253 | Accuracy: 0.6098 | Precision: 0.4429 | Recall: 0.4267 | F1-Score: 0.3492 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.4142 | Eval Loss: 1.3277 | Accuracy: 0.5732 | Precision: 0.3327 | Recall: 0.3898 | F1-Score: 0.3106 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.4094 | Eval Loss: 1.3248 | Accuracy: 0.6098 | Precision: 0.4429 | Recall: 0.4267 | F1-Score: 0.3492 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.4133 | Eval Loss: 1.3295 | Accuracy: 0.5976 | Precision: 0.3898 | Recall: 0.4165 | F1-Score: 0.3554 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.4083 | Eval Loss: 1.3256 | Accuracy: 0.6098 | Precision: 0.4429 | Recall: 0.4267 | F1-Score: 0.3492 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.4126 | Eval Loss: 1.3314 | Accuracy: 0.5610 | Precision: 0.3109 | Recall: 0.3796 | F1-Score: 0.3175 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.4071 | Eval Loss: 1.3262 | Accuracy: 0.5976 | Precision: 0.3246 | Recall: 0.4149 | F1-Score: 0.3401 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.4112 | Eval Loss: 1.3317 | Accuracy: 0.5732 | Precision: 0.3345 | Recall: 0.3914 | F1-Score: 0.3263 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.4058 | Eval Loss: 1.3275 | Accuracy: 0.6098 | Precision: 0.3496 | Recall: 0.4282 | F1-Score: 0.3607 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.4108 | Eval Loss: 1.3356 | Accuracy: 0.5488 | Precision: 0.3104 | Recall: 0.3710 | F1-Score: 0.3258 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.4053 | Eval Loss: 1.3248 | Accuracy: 0.5976 | Precision: 0.3423 | Recall: 0.4149 | F1-Score: 0.3403 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.4099 | Eval Loss: 1.3390 | Accuracy: 0.5488 | Precision: 0.3106 | Recall: 0.3725 | F1-Score: 0.3290 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.4046 | Eval Loss: 1.3306 | Accuracy: 0.5976 | Precision: 0.3442 | Recall: 0.4165 | F1-Score: 0.3529 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.4099 | Eval Loss: 1.3370 | Accuracy: 0.5610 | Precision: 0.3234 | Recall: 0.3843 | F1-Score: 0.3405 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.4036 | Eval Loss: 1.3263 | Accuracy: 0.6098 | Precision: 0.3496 | Recall: 0.4282 | F1-Score: 0.3607 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.4087 | Eval Loss: 1.3391 | Accuracy: 0.5488 | Precision: 0.3104 | Recall: 0.3710 | F1-Score: 0.3258 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [94:27:35<449:59:23, 38570.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        11\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.40      0.22      0.29         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.43      1.00      0.60        29\n",
      "\n",
      "    accuracy                           0.46        83\n",
      "   macro avg       0.29      0.37      0.31        83\n",
      "weighted avg       0.28      0.46      0.33        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.432909, test accuracy: 0.4578, test precision: 0.2938, test recall: 0.3717, test F1-score: 0.3052\n",
      "Resultados:  {'Out channels': 64, 'Kernel size': 7, 'Hidden channels': 32, 'Normalization': 'sym', 'Loss_final': 1.4086891412734985, 'Accuracy_eval': 0.5741088180112571, 'Precision_eval': 0.294091990900564, 'Recall_eval': 0.3916888045540797, 'F1_eval': 0.30723513946586356, 'Loss_eval': 1.3391014337539673, 'Loss_tst': 1.4329092502593994, 'Accuracy_tst': 0.4578313253012048, 'Precision_tst': 0.29383989145183176, 'Recall_tst': 0.3717171717171717, 'F1_tst': 0.30524891774891777}\n",
      "Entrenando modelo con out_channels=64, kernel_size=5, hidden_channels=32, normalization=sym\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.6000 | Eval Loss: 1.5323 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5430 | Eval Loss: 1.4851 | Accuracy: 0.3902 | Precision: 0.2765 | Recall: 0.2118 | F1-Score: 0.1329 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5148 | Eval Loss: 1.4493 | Accuracy: 0.5000 | Precision: 0.2080 | Recall: 0.3176 | F1-Score: 0.2448 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.4866 | Eval Loss: 1.4159 | Accuracy: 0.5610 | Precision: 0.2288 | Recall: 0.3765 | F1-Score: 0.2838 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4697 | Eval Loss: 1.3958 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4615 | Eval Loss: 1.3842 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4543 | Eval Loss: 1.3723 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4488 | Eval Loss: 1.3654 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4454 | Eval Loss: 1.3644 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4422 | Eval Loss: 1.3652 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4387 | Eval Loss: 1.3675 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4363 | Eval Loss: 1.3750 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4325 | Eval Loss: 1.3851 | Accuracy: 0.5610 | Precision: 0.2221 | Recall: 0.3818 | F1-Score: 0.2807 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4277 | Eval Loss: 1.3953 | Accuracy: 0.5488 | Precision: 0.2160 | Recall: 0.3753 | F1-Score: 0.2738 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4225 | Eval Loss: 1.4037 | Accuracy: 0.5732 | Precision: 0.3089 | Recall: 0.4153 | F1-Score: 0.3366 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4041 | Eval Loss: 1.3736 | Accuracy: 0.5854 | Precision: 0.3143 | Recall: 0.4218 | F1-Score: 0.3433 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.3868 | Eval Loss: 1.3749 | Accuracy: 0.5854 | Precision: 0.3030 | Recall: 0.4218 | F1-Score: 0.3406 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.3780 | Eval Loss: 1.3793 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.3691 | Eval Loss: 1.3797 | Accuracy: 0.6220 | Precision: 0.3412 | Recall: 0.4818 | F1-Score: 0.3954 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.3652 | Eval Loss: 1.3962 | Accuracy: 0.6220 | Precision: 0.3650 | Recall: 0.5360 | F1-Score: 0.4226 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.3526 | Eval Loss: 1.3767 | Accuracy: 0.6341 | Precision: 0.3629 | Recall: 0.5018 | F1-Score: 0.4140 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.3428 | Eval Loss: 1.3614 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.3443 | Eval Loss: 1.3614 | Accuracy: 0.6341 | Precision: 0.3946 | Recall: 0.4882 | F1-Score: 0.4164 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.3427 | Eval Loss: 1.3847 | Accuracy: 0.6463 | Precision: 0.3994 | Recall: 0.5489 | F1-Score: 0.4500 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3295 | Eval Loss: 1.3676 | Accuracy: 0.6463 | Precision: 0.4064 | Recall: 0.5082 | F1-Score: 0.4348 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3227 | Eval Loss: 1.3594 | Accuracy: 0.6341 | Precision: 0.3946 | Recall: 0.4882 | F1-Score: 0.4164 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3204 | Eval Loss: 1.3543 | Accuracy: 0.6463 | Precision: 0.4023 | Recall: 0.5000 | F1-Score: 0.4242 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3228 | Eval Loss: 1.3525 | Accuracy: 0.6829 | Precision: 0.4197 | Recall: 0.5600 | F1-Score: 0.4691 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3217 | Eval Loss: 1.3695 | Accuracy: 0.6829 | Precision: 0.4179 | Recall: 0.5735 | F1-Score: 0.4729 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3125 | Eval Loss: 1.3705 | Accuracy: 0.6829 | Precision: 0.4179 | Recall: 0.5735 | F1-Score: 0.4729 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.3046 | Eval Loss: 1.3744 | Accuracy: 0.6829 | Precision: 0.4351 | Recall: 0.5600 | F1-Score: 0.4752 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.3004 | Eval Loss: 1.3717 | Accuracy: 0.6829 | Precision: 0.4197 | Recall: 0.5600 | F1-Score: 0.4691 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.2959 | Eval Loss: 1.3745 | Accuracy: 0.6585 | Precision: 0.4224 | Recall: 0.5335 | F1-Score: 0.4542 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.2998 | Eval Loss: 1.3542 | Accuracy: 0.6463 | Precision: 0.4023 | Recall: 0.5000 | F1-Score: 0.4242 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.3021 | Eval Loss: 1.3484 | Accuracy: 0.6463 | Precision: 0.5904 | Recall: 0.4933 | F1-Score: 0.4310 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.3023 | Eval Loss: 1.3264 | Accuracy: 0.6585 | Precision: 0.6005 | Recall: 0.5133 | F1-Score: 0.4507 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.2944 | Eval Loss: 1.3298 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.2903 | Eval Loss: 1.3406 | Accuracy: 0.6951 | Precision: 0.6223 | Recall: 0.5733 | F1-Score: 0.4965 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.2866 | Eval Loss: 1.3614 | Accuracy: 0.6707 | Precision: 0.5268 | Recall: 0.5469 | F1-Score: 0.4820 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.2884 | Eval Loss: 1.3467 | Accuracy: 0.6951 | Precision: 0.6223 | Recall: 0.5733 | F1-Score: 0.4965 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.2862 | Eval Loss: 1.3467 | Accuracy: 0.6341 | Precision: 0.5872 | Recall: 0.4869 | F1-Score: 0.4255 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.2903 | Eval Loss: 1.3220 | Accuracy: 0.6585 | Precision: 0.6005 | Recall: 0.5133 | F1-Score: 0.4507 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.2848 | Eval Loss: 1.3267 | Accuracy: 0.6463 | Precision: 0.5904 | Recall: 0.4933 | F1-Score: 0.4310 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.2827 | Eval Loss: 1.3371 | Accuracy: 0.6829 | Precision: 0.6116 | Recall: 0.5533 | F1-Score: 0.4812 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.2815 | Eval Loss: 1.3377 | Accuracy: 0.6829 | Precision: 0.6116 | Recall: 0.5533 | F1-Score: 0.4812 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.2815 | Eval Loss: 1.3356 | Accuracy: 0.6341 | Precision: 0.4895 | Recall: 0.4869 | F1-Score: 0.4263 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.2826 | Eval Loss: 1.3211 | Accuracy: 0.6463 | Precision: 0.4928 | Recall: 0.4933 | F1-Score: 0.4318 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.2801 | Eval Loss: 1.3255 | Accuracy: 0.6463 | Precision: 0.4928 | Recall: 0.4933 | F1-Score: 0.4318 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.2798 | Eval Loss: 1.3231 | Accuracy: 0.6463 | Precision: 0.4763 | Recall: 0.4933 | F1-Score: 0.4283 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2774 | Eval Loss: 1.3321 | Accuracy: 0.6585 | Precision: 0.5395 | Recall: 0.5202 | F1-Score: 0.4698 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.2782 | Eval Loss: 1.3204 | Accuracy: 0.6463 | Precision: 0.4763 | Recall: 0.4933 | F1-Score: 0.4283 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2777 | Eval Loss: 1.3218 | Accuracy: 0.6585 | Precision: 0.4980 | Recall: 0.5067 | F1-Score: 0.4552 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [119:48:16<626:47:59, 55036.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.82      0.41        11\n",
      "           1       0.82      0.60      0.69        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.74      0.97      0.84        29\n",
      "\n",
      "    accuracy                           0.55        83\n",
      "   macro avg       0.37      0.48      0.39        83\n",
      "weighted avg       0.44      0.55      0.47        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.423963, test accuracy: 0.5542, test precision: 0.3656, test recall: 0.4767, test F1-score: 0.3874\n",
      "Resultados:  {'Out channels': 64, 'Kernel size': 5, 'Hidden channels': 32, 'Normalization': 'sym', 'Loss_final': 1.2776970863342285, 'Accuracy_eval': 0.6165572232645403, 'Precision_eval': 0.39406359440693134, 'Recall_eval': 0.46719116430691376, 'F1_eval': 0.3867348685553196, 'Loss_eval': 1.3217661380767822, 'Loss_tst': 1.4239627122879028, 'Accuracy_tst': 0.5542168674698795, 'Precision_tst': 0.36555023923444974, 'Recall_tst': 0.4767398119122257, 'F1_tst': 0.3874438993841979}\n",
      "Entrenando modelo con out_channels=32, kernel_size=3, hidden_channels=32, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5827 | Eval Loss: 1.5262 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5539 | Eval Loss: 1.5098 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5353 | Eval Loss: 1.4915 | Accuracy: 0.5122 | Precision: 0.2142 | Recall: 0.3294 | F1-Score: 0.2541 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.5123 | Eval Loss: 1.4638 | Accuracy: 0.5488 | Precision: 0.2236 | Recall: 0.3647 | F1-Score: 0.2759 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4935 | Eval Loss: 1.4360 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4812 | Eval Loss: 1.4222 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4687 | Eval Loss: 1.4013 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4601 | Eval Loss: 1.3944 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4532 | Eval Loss: 1.3976 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4462 | Eval Loss: 1.3970 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4371 | Eval Loss: 1.3961 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4266 | Eval Loss: 1.3970 | Accuracy: 0.5854 | Precision: 0.3143 | Recall: 0.4218 | F1-Score: 0.3433 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4169 | Eval Loss: 1.3843 | Accuracy: 0.5854 | Precision: 0.3167 | Recall: 0.4218 | F1-Score: 0.3456 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4073 | Eval Loss: 1.3904 | Accuracy: 0.5854 | Precision: 0.3143 | Recall: 0.4218 | F1-Score: 0.3433 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.3999 | Eval Loss: 1.3930 | Accuracy: 0.6098 | Precision: 0.3351 | Recall: 0.4618 | F1-Score: 0.3825 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.3909 | Eval Loss: 1.3821 | Accuracy: 0.5854 | Precision: 0.3038 | Recall: 0.4218 | F1-Score: 0.3420 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.3817 | Eval Loss: 1.3849 | Accuracy: 0.6220 | Precision: 0.3419 | Recall: 0.4735 | F1-Score: 0.3892 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.3761 | Eval Loss: 1.3901 | Accuracy: 0.6220 | Precision: 0.3337 | Recall: 0.4735 | F1-Score: 0.3861 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.3691 | Eval Loss: 1.3879 | Accuracy: 0.6098 | Precision: 0.3266 | Recall: 0.4618 | F1-Score: 0.3782 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.3610 | Eval Loss: 1.3884 | Accuracy: 0.6220 | Precision: 0.3337 | Recall: 0.4735 | F1-Score: 0.3861 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.3555 | Eval Loss: 1.3868 | Accuracy: 0.6220 | Precision: 0.3337 | Recall: 0.4735 | F1-Score: 0.3861 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.3503 | Eval Loss: 1.3826 | Accuracy: 0.6341 | Precision: 0.3455 | Recall: 0.4882 | F1-Score: 0.4014 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.3450 | Eval Loss: 1.3807 | Accuracy: 0.6220 | Precision: 0.3412 | Recall: 0.4818 | F1-Score: 0.3954 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.3407 | Eval Loss: 1.3773 | Accuracy: 0.6220 | Precision: 0.3412 | Recall: 0.4818 | F1-Score: 0.3954 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3363 | Eval Loss: 1.3727 | Accuracy: 0.6220 | Precision: 0.3317 | Recall: 0.4682 | F1-Score: 0.3839 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3336 | Eval Loss: 1.3733 | Accuracy: 0.6341 | Precision: 0.3526 | Recall: 0.4882 | F1-Score: 0.4031 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3305 | Eval Loss: 1.3713 | Accuracy: 0.6220 | Precision: 0.3435 | Recall: 0.4682 | F1-Score: 0.3870 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3280 | Eval Loss: 1.3687 | Accuracy: 0.6341 | Precision: 0.3509 | Recall: 0.4800 | F1-Score: 0.3949 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3252 | Eval Loss: 1.3653 | Accuracy: 0.6220 | Precision: 0.3520 | Recall: 0.4682 | F1-Score: 0.3894 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3233 | Eval Loss: 1.3662 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.3212 | Eval Loss: 1.3595 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.3187 | Eval Loss: 1.3566 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.3163 | Eval Loss: 1.3567 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.3142 | Eval Loss: 1.3554 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.3124 | Eval Loss: 1.3539 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.3111 | Eval Loss: 1.3529 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.3098 | Eval Loss: 1.3493 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.3084 | Eval Loss: 1.3464 | Accuracy: 0.6220 | Precision: 0.3807 | Recall: 0.4682 | F1-Score: 0.3961 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.3071 | Eval Loss: 1.3483 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.3053 | Eval Loss: 1.3430 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.3039 | Eval Loss: 1.3416 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.3033 | Eval Loss: 1.3448 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.3018 | Eval Loss: 1.3376 | Accuracy: 0.6341 | Precision: 0.3860 | Recall: 0.4800 | F1-Score: 0.4033 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.3009 | Eval Loss: 1.3386 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.2999 | Eval Loss: 1.3374 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.2984 | Eval Loss: 1.3351 | Accuracy: 0.6341 | Precision: 0.3860 | Recall: 0.4800 | F1-Score: 0.4033 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.2976 | Eval Loss: 1.3402 | Accuracy: 0.6463 | Precision: 0.4023 | Recall: 0.5000 | F1-Score: 0.4242 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.2968 | Eval Loss: 1.3412 | Accuracy: 0.6707 | Precision: 0.4090 | Recall: 0.5400 | F1-Score: 0.4538 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.2964 | Eval Loss: 1.3459 | Accuracy: 0.6707 | Precision: 0.4090 | Recall: 0.5400 | F1-Score: 0.4538 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2956 | Eval Loss: 1.3461 | Accuracy: 0.6829 | Precision: 0.4197 | Recall: 0.5600 | F1-Score: 0.4691 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.2957 | Eval Loss: 1.3384 | Accuracy: 0.6463 | Precision: 0.4023 | Recall: 0.5000 | F1-Score: 0.4242 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2999 | Eval Loss: 1.3375 | Accuracy: 0.6220 | Precision: 0.3850 | Recall: 0.4735 | F1-Score: 0.3984 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [251:59:16<2055:02:06, 184953.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.91      0.44        11\n",
      "           1       0.80      0.53      0.64        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.72      0.97      0.82        29\n",
      "\n",
      "    accuracy                           0.55        83\n",
      "   macro avg       0.36      0.48      0.38        83\n",
      "weighted avg       0.43      0.55      0.46        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.422145, test accuracy: 0.5542, test precision: 0.3624, test recall: 0.4816, test F1-score: 0.3816\n",
      "Resultados:  {'Out channels': 32, 'Kernel size': 3, 'Hidden channels': 32, 'Normalization': 'rw', 'Loss_final': 1.2998621463775635, 'Accuracy_eval': 0.6050656660412759, 'Precision_eval': 0.3299930058992381, 'Recall_eval': 0.4480834914611005, 'F1_eval': 0.36560997303472054, 'Loss_eval': 1.337524652481079, 'Loss_tst': 1.4221454858779907, 'Accuracy_tst': 0.5542168674698795, 'Precision_tst': 0.36241327300150833, 'Recall_tst': 0.4815882967607106, 'F1_tst': 0.38159477124183006}\n",
      "Entrenando modelo con out_channels=64, kernel_size=5, hidden_channels=32, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.6005 | Eval Loss: 1.5368 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5429 | Eval Loss: 1.4846 | Accuracy: 0.3902 | Precision: 0.2765 | Recall: 0.2118 | F1-Score: 0.1329 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5143 | Eval Loss: 1.4487 | Accuracy: 0.5000 | Precision: 0.2080 | Recall: 0.3176 | F1-Score: 0.2448 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.4865 | Eval Loss: 1.4157 | Accuracy: 0.5610 | Precision: 0.2288 | Recall: 0.3765 | F1-Score: 0.2838 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4695 | Eval Loss: 1.3955 | Accuracy: 0.5732 | Precision: 0.2312 | Recall: 0.3882 | F1-Score: 0.2896 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4613 | Eval Loss: 1.3836 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4548 | Eval Loss: 1.3766 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4503 | Eval Loss: 1.3686 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4455 | Eval Loss: 1.3668 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4424 | Eval Loss: 1.3642 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4398 | Eval Loss: 1.3805 | Accuracy: 0.5610 | Precision: 0.2236 | Recall: 0.3818 | F1-Score: 0.2820 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4364 | Eval Loss: 1.3752 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4291 | Eval Loss: 1.3882 | Accuracy: 0.5610 | Precision: 0.2221 | Recall: 0.3818 | F1-Score: 0.2807 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4215 | Eval Loss: 1.3945 | Accuracy: 0.5610 | Precision: 0.2221 | Recall: 0.3818 | F1-Score: 0.2807 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4083 | Eval Loss: 1.3862 | Accuracy: 0.5732 | Precision: 0.3089 | Recall: 0.4153 | F1-Score: 0.3366 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4019 | Eval Loss: 1.4021 | Accuracy: 0.5976 | Precision: 0.3193 | Recall: 0.4553 | F1-Score: 0.3715 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.3918 | Eval Loss: 1.3892 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.3742 | Eval Loss: 1.3721 | Accuracy: 0.6098 | Precision: 0.3296 | Recall: 0.4618 | F1-Score: 0.3800 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.3648 | Eval Loss: 1.3731 | Accuracy: 0.6098 | Precision: 0.3266 | Recall: 0.4618 | F1-Score: 0.3782 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.3583 | Eval Loss: 1.3704 | Accuracy: 0.6220 | Precision: 0.3412 | Recall: 0.4818 | F1-Score: 0.3954 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.3568 | Eval Loss: 1.3830 | Accuracy: 0.6341 | Precision: 0.3689 | Recall: 0.5289 | F1-Score: 0.4247 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.3478 | Eval Loss: 1.3710 | Accuracy: 0.6341 | Precision: 0.3629 | Recall: 0.5018 | F1-Score: 0.4140 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.3418 | Eval Loss: 1.3635 | Accuracy: 0.6341 | Precision: 0.3676 | Recall: 0.4882 | F1-Score: 0.4084 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.3410 | Eval Loss: 1.3715 | Accuracy: 0.6341 | Precision: 0.3721 | Recall: 0.5289 | F1-Score: 0.4268 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3315 | Eval Loss: 1.3598 | Accuracy: 0.6463 | Precision: 0.4064 | Recall: 0.5082 | F1-Score: 0.4348 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3264 | Eval Loss: 1.3594 | Accuracy: 0.6463 | Precision: 0.4064 | Recall: 0.5082 | F1-Score: 0.4348 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3242 | Eval Loss: 1.3553 | Accuracy: 0.6463 | Precision: 0.4064 | Recall: 0.5082 | F1-Score: 0.4348 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3209 | Eval Loss: 1.3585 | Accuracy: 0.6463 | Precision: 0.4064 | Recall: 0.5082 | F1-Score: 0.4348 | LR: 0.0010 | \n",
      "Epoch 29/100 | Train Loss: 1.3180 | Eval Loss: 1.3635 | Accuracy: 0.6707 | Precision: 0.4251 | Recall: 0.5400 | F1-Score: 0.4596 | LR: 0.0010 | \n",
      "Epoch 30/100 | Train Loss: 1.3123 | Eval Loss: 1.3624 | Accuracy: 0.6707 | Precision: 0.4251 | Recall: 0.5400 | F1-Score: 0.4596 | LR: 0.0010 | \n",
      "Epoch 31/100 | Train Loss: 1.3071 | Eval Loss: 1.3677 | Accuracy: 0.6707 | Precision: 0.4118 | Recall: 0.5400 | F1-Score: 0.4544 | LR: 0.0010 | \n",
      "Epoch 32/100 | Train Loss: 1.3020 | Eval Loss: 1.3734 | Accuracy: 0.6707 | Precision: 0.4251 | Recall: 0.5400 | F1-Score: 0.4596 | LR: 0.0010 | \n",
      "Epoch 33/100 | Train Loss: 1.2988 | Eval Loss: 1.3636 | Accuracy: 0.6707 | Precision: 0.4251 | Recall: 0.5400 | F1-Score: 0.4596 | LR: 0.0010 | \n",
      "Epoch 34/100 | Train Loss: 1.2973 | Eval Loss: 1.3652 | Accuracy: 0.6463 | Precision: 0.4023 | Recall: 0.5000 | F1-Score: 0.4242 | LR: 0.0010 | \n",
      "Epoch 35/100 | Train Loss: 1.3010 | Eval Loss: 1.3462 | Accuracy: 0.6463 | Precision: 0.4023 | Recall: 0.5000 | F1-Score: 0.4242 | LR: 0.0010 | \n",
      "Epoch 36/100 | Train Loss: 1.3036 | Eval Loss: 1.3388 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 37/100 | Train Loss: 1.2997 | Eval Loss: 1.3241 | Accuracy: 0.6341 | Precision: 0.3842 | Recall: 0.4800 | F1-Score: 0.4031 | LR: 0.0010 | \n",
      "Epoch 38/100 | Train Loss: 1.2942 | Eval Loss: 1.3307 | Accuracy: 0.6341 | Precision: 0.3881 | Recall: 0.4800 | F1-Score: 0.4038 | LR: 0.0010 | \n",
      "Epoch 39/100 | Train Loss: 1.2912 | Eval Loss: 1.3355 | Accuracy: 0.6585 | Precision: 0.4117 | Recall: 0.5200 | F1-Score: 0.4420 | LR: 0.0010 | \n",
      "Epoch 40/100 | Train Loss: 1.2876 | Eval Loss: 1.3489 | Accuracy: 0.6829 | Precision: 0.6274 | Recall: 0.5533 | F1-Score: 0.4868 | LR: 0.0010 | \n",
      "Epoch 41/100 | Train Loss: 1.2891 | Eval Loss: 1.3327 | Accuracy: 0.6585 | Precision: 0.6046 | Recall: 0.5133 | F1-Score: 0.4514 | LR: 0.0010 | \n",
      "Epoch 42/100 | Train Loss: 1.2891 | Eval Loss: 1.3300 | Accuracy: 0.6463 | Precision: 0.5904 | Recall: 0.4933 | F1-Score: 0.4310 | LR: 0.0010 | \n",
      "Epoch 43/100 | Train Loss: 1.2881 | Eval Loss: 1.3212 | Accuracy: 0.6463 | Precision: 0.5904 | Recall: 0.4933 | F1-Score: 0.4310 | LR: 0.0010 | \n",
      "Epoch 44/100 | Train Loss: 1.2846 | Eval Loss: 1.3261 | Accuracy: 0.6463 | Precision: 0.4928 | Recall: 0.4933 | F1-Score: 0.4318 | LR: 0.0010 | \n",
      "Epoch 45/100 | Train Loss: 1.2826 | Eval Loss: 1.3309 | Accuracy: 0.6585 | Precision: 0.5070 | Recall: 0.5133 | F1-Score: 0.4522 | LR: 0.0010 | \n",
      "Epoch 46/100 | Train Loss: 1.2821 | Eval Loss: 1.3317 | Accuracy: 0.6585 | Precision: 0.4917 | Recall: 0.5133 | F1-Score: 0.4480 | LR: 0.0010 | \n",
      "Epoch 47/100 | Train Loss: 1.2814 | Eval Loss: 1.3308 | Accuracy: 0.6585 | Precision: 0.5070 | Recall: 0.5133 | F1-Score: 0.4522 | LR: 0.0010 | \n",
      "Epoch 48/100 | Train Loss: 1.2825 | Eval Loss: 1.3208 | Accuracy: 0.6463 | Precision: 0.4928 | Recall: 0.4933 | F1-Score: 0.4318 | LR: 0.0010 | \n",
      "Epoch 49/100 | Train Loss: 1.2818 | Eval Loss: 1.3118 | Accuracy: 0.6463 | Precision: 0.4909 | Recall: 0.4933 | F1-Score: 0.4315 | LR: 0.0010 | \n",
      "Epoch 50/100 | Train Loss: 1.2799 | Eval Loss: 1.3173 | Accuracy: 0.6463 | Precision: 0.4928 | Recall: 0.4933 | F1-Score: 0.4318 | LR: 0.0010 | \n",
      "Epoch 51/100 | Train Loss: 1.2788 | Eval Loss: 1.3146 | Accuracy: 0.6585 | Precision: 0.5870 | Recall: 0.5133 | F1-Score: 0.4468 | LR: 0.0010 | \n",
      "Epoch 52/100 | Train Loss: 1.2771 | Eval Loss: 1.3205 | Accuracy: 0.6707 | Precision: 0.5039 | Recall: 0.5200 | F1-Score: 0.4755 | LR: 0.0010 | \n",
      "\n",
      "==================== TEST INFO ===================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [260:00:51<1486:14:20, 137191.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.82      0.43        11\n",
      "           1       0.82      0.60      0.69        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       0.74      0.97      0.84        29\n",
      "\n",
      "    accuracy                           0.55        83\n",
      "   macro avg       0.37      0.48      0.39        83\n",
      "weighted avg       0.44      0.55      0.47        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.421972, test accuracy: 0.5542, test precision: 0.3691, test recall: 0.4767, test F1-score: 0.3913\n",
      "Resultados:  {'Out channels': 64, 'Kernel size': 5, 'Hidden channels': 32, 'Normalization': 'rw', 'Loss_final': 1.2770963907241821, 'Accuracy_eval': 0.6139774859287056, 'Precision_eval': 0.37620678363996163, 'Recall_eval': 0.46170559042475545, 'F1_eval': 0.3818851550747284, 'Loss_eval': 1.3205134868621826, 'Loss_tst': 1.4219720363616943, 'Accuracy_tst': 0.5542168674698795, 'Precision_tst': 0.36906930081802747, 'Recall_tst': 0.4767398119122257, 'F1_tst': 0.3913400032803018}\n",
      "Entrenando modelo con out_channels=32, kernel_size=5, hidden_channels=16, normalization=rw\n",
      "\n",
      "==================== DATASET INFO ===================\n",
      "\n",
      "Train dataset: 384\n",
      "Validation dataset: 82\n",
      "Test dataset: 83\n",
      "\n",
      "==================== TRAIN INFO ===================\n",
      "\n",
      "Epoch 1/100 | Train Loss: 1.5766 | Eval Loss: 1.5114 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 2/100 | Train Loss: 1.5527 | Eval Loss: 1.5025 | Accuracy: 0.3780 | Precision: 0.0756 | Recall: 0.2000 | F1-Score: 0.1097 | LR: 0.0010 | \n",
      "Epoch 3/100 | Train Loss: 1.5371 | Eval Loss: 1.4868 | Accuracy: 0.4268 | Precision: 0.1601 | Recall: 0.2533 | F1-Score: 0.1831 | LR: 0.0010 | \n",
      "Epoch 4/100 | Train Loss: 1.5150 | Eval Loss: 1.4628 | Accuracy: 0.4878 | Precision: 0.1852 | Recall: 0.3200 | F1-Score: 0.2336 | LR: 0.0010 | \n",
      "Epoch 5/100 | Train Loss: 1.4960 | Eval Loss: 1.4403 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 6/100 | Train Loss: 1.4827 | Eval Loss: 1.4225 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 7/100 | Train Loss: 1.4737 | Eval Loss: 1.4094 | Accuracy: 0.5000 | Precision: 0.1876 | Recall: 0.3333 | F1-Score: 0.2401 | LR: 0.0010 | \n",
      "Epoch 8/100 | Train Loss: 1.4666 | Eval Loss: 1.3991 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 9/100 | Train Loss: 1.4612 | Eval Loss: 1.3911 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 10/100 | Train Loss: 1.4562 | Eval Loss: 1.3809 | Accuracy: 0.5732 | Precision: 0.2338 | Recall: 0.3882 | F1-Score: 0.2914 | LR: 0.0010 | \n",
      "Epoch 11/100 | Train Loss: 1.4518 | Eval Loss: 1.3754 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 12/100 | Train Loss: 1.4485 | Eval Loss: 1.3728 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 13/100 | Train Loss: 1.4454 | Eval Loss: 1.3712 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 14/100 | Train Loss: 1.4425 | Eval Loss: 1.3712 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 15/100 | Train Loss: 1.4395 | Eval Loss: 1.3711 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 16/100 | Train Loss: 1.4361 | Eval Loss: 1.3718 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 17/100 | Train Loss: 1.4323 | Eval Loss: 1.3708 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 18/100 | Train Loss: 1.4279 | Eval Loss: 1.3705 | Accuracy: 0.5610 | Precision: 0.2276 | Recall: 0.3818 | F1-Score: 0.2850 | LR: 0.0010 | \n",
      "Epoch 19/100 | Train Loss: 1.4226 | Eval Loss: 1.3708 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 20/100 | Train Loss: 1.4162 | Eval Loss: 1.3719 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 21/100 | Train Loss: 1.4087 | Eval Loss: 1.3668 | Accuracy: 0.5610 | Precision: 0.2254 | Recall: 0.3818 | F1-Score: 0.2834 | LR: 0.0010 | \n",
      "Epoch 22/100 | Train Loss: 1.4002 | Eval Loss: 1.3696 | Accuracy: 0.5854 | Precision: 0.3653 | Recall: 0.4218 | F1-Score: 0.3501 | LR: 0.0010 | \n",
      "Epoch 23/100 | Train Loss: 1.3917 | Eval Loss: 1.3702 | Accuracy: 0.5854 | Precision: 0.3153 | Recall: 0.4218 | F1-Score: 0.3444 | LR: 0.0010 | \n",
      "Epoch 24/100 | Train Loss: 1.3821 | Eval Loss: 1.3715 | Accuracy: 0.6098 | Precision: 0.3437 | Recall: 0.4618 | F1-Score: 0.3859 | LR: 0.0010 | \n",
      "Epoch 25/100 | Train Loss: 1.3735 | Eval Loss: 1.3738 | Accuracy: 0.6098 | Precision: 0.3296 | Recall: 0.4618 | F1-Score: 0.3800 | LR: 0.0010 | \n",
      "Epoch 26/100 | Train Loss: 1.3657 | Eval Loss: 1.3703 | Accuracy: 0.6220 | Precision: 0.3312 | Recall: 0.4682 | F1-Score: 0.3860 | LR: 0.0010 | \n",
      "Epoch 27/100 | Train Loss: 1.3580 | Eval Loss: 1.3709 | Accuracy: 0.6220 | Precision: 0.3307 | Recall: 0.4682 | F1-Score: 0.3852 | LR: 0.0010 | \n",
      "Epoch 28/100 | Train Loss: 1.3514 | Eval Loss: 1.3719 | Accuracy: 0.6098 | Precision: 0.3260 | Recall: 0.4618 | F1-Score: 0.3785 | LR: 0.0010 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [263:42:20<934:57:24, 86303.70s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     18\u001b[0m problem \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasificacion\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m mejor_trainer, mejores_parametros, mejores_resultados, resultados_df \u001b[38;5;241m=\u001b[39m \u001b[43mentrenar_y_evaluar_modelos_stconv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_early_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTConv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 29\u001b[0m, in \u001b[0;36mentrenar_y_evaluar_modelos_stconv\u001b[0;34m(param_grid, dataset, dataloader_params, num_early_stop, num_epochs, problem, name, target_names, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m STConvModel(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTConv\u001b[39m\u001b[38;5;124m\"\u001b[39m, node_features\u001b[38;5;241m=\u001b[39mn_features, node_count\u001b[38;5;241m=\u001b[39mn_nodes, n_target\u001b[38;5;241m=\u001b[39mn_target, out_channels\u001b[38;5;241m=\u001b[39mout_channels,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39mkernel_size, hidden_channels\u001b[38;5;241m=\u001b[39mhidden_channels, normalization\u001b[38;5;241m=\u001b[39mnormalization, is_classification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TrainerSTConv(model, dataset, device, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../experimentos_split/results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, dataloader_params, is_classification \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m losses, eval_losses, accs, precisions, recalls, f1s \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_early_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_early_stop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m test_acc, test_precision, test_recall, test_f1, test_loss, preds, real \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest()\n\u001b[1;32m     32\u001b[0m results_intermedio \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOut channels\u001b[39m\u001b[38;5;124m\"\u001b[39m: out_channels,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel size\u001b[39m\u001b[38;5;124m\"\u001b[39m: kernel_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_tst\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_f1\n\u001b[1;32m     48\u001b[0m }\n",
      "File \u001b[0;32m~/Documents/UGR/Master/TFM/repo/GNNs_PowerGraph/TFM/utils/trainer.py:148\u001b[0m, in \u001b[0;36mTrainerModel.train\u001b[0;34m(self, num_epochs, steps, num_early_stop, lr)\u001b[0m\n\u001b[1;32m    146\u001b[0m is_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 148\u001b[0m losses_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(losses_epoch)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    150\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m~/Documents/UGR/Master/TFM/repo/GNNs_PowerGraph/TFM/utils/trainer.py:640\u001b[0m, in \u001b[0;36mTrainerMPNNLSTM._train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m snapshot \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    639\u001b[0m     snapshot \u001b[38;5;241m=\u001b[39m snapshot\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 640\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_snap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnapshot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    643\u001b[0m     accumulated_loss  \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/UGR/Master/TFM/repo/GNNs_PowerGraph/TFM/utils/trainer.py:755\u001b[0m, in \u001b[0;36mTrainerSTConv._train_snap\u001b[0;34m(self, snapshot)\u001b[0m\n\u001b[1;32m    753\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m snapshot\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \n\u001b[1;32m    754\u001b[0m y \u001b[38;5;241m=\u001b[39m snapshot\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \n\u001b[0;32m--> 755\u001b[0m y_hat\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__loss__(y_hat, y)\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda/envs/tfm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/tfm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UGR/Master/TFM/repo/GNNs_PowerGraph/TFM/utils/models.py:349\u001b[0m, in \u001b[0;36mSTConvModel.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_weight):\n\u001b[0;32m--> 349\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurrent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(h)\n\u001b[1;32m    351\u001b[0m     h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/tfm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/tfm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UGR/Master/TFM/repo/GNNs_PowerGraph/TFM/utils/stgcn.py:153\u001b[0m, in \u001b[0;36mSTConv.forward\u001b[0;34m(self, X, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T_0\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T_0\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 153\u001b[0m         T[b][t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT_0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m T \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(T)\n\u001b[1;32m    156\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporal_conv2(T)\n",
      "File \u001b[0;32m~/miniconda/envs/tfm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/tfm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UGR/Master/TFM/repo/GNNs_PowerGraph/TFM/utils/cheb_conv.py:151\u001b[0m, in \u001b[0;36mChebConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    144\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m     lambda_max: OptTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    149\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 151\u001b[0m     edge_index, norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__norm__\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     Tx_0 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    162\u001b[0m     Tx_1 \u001b[38;5;241m=\u001b[39m x  \u001b[38;5;66;03m# Dummy.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UGR/Master/TFM/repo/GNNs_PowerGraph/TFM/utils/cheb_conv.py:135\u001b[0m, in \u001b[0;36mChebConv.__norm__\u001b[0;34m(self, edge_index, num_nodes, edge_weight, normalization, lambda_max, dtype, batch)\u001b[0m\n\u001b[1;32m    132\u001b[0m     lambda_max \u001b[38;5;241m=\u001b[39m lambda_max[batch[edge_index[\u001b[38;5;241m0\u001b[39m]]]\n\u001b[1;32m    134\u001b[0m edge_weight \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m edge_weight) \u001b[38;5;241m/\u001b[39m lambda_max\n\u001b[0;32m--> 135\u001b[0m \u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m loop_mask \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    138\u001b[0m edge_weight[loop_mask] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"out_channels\": [32, 64],\n",
    "    \"kernel_size\": [3,5,7],\n",
    "    \"normalization\": [\"sym\", \"rw\"],\n",
    "    \"hidden_channels\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": 4,\n",
    "    \"data_split_ratio\": [0.7, 0.15, 0.15],\n",
    "    \"seed\": 42,\n",
    "    \"keep_same\": True,\n",
    "    \"use_batch\": False\n",
    "}\n",
    "\n",
    "num_early_stop = 10\n",
    "num_epochs = 100\n",
    "problem = \"clasificacion\"\n",
    "\n",
    "mejor_trainer, mejores_parametros, mejores_resultados, resultados_df = entrenar_y_evaluar_modelos_stconv(\n",
    "    param_grid, \n",
    "    dataset_full, \n",
    "    dataloader_params, \n",
    "    num_early_stop, \n",
    "    num_epochs, \n",
    "    problem, \"STConv\",target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TEST INFO ===================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        11\n",
      "           1       0.92      0.73      0.81        15\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.95      1.00      0.97        19\n",
      "           4       0.85      1.00      0.92        29\n",
      "\n",
      "    accuracy                           0.84        83\n",
      "   macro avg       0.67      0.75      0.70        83\n",
      "weighted avg       0.77      0.84      0.80        83\n",
      "\n",
      "preds:  torch.Size([])\n",
      "test loss: 1.064711, test accuracy: 0.8434, test precision: 0.6733, test recall: 0.7467, test F1-score: 0.6991\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc, test_precision, test_recall, test_f1, test_loss, preds, real = mejor_trainer.test()\n",
    "plot_clasificacion(real, preds, target_names, \"MTGNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== GUARDANDO RESULTADOS ===================\n",
      "\n",
      "         Modelo                                             Params  \\\n",
      "0     MPNN_LSTM                {'Hidden Size': 64, 'Dropout': 0.2}   \n",
      "1    LSTM_BATCH                  {'Hidden Size': 150, 'Layers': 1}   \n",
      "2  LSTM_NOBATCH                  {'Hidden Size': 150, 'Layers': 2}   \n",
      "3         AGCRN             {'hidden': 50, 'Embedding': 5, 'K': 2}   \n",
      "4   DyGrEncoder  {'aggr': 'mean', 'conv': 2, 'lstm': 1, 'lstm_o...   \n",
      "5        MSTGCN  {'nb_block': 2, 'nb_chev_filter': 4, 'nb_time_...   \n",
      "6         DCRNN                                     {'hidden': 60}   \n",
      "7         MTGNN  {'gcn_depth': 2, 'conv_channels': 16, 'kernel_...   \n",
      "\n",
      "                      Fichero_resultados_experimento  Loss_tst  Loss_eval  \\\n",
      "0  ../experimentos_split/results/clasificacion/aj...  1.348738   1.286855   \n",
      "1  ../experimentos_split/results/clasificacion/aj...  1.163377   1.213140   \n",
      "2  ../experimentos_split/results/clasificacion/aj...  1.160608   1.194841   \n",
      "3  ../experimentos_split/results/clasificacion/aj...  1.344170   1.293829   \n",
      "4  ../experimentos_split/results/clasificacion/aj...  1.278305   1.244017   \n",
      "5  ../experimentos_split/results/clasificacion/aj...  1.115873   1.170089   \n",
      "6  ../experimentos_split/results/clasificacion/aj...  1.365779   1.297018   \n",
      "7  ../experimentos_split/results/clasificacion/aj...  1.064711   1.164019   \n",
      "\n",
      "   Loss_final  Accuracy_eval  Precision_eval  Recall_eval   F1_eval  \\\n",
      "0    1.270143       0.600000        0.438630     0.498128  0.435153   \n",
      "1    1.075731       0.671875        0.630667     0.671140  0.635028   \n",
      "2    1.076455       0.706667        0.666084     0.685025  0.667648   \n",
      "3    1.254052       0.583333        0.399306     0.481816  0.421265   \n",
      "4    1.019157       0.626667        0.523039     0.498103  0.504885   \n",
      "5    1.019408       0.746667        0.699744     0.720493  0.707039   \n",
      "6    1.285657       0.600000        0.438603     0.498128  0.418954   \n",
      "7    1.105075       0.731707        0.584593     0.679561  0.621524   \n",
      "\n",
      "   Accuracy_tst  Precision_tst  Recall_tst    F1_tst  \n",
      "0      0.535714       0.338182    0.475517  0.388172  \n",
      "1      0.765625       0.705541    0.699405  0.698988  \n",
      "2      0.738095       0.688172    0.677798  0.681843  \n",
      "3      0.547619       0.327039    0.495517  0.389881  \n",
      "4      0.630952       0.586096    0.576328  0.575000  \n",
      "5      0.809524       0.731190    0.720881  0.717359  \n",
      "6      0.547619       0.327039    0.495517  0.389881  \n",
      "7      0.843373       0.673333    0.746667  0.699105  \n",
      "\n",
      "==================== RESULTADOS GUARDADOS ===================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_model =\"MTGNN\"\n",
    "results_save_path = \"../experimentos_split/results\"\n",
    "\n",
    "path_save_experiment = results_save_path+f\"/{problem}\"+ f\"/ajustes/{name_model}_results.csv\"\n",
    "resultados_df.to_csv(path_save_experiment, index=False)\n",
    "mejor_trainer.save_model(path_save_experiment=path_save_experiment, params = mejores_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
